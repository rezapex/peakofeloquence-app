{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:dammit.py","body":"# -*- coding: utf-8 -*-\n\"\"\"Beautiful Soup bonus library: Unicode, Dammit\n\nThis library converts a bytestream to Unicode through any means\nnecessary. It is heavily based on code from Mark Pilgrim's Universal\nFeed Parser. It works best on XML and HTML, but it does not rewrite the\nXML or HTML to reflect a new encoding; that's the tree builder's job.\n\"\"\"\n# Use of this source code is governed by the MIT license.\n__license__ = \"MIT\"\n\nfrom html.entities import codepoint2name\nfrom collections import defaultdict\nimport codecs\nimport re\nimport logging\nimport string\n\n# Import a library to autodetect character encodings. We'll support\n# any of a number of libraries that all support the same API:\n#\n# * cchardet\n# * chardet\n# * charset-normalizer\nchardet_module = None\ntry:\n    #  PyPI package: cchardet\n    import cchardet as chardet_module\nexcept ImportError:\n    try:\n        #  Debian package: python-chardet\n        #  PyPI package: chardet\n        import chardet as chardet_module\n    except ImportError:\n        try:\n            # PyPI package: charset-normalizer\n            import charset_normalizer as chardet_module\n        except ImportError:\n            # No chardet available.\n            chardet_module = None\n\nif chardet_module:\n    def chardet_dammit(s):\n        if isinstance(s, str):\n            return None\n        return chardet_module.detect(s)['encoding']\nelse:\n    def chardet_dammit(s):\n        return None\n\n# Build bytestring and Unicode versions of regular expressions for finding\n# a declared encoding inside an XML or HTML document.\nxml_encoding = '^\\\\s*<\\\\?.*encoding=[\\'\"](.*?)[\\'\"].*\\\\?>'\nhtml_meta = '<\\\\s*meta[^>]+charset\\\\s*=\\\\s*[\"\\']?([^>]*?)[ /;\\'\">]'\nencoding_res = dict()\nencoding_res[bytes] = {\n    'html' : re.compile(html_meta.encode(\"ascii\"), re.I),\n    'xml' : re.compile(xml_encoding.encode(\"ascii\"), re.I),\n}\nencoding_res[str] = {\n    'html' : re.compile(html_meta, re.I),\n    'xml' : re.compile(xml_encoding, re.I)\n}\n\nfrom html.entities import html5\n\nclass EntitySubstitution(object):\n    \"\"\"The ability to substitute XML or HTML entities for certain characters.\"\"\"\n\n    def _populate_class_variables():\n        \"\"\"Initialize variables used by this class to manage the plethora of\n        HTML5 named entities.\n\n        This function returns a 3-tuple containing two dictionaries\n        and a regular expression:\n\n        unicode_to_name - A mapping of Unicode strings like \"⦨\" to\n        entity names like \"angmsdaa\". When a single Unicode string has\n        multiple entity names, we try to choose the most commonly-used\n        name.\n\n        name_to_unicode: A mapping of entity names like \"angmsdaa\" to \n        Unicode strings like \"⦨\".\n\n        named_entity_re: A regular expression matching (almost) any\n        Unicode string that corresponds to an HTML5 named entity.\n        \"\"\"\n        unicode_to_name = {}\n        name_to_unicode = {}\n\n        short_entities = set()\n        long_entities_by_first_character = defaultdict(set)\n        \n        for name_with_semicolon, character in sorted(html5.items()):\n            # \"It is intentional, for legacy compatibility, that many\n            # code points have multiple character reference names. For\n            # example, some appear both with and without the trailing\n            # semicolon, or with different capitalizations.\"\n            # - https://html.spec.whatwg.org/multipage/named-characters.html#named-character-references\n            #\n            # The parsers are in charge of handling (or not) character\n            # references with no trailing semicolon, so we remove the\n            # semicolon whenever it appears.\n            if name_with_semicolon.endswith(';'):\n                name = name_with_semicolon[:-1]\n            else:\n                name = name_with_semicolon\n\n            # When parsing HTML, we want to recognize any known named\n            # entity and convert it to a sequence of Unicode\n            # characters.\n            if name not in name_to_unicode:\n                name_to_unicode[name] = character\n\n            # When _generating_ HTML, we want to recognize special\n            # character sequences that _could_ be converted to named\n            # entities.\n            unicode_to_name[character] = name\n\n            # We also need to build a regular expression that lets us\n            # _find_ those characters in output strings so we can\n            # replace them.\n            #\n            # This is tricky, for two reasons.\n\n            if (len(character) == 1 and ord(character) < 128\n                and character not in '<>&'):\n                # First, it would be annoying to turn single ASCII\n                # characters like | into named entities like\n                # &verbar;. The exceptions are <>&, which we _must_\n                # turn into named entities to produce valid HTML.\n                continue\n\n            if len(character) > 1 and all(ord(x) < 128 for x in character):\n                # We also do not want to turn _combinations_ of ASCII\n                # characters like 'fj' into named entities like '&fjlig;',\n                # though that's more debateable.\n                continue\n\n            # Second, some named entities have a Unicode value that's\n            # a subset of the Unicode value for some _other_ named\n            # entity.  As an example, \\u2267' is &GreaterFullEqual;,\n            # but '\\u2267\\u0338' is &NotGreaterFullEqual;. Our regular\n            # expression needs to match the first two characters of\n            # \"\\u2267\\u0338foo\", but only the first character of\n            # \"\\u2267foo\".\n            #\n            # In this step, we build two sets of characters that\n            # _eventually_ need to go into the regular expression. But\n            # we won't know exactly what the regular expression needs\n            # to look like until we've gone through the entire list of\n            # named entities.\n            if len(character) == 1:\n                short_entities.add(character)\n            else:\n                long_entities_by_first_character[character[0]].add(character)\n\n        # Now that we've been through the entire list of entities, we\n        # can create a regular expression that matches any of them.\n        particles = set()\n        for short in short_entities:\n            long_versions = long_entities_by_first_character[short]\n            if not long_versions:\n                particles.add(short)\n            else:\n                ignore = \"\".join([x[1] for x in long_versions])\n                # This finds, e.g. \\u2267 but only if it is _not_\n                # followed by \\u0338.\n                particles.add(\"%s(?![%s])\" % (short, ignore))\n        \n        for long_entities in list(long_entities_by_first_character.values()):\n            for long_entity in long_entities:\n                particles.add(long_entity)\n\n        re_definition = \"(%s)\" % \"|\".join(particles)\n                \n        # If an entity shows up in both html5 and codepoint2name, it's\n        # likely that HTML5 gives it several different names, such as\n        # 'rsquo' and 'rsquor'. When converting Unicode characters to\n        # named entities, the codepoint2name name should take\n        # precedence where possible, since that's the more easily\n        # recognizable one.\n        for codepoint, name in list(codepoint2name.items()):\n            character = chr(codepoint)\n            unicode_to_name[character] = name\n\n        return unicode_to_name, name_to_unicode, re.compile(re_definition)\n    (CHARACTER_TO_HTML_ENTITY, HTML_ENTITY_TO_CHARACTER,\n     CHARACTER_TO_HTML_ENTITY_RE) = _populate_class_variables()\n\n    CHARACTER_TO_XML_ENTITY = {\n        \"'\": \"apos\",\n        '\"': \"quot\",\n        \"&\": \"amp\",\n        \"<\": \"lt\",\n        \">\": \"gt\",\n        }\n\n    BARE_AMPERSAND_OR_BRACKET = re.compile(\"([<>]|\"\n                                           \"&(?!#\\\\d+;|#x[0-9a-fA-F]+;|\\\\w+;)\"\n                                           \")\")\n\n    AMPERSAND_OR_BRACKET = re.compile(\"([<>&])\")\n\n    @classmethod\n    def _substitute_html_entity(cls, matchobj):\n        \"\"\"Used with a regular expression to substitute the\n        appropriate HTML entity for a special character string.\"\"\"\n        entity = cls.CHARACTER_TO_HTML_ENTITY.get(matchobj.group(0))\n        return \"&%s;\" % entity\n\n    @classmethod\n    def _substitute_xml_entity(cls, matchobj):\n        \"\"\"Used with a regular expression to substitute the\n        appropriate XML entity for a special character string.\"\"\"\n        entity = cls.CHARACTER_TO_XML_ENTITY[matchobj.group(0)]\n        return \"&%s;\" % entity\n\n    @classmethod\n    def quoted_attribute_value(self, value):\n        \"\"\"Make a value into a quoted XML attribute, possibly escaping it.\n\n         Most strings will be quoted using double quotes.\n\n          Bob's Bar -> \"Bob's Bar\"\n\n         If a string contains double quotes, it will be quoted using\n         single quotes.\n\n          Welcome to \"my bar\" -> 'Welcome to \"my bar\"'\n\n         If a string contains both single and double quotes, the\n         double quotes will be escaped, and the string will be quoted\n         using double quotes.\n\n          Welcome to \"Bob's Bar\" -> \"Welcome to &quot;Bob's bar&quot;\n        \"\"\"\n        quote_with = '\"'\n        if '\"' in value:\n            if \"'\" in value:\n                # The string contains both single and double\n                # quotes.  Turn the double quotes into\n                # entities. We quote the double quotes rather than\n                # the single quotes because the entity name is\n                # \"&quot;\" whether this is HTML or XML.  If we\n                # quoted the single quotes, we'd have to decide\n                # between &apos; and &squot;.\n                replace_with = \"&quot;\"\n                value = value.replace('\"', replace_with)\n            else:\n                # There are double quotes but no single quotes.\n                # We can use single quotes to quote the attribute.\n                quote_with = \"'\"\n        return quote_with + value + quote_with\n\n    @classmethod\n    def substitute_xml(cls, value, make_quoted_attribute=False):\n        \"\"\"Substitute XML entities for special XML characters.\n\n        :param value: A string to be substituted. The less-than sign\n          will become &lt;, the greater-than sign will become &gt;,\n          and any ampersands will become &amp;. If you want ampersands\n          that appear to be part of an entity definition to be left\n          alone, use substitute_xml_containing_entities() instead.\n\n        :param make_quoted_attribute: If True, then the string will be\n         quoted, as befits an attribute value.\n        \"\"\"\n        # Escape angle brackets and ampersands.\n        value = cls.AMPERSAND_OR_BRACKET.sub(\n            cls._substitute_xml_entity, value)\n\n        if make_quoted_attribute:\n            value = cls.quoted_attribute_value(value)\n        return value\n\n    @classmethod\n    def substitute_xml_containing_entities(\n        cls, value, make_quoted_attribute=False):\n        \"\"\"Substitute XML entities for special XML characters.\n\n        :param value: A string to be substituted. The less-than sign will\n          become &lt;, the greater-than sign will become &gt;, and any\n          ampersands that are not part of an entity defition will\n          become &amp;.\n\n        :param make_quoted_attribute: If True, then the string will be\n         quoted, as befits an attribute value.\n        \"\"\"\n        # Escape angle brackets, and ampersands that aren't part of\n        # entities.\n        value = cls.BARE_AMPERSAND_OR_BRACKET.sub(\n            cls._substitute_xml_entity, value)\n\n        if make_quoted_attribute:\n            value = cls.quoted_attribute_value(value)\n        return value\n\n    @classmethod\n    def substitute_html(cls, s):\n        \"\"\"Replace certain Unicode characters with named HTML entities.\n\n        This differs from data.encode(encoding, 'xmlcharrefreplace')\n        in that the goal is to make the result more readable (to those\n        with ASCII displays) rather than to recover from\n        errors. There's absolutely nothing wrong with a UTF-8 string\n        containg a LATIN SMALL LETTER E WITH ACUTE, but replacing that\n        character with \"&eacute;\" will make it more readable to some\n        people.\n\n        :param s: A Unicode string.\n        \"\"\"\n        return cls.CHARACTER_TO_HTML_ENTITY_RE.sub(\n            cls._substitute_html_entity, s)\n\n\nclass EncodingDetector:\n    \"\"\"Suggests a number of possible encodings for a bytestring.\n\n    Order of precedence:\n\n    1. Encodings you specifically tell EncodingDetector to try first\n    (the known_definite_encodings argument to the constructor).\n\n    2. An encoding determined by sniffing the document's byte-order mark.\n\n    3. Encodings you specifically tell EncodingDetector to try if\n    byte-order mark sniffing fails (the user_encodings argument to the\n    constructor).\n\n    4. An encoding declared within the bytestring itself, either in an\n    XML declaration (if the bytestring is to be interpreted as an XML\n    document), or in a <meta> tag (if the bytestring is to be\n    interpreted as an HTML document.)\n\n    5. An encoding detected through textual analysis by chardet,\n    cchardet, or a similar external library.\n\n    4. UTF-8.\n\n    5. Windows-1252.\n\n    \"\"\"\n    def __init__(self, markup, known_definite_encodings=None,\n                 is_html=False, exclude_encodings=None,\n                 user_encodings=None, override_encodings=None):\n        \"\"\"Constructor.\n\n        :param markup: Some markup in an unknown encoding.\n\n        :param known_definite_encodings: When determining the encoding\n            of `markup`, these encodings will be tried first, in\n            order. In HTML terms, this corresponds to the \"known\n            definite encoding\" step defined here:\n            https://html.spec.whatwg.org/multipage/parsing.html#parsing-with-a-known-character-encoding\n\n        :param user_encodings: These encodings will be tried after the\n            `known_definite_encodings` have been tried and failed, and\n            after an attempt to sniff the encoding by looking at a\n            byte order mark has failed. In HTML terms, this\n            corresponds to the step \"user has explicitly instructed\n            the user agent to override the document's character\n            encoding\", defined here:\n            https://html.spec.whatwg.org/multipage/parsing.html#determining-the-character-encoding\n\n        :param override_encodings: A deprecated alias for\n            known_definite_encodings. Any encodings here will be tried\n            immediately after the encodings in\n            known_definite_encodings.\n\n        :param is_html: If True, this markup is considered to be\n            HTML. Otherwise it's assumed to be XML.\n\n        :param exclude_encodings: These encodings will not be tried,\n            even if they otherwise would be.\n\n        \"\"\"\n        self.known_definite_encodings = list(known_definite_encodings or [])\n        if override_encodings:\n            self.known_definite_encodings += override_encodings\n        self.user_encodings = user_encodings or []\n        exclude_encodings = exclude_encodings or []\n        self.exclude_encodings = set([x.lower() for x in exclude_encodings])\n        self.chardet_encoding = None\n        self.is_html = is_html\n        self.declared_encoding = None\n\n        # First order of business: strip a byte-order mark.\n        self.markup, self.sniffed_encoding = self.strip_byte_order_mark(markup)\n\n    def _usable(self, encoding, tried):\n        \"\"\"Should we even bother to try this encoding?\n\n        :param encoding: Name of an encoding.\n        :param tried: Encodings that have already been tried. This will be modified\n            as a side effect.\n        \"\"\"\n        if encoding is not None:\n            encoding = encoding.lower()\n            if encoding in self.exclude_encodings:\n                return False\n            if encoding not in tried:\n                tried.add(encoding)\n                return True\n        return False\n\n    @property\n    def encodings(self):\n        \"\"\"Yield a number of encodings that might work for this markup.\n\n        :yield: A sequence of strings.\n        \"\"\"\n        tried = set()\n\n        # First, try the known definite encodings\n        for e in self.known_definite_encodings:\n            if self._usable(e, tried):\n                yield e\n\n        # Did the document originally start with a byte-order mark\n        # that indicated its encoding?\n        if self._usable(self.sniffed_encoding, tried):\n            yield self.sniffed_encoding\n\n        # Sniffing the byte-order mark did nothing; try the user\n        # encodings.\n        for e in self.user_encodings:\n            if self._usable(e, tried):\n                yield e\n            \n        # Look within the document for an XML or HTML encoding\n        # declaration.\n        if self.declared_encoding is None:\n            self.declared_encoding = self.find_declared_encoding(\n                self.markup, self.is_html)\n        if self._usable(self.declared_encoding, tried):\n            yield self.declared_encoding\n\n        # Use third-party character set detection to guess at the\n        # encoding.\n        if self.chardet_encoding is None:\n            self.chardet_encoding = chardet_dammit(self.markup)\n        if self._usable(self.chardet_encoding, tried):\n            yield self.chardet_encoding\n\n        # As a last-ditch effort, try utf-8 and windows-1252.\n        for e in ('utf-8', 'windows-1252'):\n            if self._usable(e, tried):\n                yield e\n\n    @classmethod\n    def strip_byte_order_mark(cls, data):\n        \"\"\"If a byte-order mark is present, strip it and return the encoding it implies.\n\n        :param data: Some markup.\n        :return: A 2-tuple (modified data, implied encoding)\n        \"\"\"\n        encoding = None\n        if isinstance(data, str):\n            # Unicode data cannot have a byte-order mark.\n            return data, encoding\n        if (len(data) >= 4) and (data[:2] == b'\\xfe\\xff') \\\n               and (data[2:4] != '\\x00\\x00'):\n            encoding = 'utf-16be'\n            data = data[2:]\n        elif (len(data) >= 4) and (data[:2] == b'\\xff\\xfe') \\\n                 and (data[2:4] != '\\x00\\x00'):\n            encoding = 'utf-16le'\n            data = data[2:]\n        elif data[:3] == b'\\xef\\xbb\\xbf':\n            encoding = 'utf-8'\n            data = data[3:]\n        elif data[:4] == b'\\x00\\x00\\xfe\\xff':\n            encoding = 'utf-32be'\n            data = data[4:]\n        elif data[:4] == b'\\xff\\xfe\\x00\\x00':\n            encoding = 'utf-32le'\n            data = data[4:]\n        return data, encoding\n\n    @classmethod\n    def find_declared_encoding(cls, markup, is_html=False, search_entire_document=False):\n        \"\"\"Given a document, tries to find its declared encoding.\n\n        An XML encoding is declared at the beginning of the document.\n\n        An HTML encoding is declared in a <meta> tag, hopefully near the\n        beginning of the document.\n\n        :param markup: Some markup.\n        :param is_html: If True, this markup is considered to be HTML. Otherwise\n            it's assumed to be XML.\n        :param search_entire_document: Since an encoding is supposed to declared near the beginning\n            of the document, most of the time it's only necessary to search a few kilobytes of data.\n            Set this to True to force this method to search the entire document.\n        \"\"\"\n        if search_entire_document:\n            xml_endpos = html_endpos = len(markup)\n        else:\n            xml_endpos = 1024\n            html_endpos = max(2048, int(len(markup) * 0.05))\n\n        if isinstance(markup, bytes):\n            res = encoding_res[bytes]\n        else:\n            res = encoding_res[str]\n\n        xml_re = res['xml']\n        html_re = res['html']\n        declared_encoding = None\n        declared_encoding_match = xml_re.search(markup, endpos=xml_endpos)\n        if not declared_encoding_match and is_html:\n            declared_encoding_match = html_re.search(markup, endpos=html_endpos)\n        if declared_encoding_match is not None:\n            declared_encoding = declared_encoding_match.groups()[0]\n        if declared_encoding:\n            if isinstance(declared_encoding, bytes):\n                declared_encoding = declared_encoding.decode('ascii', 'replace')\n            return declared_encoding.lower()\n        return None\n\nclass UnicodeDammit:\n    \"\"\"A class for detecting the encoding of a *ML document and\n    converting it to a Unicode string. If the source encoding is\n    windows-1252, can replace MS smart quotes with their HTML or XML\n    equivalents.\"\"\"\n\n    # This dictionary maps commonly seen values for \"charset\" in HTML\n    # meta tags to the corresponding Python codec names. It only covers\n    # values that aren't in Python's aliases and can't be determined\n    # by the heuristics in find_codec.\n    CHARSET_ALIASES = {\"macintosh\": \"mac-roman\",\n                       \"x-sjis\": \"shift-jis\"}\n\n    ENCODINGS_WITH_SMART_QUOTES = [\n        \"windows-1252\",\n        \"iso-8859-1\",\n        \"iso-8859-2\",\n        ]\n\n    def __init__(self, markup, known_definite_encodings=[],\n                 smart_quotes_to=None, is_html=False, exclude_encodings=[],\n                 user_encodings=None, override_encodings=None\n    ):\n        \"\"\"Constructor.\n\n        :param markup: A bytestring representing markup in an unknown encoding.\n\n        :param known_definite_encodings: When determining the encoding\n            of `markup`, these encodings will be tried first, in\n            order. In HTML terms, this corresponds to the \"known\n            definite encoding\" step defined here:\n            https://html.spec.whatwg.org/multipage/parsing.html#parsing-with-a-known-character-encoding\n\n        :param user_encodings: These encodings will be tried after the\n            `known_definite_encodings` have been tried and failed, and\n            after an attempt to sniff the encoding by looking at a\n            byte order mark has failed. In HTML terms, this\n            corresponds to the step \"user has explicitly instructed\n            the user agent to override the document's character\n            encoding\", defined here:\n            https://html.spec.whatwg.org/multipage/parsing.html#determining-the-character-encoding\n\n        :param override_encodings: A deprecated alias for\n            known_definite_encodings. Any encodings here will be tried\n            immediately after the encodings in\n            known_definite_encodings.\n\n        :param smart_quotes_to: By default, Microsoft smart quotes will, like all other characters, be converted\n           to Unicode characters. Setting this to 'ascii' will convert them to ASCII quotes instead.\n           Setting it to 'xml' will convert them to XML entity references, and setting it to 'html'\n           will convert them to HTML entity references.\n        :param is_html: If True, this markup is considered to be HTML. Otherwise\n            it's assumed to be XML.\n        :param exclude_encodings: These encodings will not be considered, even\n            if the sniffing code thinks they might make sense.\n\n        \"\"\"\n        self.smart_quotes_to = smart_quotes_to\n        self.tried_encodings = []\n        self.contains_replacement_characters = False\n        self.is_html = is_html\n        self.log = logging.getLogger(__name__)\n        self.detector = EncodingDetector(\n            markup, known_definite_encodings, is_html, exclude_encodings,\n            user_encodings, override_encodings\n        )\n\n        # Short-circuit if the data is in Unicode to begin with.\n        if isinstance(markup, str) or markup == '':\n            self.markup = markup\n            self.unicode_markup = str(markup)\n            self.original_encoding = None\n            return\n\n        # The encoding detector may have stripped a byte-order mark.\n        # Use the stripped markup from this point on.\n        self.markup = self.detector.markup\n\n        u = None\n        for encoding in self.detector.encodings:\n            markup = self.detector.markup\n            u = self._convert_from(encoding)\n            if u is not None:\n                break\n\n        if not u:\n            # None of the encodings worked. As an absolute last resort,\n            # try them again with character replacement.\n\n            for encoding in self.detector.encodings:\n                if encoding != \"ascii\":\n                    u = self._convert_from(encoding, \"replace\")\n                if u is not None:\n                    self.log.warning(\n                            \"Some characters could not be decoded, and were \"\n                            \"replaced with REPLACEMENT CHARACTER.\"\n                    )\n                    self.contains_replacement_characters = True\n                    break\n\n        # If none of that worked, we could at this point force it to\n        # ASCII, but that would destroy so much data that I think\n        # giving up is better.\n        self.unicode_markup = u\n        if not u:\n            self.original_encoding = None\n\n    def _sub_ms_char(self, match):\n        \"\"\"Changes a MS smart quote character to an XML or HTML\n        entity, or an ASCII character.\"\"\"\n        orig = match.group(1)\n        if self.smart_quotes_to == 'ascii':\n            sub = self.MS_CHARS_TO_ASCII.get(orig).encode()\n        else:\n            sub = self.MS_CHARS.get(orig)\n            if type(sub) == tuple:\n                if self.smart_quotes_to == 'xml':\n                    sub = '&#x'.encode() + sub[1].encode() + ';'.encode()\n                else:\n                    sub = '&'.encode() + sub[0].encode() + ';'.encode()\n            else:\n                sub = sub.encode()\n        return sub\n\n    def _convert_from(self, proposed, errors=\"strict\"):\n        \"\"\"Attempt to convert the markup to the proposed encoding.\n\n        :param proposed: The name of a character encoding.\n        \"\"\"\n        proposed = self.find_codec(proposed)\n        if not proposed or (proposed, errors) in self.tried_encodings:\n            return None\n        self.tried_encodings.append((proposed, errors))\n        markup = self.markup\n        # Convert smart quotes to HTML if coming from an encoding\n        # that might have them.\n        if (self.smart_quotes_to is not None\n            and proposed in self.ENCODINGS_WITH_SMART_QUOTES):\n            smart_quotes_re = b\"([\\x80-\\x9f])\"\n            smart_quotes_compiled = re.compile(smart_quotes_re)\n            markup = smart_quotes_compiled.sub(self._sub_ms_char, markup)\n\n        try:\n            #print(\"Trying to convert document to %s (errors=%s)\" % (\n            #    proposed, errors))\n            u = self._to_unicode(markup, proposed, errors)\n            self.markup = u\n            self.original_encoding = proposed\n        except Exception as e:\n            #print(\"That didn't work!\")\n            #print(e)\n            return None\n        #print(\"Correct encoding: %s\" % proposed)\n        return self.markup\n\n    def _to_unicode(self, data, encoding, errors=\"strict\"):\n        \"\"\"Given a string and its encoding, decodes the string into Unicode.\n\n        :param encoding: The name of an encoding.\n        \"\"\"\n        return str(data, encoding, errors)\n\n    @property\n    def declared_html_encoding(self):\n        \"\"\"If the markup is an HTML document, returns the encoding declared _within_\n        the document.\n        \"\"\"\n        if not self.is_html:\n            return None\n        return self.detector.declared_encoding\n\n    def find_codec(self, charset):\n        \"\"\"Convert the name of a character set to a codec name.\n\n        :param charset: The name of a character set.\n        :return: The name of a codec.\n        \"\"\"\n        value = (self._codec(self.CHARSET_ALIASES.get(charset, charset))\n               or (charset and self._codec(charset.replace(\"-\", \"\")))\n               or (charset and self._codec(charset.replace(\"-\", \"_\")))\n               or (charset and charset.lower())\n               or charset\n                )\n        if value:\n            return value.lower()\n        return None\n\n    def _codec(self, charset):\n        if not charset:\n            return charset\n        codec = None\n        try:\n            codecs.lookup(charset)\n            codec = charset\n        except (LookupError, ValueError):\n            pass\n        return codec\n\n\n    # A partial mapping of ISO-Latin-1 to HTML entities/XML numeric entities.\n    MS_CHARS = {b'\\x80': ('euro', '20AC'),\n                b'\\x81': ' ',\n                b'\\x82': ('sbquo', '201A'),\n                b'\\x83': ('fnof', '192'),\n                b'\\x84': ('bdquo', '201E'),\n                b'\\x85': ('hellip', '2026'),\n                b'\\x86': ('dagger', '2020'),\n                b'\\x87': ('Dagger', '2021'),\n                b'\\x88': ('circ', '2C6'),\n                b'\\x89': ('permil', '2030'),\n                b'\\x8A': ('Scaron', '160'),\n                b'\\x8B': ('lsaquo', '2039'),\n                b'\\x8C': ('OElig', '152'),\n                b'\\x8D': '?',\n                b'\\x8E': ('#x17D', '17D'),\n                b'\\x8F': '?',\n                b'\\x90': '?',\n                b'\\x91': ('lsquo', '2018'),\n                b'\\x92': ('rsquo', '2019'),\n                b'\\x93': ('ldquo', '201C'),\n                b'\\x94': ('rdquo', '201D'),\n                b'\\x95': ('bull', '2022'),\n                b'\\x96': ('ndash', '2013'),\n                b'\\x97': ('mdash', '2014'),\n                b'\\x98': ('tilde', '2DC'),\n                b'\\x99': ('trade', '2122'),\n                b'\\x9a': ('scaron', '161'),\n                b'\\x9b': ('rsaquo', '203A'),\n                b'\\x9c': ('oelig', '153'),\n                b'\\x9d': '?',\n                b'\\x9e': ('#x17E', '17E'),\n                b'\\x9f': ('Yuml', ''),}\n\n    # A parochial partial mapping of ISO-Latin-1 to ASCII. Contains\n    # horrors like stripping diacritical marks to turn á into a, but also\n    # contains non-horrors like turning “ into \".\n    MS_CHARS_TO_ASCII = {\n        b'\\x80' : 'EUR',\n        b'\\x81' : ' ',\n        b'\\x82' : ',',\n        b'\\x83' : 'f',\n        b'\\x84' : ',,',\n        b'\\x85' : '...',\n        b'\\x86' : '+',\n        b'\\x87' : '++',\n        b'\\x88' : '^',\n        b'\\x89' : '%',\n        b'\\x8a' : 'S',\n        b'\\x8b' : '<',\n        b'\\x8c' : 'OE',\n        b'\\x8d' : '?',\n        b'\\x8e' : 'Z',\n        b'\\x8f' : '?',\n        b'\\x90' : '?',\n        b'\\x91' : \"'\",\n        b'\\x92' : \"'\",\n        b'\\x93' : '\"',\n        b'\\x94' : '\"',\n        b'\\x95' : '*',\n        b'\\x96' : '-',\n        b'\\x97' : '--',\n        b'\\x98' : '~',\n        b'\\x99' : '(TM)',\n        b'\\x9a' : 's',\n        b'\\x9b' : '>',\n        b'\\x9c' : 'oe',\n        b'\\x9d' : '?',\n        b'\\x9e' : 'z',\n        b'\\x9f' : 'Y',\n        b'\\xa0' : ' ',\n        b'\\xa1' : '!',\n        b'\\xa2' : 'c',\n        b'\\xa3' : 'GBP',\n        b'\\xa4' : '$', #This approximation is especially parochial--this is the\n                       #generic currency symbol.\n        b'\\xa5' : 'YEN',\n        b'\\xa6' : '|',\n        b'\\xa7' : 'S',\n        b'\\xa8' : '..',\n        b'\\xa9' : '',\n        b'\\xaa' : '(th)',\n        b'\\xab' : '<<',\n        b'\\xac' : '!',\n        b'\\xad' : ' ',\n        b'\\xae' : '(R)',\n        b'\\xaf' : '-',\n        b'\\xb0' : 'o',\n        b'\\xb1' : '+-',\n        b'\\xb2' : '2',\n        b'\\xb3' : '3',\n        b'\\xb4' : (\"'\", 'acute'),\n        b'\\xb5' : 'u',\n        b'\\xb6' : 'P',\n        b'\\xb7' : '*',\n        b'\\xb8' : ',',\n        b'\\xb9' : '1',\n        b'\\xba' : '(th)',\n        b'\\xbb' : '>>',\n        b'\\xbc' : '1/4',\n        b'\\xbd' : '1/2',\n        b'\\xbe' : '3/4',\n        b'\\xbf' : '?',\n        b'\\xc0' : 'A',\n        b'\\xc1' : 'A',\n        b'\\xc2' : 'A',\n        b'\\xc3' : 'A',\n        b'\\xc4' : 'A',\n        b'\\xc5' : 'A',\n        b'\\xc6' : 'AE',\n        b'\\xc7' : 'C',\n        b'\\xc8' : 'E',\n        b'\\xc9' : 'E',\n        b'\\xca' : 'E',\n        b'\\xcb' : 'E',\n        b'\\xcc' : 'I',\n        b'\\xcd' : 'I',\n        b'\\xce' : 'I',\n        b'\\xcf' : 'I',\n        b'\\xd0' : 'D',\n        b'\\xd1' : 'N',\n        b'\\xd2' : 'O',\n        b'\\xd3' : 'O',\n        b'\\xd4' : 'O',\n        b'\\xd5' : 'O',\n        b'\\xd6' : 'O',\n        b'\\xd7' : '*',\n        b'\\xd8' : 'O',\n        b'\\xd9' : 'U',\n        b'\\xda' : 'U',\n        b'\\xdb' : 'U',\n        b'\\xdc' : 'U',\n        b'\\xdd' : 'Y',\n        b'\\xde' : 'b',\n        b'\\xdf' : 'B',\n        b'\\xe0' : 'a',\n        b'\\xe1' : 'a',\n        b'\\xe2' : 'a',\n        b'\\xe3' : 'a',\n        b'\\xe4' : 'a',\n        b'\\xe5' : 'a',\n        b'\\xe6' : 'ae',\n        b'\\xe7' : 'c',\n        b'\\xe8' : 'e',\n        b'\\xe9' : 'e',\n        b'\\xea' : 'e',\n        b'\\xeb' : 'e',\n        b'\\xec' : 'i',\n        b'\\xed' : 'i',\n        b'\\xee' : 'i',\n        b'\\xef' : 'i',\n        b'\\xf0' : 'o',\n        b'\\xf1' : 'n',\n        b'\\xf2' : 'o',\n        b'\\xf3' : 'o',\n        b'\\xf4' : 'o',\n        b'\\xf5' : 'o',\n        b'\\xf6' : 'o',\n        b'\\xf7' : '/',\n        b'\\xf8' : 'o',\n        b'\\xf9' : 'u',\n        b'\\xfa' : 'u',\n        b'\\xfb' : 'u',\n        b'\\xfc' : 'u',\n        b'\\xfd' : 'y',\n        b'\\xfe' : 'b',\n        b'\\xff' : 'y',\n        }\n\n    # A map used when removing rogue Windows-1252/ISO-8859-1\n    # characters in otherwise UTF-8 documents.\n    #\n    # Note that \\x81, \\x8d, \\x8f, \\x90, and \\x9d are undefined in\n    # Windows-1252.\n    WINDOWS_1252_TO_UTF8 = {\n        0x80 : b'\\xe2\\x82\\xac', # €\n        0x82 : b'\\xe2\\x80\\x9a', # ‚\n        0x83 : b'\\xc6\\x92',     # ƒ\n        0x84 : b'\\xe2\\x80\\x9e', # „\n        0x85 : b'\\xe2\\x80\\xa6', # …\n        0x86 : b'\\xe2\\x80\\xa0', # †\n        0x87 : b'\\xe2\\x80\\xa1', # ‡\n        0x88 : b'\\xcb\\x86',     # ˆ\n        0x89 : b'\\xe2\\x80\\xb0', # ‰\n        0x8a : b'\\xc5\\xa0',     # Š\n        0x8b : b'\\xe2\\x80\\xb9', # ‹\n        0x8c : b'\\xc5\\x92',     # Œ\n        0x8e : b'\\xc5\\xbd',     # Ž\n        0x91 : b'\\xe2\\x80\\x98', # ‘\n        0x92 : b'\\xe2\\x80\\x99', # ’\n        0x93 : b'\\xe2\\x80\\x9c', # “\n        0x94 : b'\\xe2\\x80\\x9d', # ”\n        0x95 : b'\\xe2\\x80\\xa2', # •\n        0x96 : b'\\xe2\\x80\\x93', # –\n        0x97 : b'\\xe2\\x80\\x94', # —\n        0x98 : b'\\xcb\\x9c',     # ˜\n        0x99 : b'\\xe2\\x84\\xa2', # ™\n        0x9a : b'\\xc5\\xa1',     # š\n        0x9b : b'\\xe2\\x80\\xba', # ›\n        0x9c : b'\\xc5\\x93',     # œ\n        0x9e : b'\\xc5\\xbe',     # ž\n        0x9f : b'\\xc5\\xb8',     # Ÿ\n        0xa0 : b'\\xc2\\xa0',     #  \n        0xa1 : b'\\xc2\\xa1',     # ¡\n        0xa2 : b'\\xc2\\xa2',     # ¢\n        0xa3 : b'\\xc2\\xa3',     # £\n        0xa4 : b'\\xc2\\xa4',     # ¤\n        0xa5 : b'\\xc2\\xa5',     # ¥\n        0xa6 : b'\\xc2\\xa6',     # ¦\n        0xa7 : b'\\xc2\\xa7',     # §\n        0xa8 : b'\\xc2\\xa8',     # ¨\n        0xa9 : b'\\xc2\\xa9',     # ©\n        0xaa : b'\\xc2\\xaa',     # ª\n        0xab : b'\\xc2\\xab',     # «\n        0xac : b'\\xc2\\xac',     # ¬\n        0xad : b'\\xc2\\xad',     # ­\n        0xae : b'\\xc2\\xae',     # ®\n        0xaf : b'\\xc2\\xaf',     # ¯\n        0xb0 : b'\\xc2\\xb0',     # °\n        0xb1 : b'\\xc2\\xb1',     # ±\n        0xb2 : b'\\xc2\\xb2',     # ²\n        0xb3 : b'\\xc2\\xb3',     # ³\n        0xb4 : b'\\xc2\\xb4',     # ´\n        0xb5 : b'\\xc2\\xb5',     # µ\n        0xb6 : b'\\xc2\\xb6',     # ¶\n        0xb7 : b'\\xc2\\xb7',     # ·\n        0xb8 : b'\\xc2\\xb8',     # ¸\n        0xb9 : b'\\xc2\\xb9',     # ¹\n        0xba : b'\\xc2\\xba',     # º\n        0xbb : b'\\xc2\\xbb',     # »\n        0xbc : b'\\xc2\\xbc',     # ¼\n        0xbd : b'\\xc2\\xbd',     # ½\n        0xbe : b'\\xc2\\xbe',     # ¾\n        0xbf : b'\\xc2\\xbf',     # ¿\n        0xc0 : b'\\xc3\\x80',     # À\n        0xc1 : b'\\xc3\\x81',     # Á\n        0xc2 : b'\\xc3\\x82',     # Â\n        0xc3 : b'\\xc3\\x83',     # Ã\n        0xc4 : b'\\xc3\\x84',     # Ä\n        0xc5 : b'\\xc3\\x85',     # Å\n        0xc6 : b'\\xc3\\x86',     # Æ\n        0xc7 : b'\\xc3\\x87',     # Ç\n        0xc8 : b'\\xc3\\x88',     # È\n        0xc9 : b'\\xc3\\x89',     # É\n        0xca : b'\\xc3\\x8a',     # Ê\n        0xcb : b'\\xc3\\x8b',     # Ë\n        0xcc : b'\\xc3\\x8c',     # Ì\n        0xcd : b'\\xc3\\x8d',     # Í\n        0xce : b'\\xc3\\x8e',     # Î\n        0xcf : b'\\xc3\\x8f',     # Ï\n        0xd0 : b'\\xc3\\x90',     # Ð\n        0xd1 : b'\\xc3\\x91',     # Ñ\n        0xd2 : b'\\xc3\\x92',     # Ò\n        0xd3 : b'\\xc3\\x93',     # Ó\n        0xd4 : b'\\xc3\\x94',     # Ô\n        0xd5 : b'\\xc3\\x95',     # Õ\n        0xd6 : b'\\xc3\\x96',     # Ö\n        0xd7 : b'\\xc3\\x97',     # ×\n        0xd8 : b'\\xc3\\x98',     # Ø\n        0xd9 : b'\\xc3\\x99',     # Ù\n        0xda : b'\\xc3\\x9a',     # Ú\n        0xdb : b'\\xc3\\x9b',     # Û\n        0xdc : b'\\xc3\\x9c',     # Ü\n        0xdd : b'\\xc3\\x9d',     # Ý\n        0xde : b'\\xc3\\x9e',     # Þ\n        0xdf : b'\\xc3\\x9f',     # ß\n        0xe0 : b'\\xc3\\xa0',     # à\n        0xe1 : b'\\xa1',         # á\n        0xe2 : b'\\xc3\\xa2',     # â\n        0xe3 : b'\\xc3\\xa3',     # ã\n        0xe4 : b'\\xc3\\xa4',     # ä\n        0xe5 : b'\\xc3\\xa5',     # å\n        0xe6 : b'\\xc3\\xa6',     # æ\n        0xe7 : b'\\xc3\\xa7',     # ç\n        0xe8 : b'\\xc3\\xa8',     # è\n        0xe9 : b'\\xc3\\xa9',     # é\n        0xea : b'\\xc3\\xaa',     # ê\n        0xeb : b'\\xc3\\xab',     # ë\n        0xec : b'\\xc3\\xac',     # ì\n        0xed : b'\\xc3\\xad',     # í\n        0xee : b'\\xc3\\xae',     # î\n        0xef : b'\\xc3\\xaf',     # ï\n        0xf0 : b'\\xc3\\xb0',     # ð\n        0xf1 : b'\\xc3\\xb1',     # ñ\n        0xf2 : b'\\xc3\\xb2',     # ò\n        0xf3 : b'\\xc3\\xb3',     # ó\n        0xf4 : b'\\xc3\\xb4',     # ô\n        0xf5 : b'\\xc3\\xb5',     # õ\n        0xf6 : b'\\xc3\\xb6',     # ö\n        0xf7 : b'\\xc3\\xb7',     # ÷\n        0xf8 : b'\\xc3\\xb8',     # ø\n        0xf9 : b'\\xc3\\xb9',     # ù\n        0xfa : b'\\xc3\\xba',     # ú\n        0xfb : b'\\xc3\\xbb',     # û\n        0xfc : b'\\xc3\\xbc',     # ü\n        0xfd : b'\\xc3\\xbd',     # ý\n        0xfe : b'\\xc3\\xbe',     # þ\n        }\n\n    MULTIBYTE_MARKERS_AND_SIZES = [\n        (0xc2, 0xdf, 2), # 2-byte characters start with a byte C2-DF\n        (0xe0, 0xef, 3), # 3-byte characters start with E0-EF\n        (0xf0, 0xf4, 4), # 4-byte characters start with F0-F4\n        ]\n\n    FIRST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[0][0]\n    LAST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[-1][1]\n\n    @classmethod\n    def detwingle(cls, in_bytes, main_encoding=\"utf8\",\n                  embedded_encoding=\"windows-1252\"):\n        \"\"\"Fix characters from one encoding embedded in some other encoding.\n\n        Currently the only situation supported is Windows-1252 (or its\n        subset ISO-8859-1), embedded in UTF-8.\n\n        :param in_bytes: A bytestring that you suspect contains\n            characters from multiple encodings. Note that this _must_\n            be a bytestring. If you've already converted the document\n            to Unicode, you're too late.\n        :param main_encoding: The primary encoding of `in_bytes`.\n        :param embedded_encoding: The encoding that was used to embed characters\n            in the main document.\n        :return: A bytestring in which `embedded_encoding`\n          characters have been converted to their `main_encoding`\n          equivalents.\n        \"\"\"\n        if embedded_encoding.replace('_', '-').lower() not in (\n            'windows-1252', 'windows_1252'):\n            raise NotImplementedError(\n                \"Windows-1252 and ISO-8859-1 are the only currently supported \"\n                \"embedded encodings.\")\n\n        if main_encoding.lower() not in ('utf8', 'utf-8'):\n            raise NotImplementedError(\n                \"UTF-8 is the only currently supported main encoding.\")\n\n        byte_chunks = []\n\n        chunk_start = 0\n        pos = 0\n        while pos < len(in_bytes):\n            byte = in_bytes[pos]\n            if not isinstance(byte, int):\n                # Python 2.x\n                byte = ord(byte)\n            if (byte >= cls.FIRST_MULTIBYTE_MARKER\n                and byte <= cls.LAST_MULTIBYTE_MARKER):\n                # This is the start of a UTF-8 multibyte character. Skip\n                # to the end.\n                for start, end, size in cls.MULTIBYTE_MARKERS_AND_SIZES:\n                    if byte >= start and byte <= end:\n                        pos += size\n                        break\n            elif byte >= 0x80 and byte in cls.WINDOWS_1252_TO_UTF8:\n                # We found a Windows-1252 character!\n                # Save the string up to this point as a chunk.\n                byte_chunks.append(in_bytes[chunk_start:pos])\n\n                # Now translate the Windows-1252 character into UTF-8\n                # and add it as another, one-byte chunk.\n                byte_chunks.append(cls.WINDOWS_1252_TO_UTF8[byte])\n                pos += 1\n                chunk_start = pos\n            else:\n                # Go on to the next character.\n                pos += 1\n        if chunk_start == 0:\n            # The string is unchanged.\n            return in_bytes\n        else:\n            # Store the final chunk.\n            byte_chunks.append(in_bytes[chunk_start:])\n        return b''.join(byte_chunks)\n\n"},"hash":"8VgnQcZCsf"}