{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:chardet:charsetprober.py","body":"######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is Mozilla Universal charset detector code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 2001\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#   Shy Shalom - original C code\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nimport logging\nimport re\nfrom typing import Optional, Union\n\nfrom .enums import LanguageFilter, ProbingState\n\nINTERNATIONAL_WORDS_PATTERN = re.compile(\n    b\"[a-zA-Z]*[\\x80-\\xFF]+[a-zA-Z]*[^a-zA-Z\\x80-\\xFF]?\"\n)\n\n\nclass CharSetProber:\n\n    SHORTCUT_THRESHOLD = 0.95\n\n    def __init__(self, lang_filter: LanguageFilter = LanguageFilter.NONE) -> None:\n        self._state = ProbingState.DETECTING\n        self.active = True\n        self.lang_filter = lang_filter\n        self.logger = logging.getLogger(__name__)\n\n    def reset(self) -> None:\n        self._state = ProbingState.DETECTING\n\n    @property\n    def charset_name(self) -> Optional[str]:\n        return None\n\n    @property\n    def language(self) -> Optional[str]:\n        raise NotImplementedError\n\n    def feed(self, byte_str: Union[bytes, bytearray]) -> ProbingState:\n        raise NotImplementedError\n\n    @property\n    def state(self) -> ProbingState:\n        return self._state\n\n    def get_confidence(self) -> float:\n        return 0.0\n\n    @staticmethod\n    def filter_high_byte_only(buf: Union[bytes, bytearray]) -> bytes:\n        buf = re.sub(b\"([\\x00-\\x7F])+\", b\" \", buf)\n        return buf\n\n    @staticmethod\n    def filter_international_words(buf: Union[bytes, bytearray]) -> bytearray:\n        \"\"\"\n        We define three types of bytes:\n        alphabet: english alphabets [a-zA-Z]\n        international: international characters [\\x80-\\xFF]\n        marker: everything else [^a-zA-Z\\x80-\\xFF]\n        The input buffer can be thought to contain a series of words delimited\n        by markers. This function works to filter all words that contain at\n        least one international character. All contiguous sequences of markers\n        are replaced by a single space ascii character.\n        This filter applies to all scripts which do not use English characters.\n        \"\"\"\n        filtered = bytearray()\n\n        # This regex expression filters out only words that have at-least one\n        # international character. The word may include one marker character at\n        # the end.\n        words = INTERNATIONAL_WORDS_PATTERN.findall(buf)\n\n        for word in words:\n            filtered.extend(word[:-1])\n\n            # If the last character in the word is a marker, replace it with a\n            # space as markers shouldn't affect our analysis (they are used\n            # similarly across all languages and may thus have similar\n            # frequencies).\n            last_char = word[-1:]\n            if not last_char.isalpha() and last_char < b\"\\x80\":\n                last_char = b\" \"\n            filtered.extend(last_char)\n\n        return filtered\n\n    @staticmethod\n    def remove_xml_tags(buf: Union[bytes, bytearray]) -> bytes:\n        \"\"\"\n        Returns a copy of ``buf`` that retains only the sequences of English\n        alphabet and high byte characters that are not between <> characters.\n        This filter can be applied to all scripts which contain both English\n        characters and extended ASCII characters, but is currently only used by\n        ``Latin1Prober``.\n        \"\"\"\n        filtered = bytearray()\n        in_tag = False\n        prev = 0\n        buf = memoryview(buf).cast(\"c\")\n\n        for curr, buf_char in enumerate(buf):\n            # Check if we're coming out of or entering an XML tag\n\n            # https://github.com/python/typeshed/issues/8182\n            if buf_char == b\">\":  # type: ignore[comparison-overlap]\n                prev = curr + 1\n                in_tag = False\n            # https://github.com/python/typeshed/issues/8182\n            elif buf_char == b\"<\":  # type: ignore[comparison-overlap]\n                if curr > prev and not in_tag:\n                    # Keep everything after last non-extended-ASCII,\n                    # non-alphabetic character\n                    filtered.extend(buf[prev:curr])\n                    # Output a space to delimit stretch we kept\n                    filtered.extend(b\" \")\n                in_tag = True\n\n        # If we're not in a tag...\n        if not in_tag:\n            # Keep everything after last non-extended-ASCII, non-alphabetic\n            # character\n            filtered.extend(buf[prev:])\n\n        return filtered\n"},"hash":"W63IRhLlTe"}