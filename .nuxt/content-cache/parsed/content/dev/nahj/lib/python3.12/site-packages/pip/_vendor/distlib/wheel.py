{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:distlib:wheel.py","body":"# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2013-2023 Vinay Sajip.\n# Licensed to the Python Software Foundation under a contributor agreement.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\nfrom __future__ import unicode_literals\n\nimport base64\nimport codecs\nimport datetime\nfrom email import message_from_file\nimport hashlib\nimport json\nimport logging\nimport os\nimport posixpath\nimport re\nimport shutil\nimport sys\nimport tempfile\nimport zipfile\n\nfrom . import __version__, DistlibException\nfrom .compat import sysconfig, ZipFile, fsdecode, text_type, filter\nfrom .database import InstalledDistribution\nfrom .metadata import Metadata, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME\nfrom .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache,\n                   cached_property, get_cache_base, read_exports, tempdir,\n                   get_platform)\nfrom .version import NormalizedVersion, UnsupportedVersionError\n\nlogger = logging.getLogger(__name__)\n\ncache = None  # created when needed\n\nif hasattr(sys, 'pypy_version_info'):  # pragma: no cover\n    IMP_PREFIX = 'pp'\nelif sys.platform.startswith('java'):  # pragma: no cover\n    IMP_PREFIX = 'jy'\nelif sys.platform == 'cli':  # pragma: no cover\n    IMP_PREFIX = 'ip'\nelse:\n    IMP_PREFIX = 'cp'\n\nVER_SUFFIX = sysconfig.get_config_var('py_version_nodot')\nif not VER_SUFFIX:  # pragma: no cover\n    VER_SUFFIX = '%s%s' % sys.version_info[:2]\nPYVER = 'py' + VER_SUFFIX\nIMPVER = IMP_PREFIX + VER_SUFFIX\n\nARCH = get_platform().replace('-', '_').replace('.', '_')\n\nABI = sysconfig.get_config_var('SOABI')\nif ABI and ABI.startswith('cpython-'):\n    ABI = ABI.replace('cpython-', 'cp').split('-')[0]\nelse:\n\n    def _derive_abi():\n        parts = ['cp', VER_SUFFIX]\n        if sysconfig.get_config_var('Py_DEBUG'):\n            parts.append('d')\n        if IMP_PREFIX == 'cp':\n            vi = sys.version_info[:2]\n            if vi < (3, 8):\n                wpm = sysconfig.get_config_var('WITH_PYMALLOC')\n                if wpm is None:\n                    wpm = True\n                if wpm:\n                    parts.append('m')\n                if vi < (3, 3):\n                    us = sysconfig.get_config_var('Py_UNICODE_SIZE')\n                    if us == 4 or (us is None and sys.maxunicode == 0x10FFFF):\n                        parts.append('u')\n        return ''.join(parts)\n\n    ABI = _derive_abi()\n    del _derive_abi\n\nFILENAME_RE = re.compile(\n    r'''\n(?P<nm>[^-]+)\n-(?P<vn>\\d+[^-]*)\n(-(?P<bn>\\d+[^-]*))?\n-(?P<py>\\w+\\d+(\\.\\w+\\d+)*)\n-(?P<bi>\\w+)\n-(?P<ar>\\w+(\\.\\w+)*)\n\\.whl$\n''', re.IGNORECASE | re.VERBOSE)\n\nNAME_VERSION_RE = re.compile(\n    r'''\n(?P<nm>[^-]+)\n-(?P<vn>\\d+[^-]*)\n(-(?P<bn>\\d+[^-]*))?$\n''', re.IGNORECASE | re.VERBOSE)\n\nSHEBANG_RE = re.compile(br'\\s*#![^\\r\\n]*')\nSHEBANG_DETAIL_RE = re.compile(br'^(\\s*#!(\"[^\"]+\"|\\S+))\\s+(.*)$')\nSHEBANG_PYTHON = b'#!python'\nSHEBANG_PYTHONW = b'#!pythonw'\n\nif os.sep == '/':\n    to_posix = lambda o: o\nelse:\n    to_posix = lambda o: o.replace(os.sep, '/')\n\nif sys.version_info[0] < 3:\n    import imp\nelse:\n    imp = None\n    import importlib.machinery\n    import importlib.util\n\n\ndef _get_suffixes():\n    if imp:\n        return [s[0] for s in imp.get_suffixes()]\n    else:\n        return importlib.machinery.EXTENSION_SUFFIXES\n\n\ndef _load_dynamic(name, path):\n    # https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n    if imp:\n        return imp.load_dynamic(name, path)\n    else:\n        spec = importlib.util.spec_from_file_location(name, path)\n        module = importlib.util.module_from_spec(spec)\n        sys.modules[name] = module\n        spec.loader.exec_module(module)\n        return module\n\n\nclass Mounter(object):\n\n    def __init__(self):\n        self.impure_wheels = {}\n        self.libs = {}\n\n    def add(self, pathname, extensions):\n        self.impure_wheels[pathname] = extensions\n        self.libs.update(extensions)\n\n    def remove(self, pathname):\n        extensions = self.impure_wheels.pop(pathname)\n        for k, v in extensions:\n            if k in self.libs:\n                del self.libs[k]\n\n    def find_module(self, fullname, path=None):\n        if fullname in self.libs:\n            result = self\n        else:\n            result = None\n        return result\n\n    def load_module(self, fullname):\n        if fullname in sys.modules:\n            result = sys.modules[fullname]\n        else:\n            if fullname not in self.libs:\n                raise ImportError('unable to find extension for %s' % fullname)\n            result = _load_dynamic(fullname, self.libs[fullname])\n            result.__loader__ = self\n            parts = fullname.rsplit('.', 1)\n            if len(parts) > 1:\n                result.__package__ = parts[0]\n        return result\n\n\n_hook = Mounter()\n\n\nclass Wheel(object):\n    \"\"\"\n    Class to build and install from Wheel files (PEP 427).\n    \"\"\"\n\n    wheel_version = (1, 1)\n    hash_kind = 'sha256'\n\n    def __init__(self, filename=None, sign=False, verify=False):\n        \"\"\"\n        Initialise an instance using a (valid) filename.\n        \"\"\"\n        self.sign = sign\n        self.should_verify = verify\n        self.buildver = ''\n        self.pyver = [PYVER]\n        self.abi = ['none']\n        self.arch = ['any']\n        self.dirname = os.getcwd()\n        if filename is None:\n            self.name = 'dummy'\n            self.version = '0.1'\n            self._filename = self.filename\n        else:\n            m = NAME_VERSION_RE.match(filename)\n            if m:\n                info = m.groupdict('')\n                self.name = info['nm']\n                # Reinstate the local version separator\n                self.version = info['vn'].replace('_', '-')\n                self.buildver = info['bn']\n                self._filename = self.filename\n            else:\n                dirname, filename = os.path.split(filename)\n                m = FILENAME_RE.match(filename)\n                if not m:\n                    raise DistlibException('Invalid name or '\n                                           'filename: %r' % filename)\n                if dirname:\n                    self.dirname = os.path.abspath(dirname)\n                self._filename = filename\n                info = m.groupdict('')\n                self.name = info['nm']\n                self.version = info['vn']\n                self.buildver = info['bn']\n                self.pyver = info['py'].split('.')\n                self.abi = info['bi'].split('.')\n                self.arch = info['ar'].split('.')\n\n    @property\n    def filename(self):\n        \"\"\"\n        Build and return a filename from the various components.\n        \"\"\"\n        if self.buildver:\n            buildver = '-' + self.buildver\n        else:\n            buildver = ''\n        pyver = '.'.join(self.pyver)\n        abi = '.'.join(self.abi)\n        arch = '.'.join(self.arch)\n        # replace - with _ as a local version separator\n        version = self.version.replace('-', '_')\n        return '%s-%s%s-%s-%s-%s.whl' % (self.name, version, buildver, pyver,\n                                         abi, arch)\n\n    @property\n    def exists(self):\n        path = os.path.join(self.dirname, self.filename)\n        return os.path.isfile(path)\n\n    @property\n    def tags(self):\n        for pyver in self.pyver:\n            for abi in self.abi:\n                for arch in self.arch:\n                    yield pyver, abi, arch\n\n    @cached_property\n    def metadata(self):\n        pathname = os.path.join(self.dirname, self.filename)\n        name_ver = '%s-%s' % (self.name, self.version)\n        info_dir = '%s.dist-info' % name_ver\n        wrapper = codecs.getreader('utf-8')\n        with ZipFile(pathname, 'r') as zf:\n            self.get_wheel_metadata(zf)\n            # wv = wheel_metadata['Wheel-Version'].split('.', 1)\n            # file_version = tuple([int(i) for i in wv])\n            # if file_version < (1, 1):\n            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME,\n            # LEGACY_METADATA_FILENAME]\n            # else:\n            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME]\n            fns = [WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME]\n            result = None\n            for fn in fns:\n                try:\n                    metadata_filename = posixpath.join(info_dir, fn)\n                    with zf.open(metadata_filename) as bf:\n                        wf = wrapper(bf)\n                        result = Metadata(fileobj=wf)\n                        if result:\n                            break\n                except KeyError:\n                    pass\n            if not result:\n                raise ValueError('Invalid wheel, because metadata is '\n                                 'missing: looked in %s' % ', '.join(fns))\n        return result\n\n    def get_wheel_metadata(self, zf):\n        name_ver = '%s-%s' % (self.name, self.version)\n        info_dir = '%s.dist-info' % name_ver\n        metadata_filename = posixpath.join(info_dir, 'WHEEL')\n        with zf.open(metadata_filename) as bf:\n            wf = codecs.getreader('utf-8')(bf)\n            message = message_from_file(wf)\n        return dict(message)\n\n    @cached_property\n    def info(self):\n        pathname = os.path.join(self.dirname, self.filename)\n        with ZipFile(pathname, 'r') as zf:\n            result = self.get_wheel_metadata(zf)\n        return result\n\n    def process_shebang(self, data):\n        m = SHEBANG_RE.match(data)\n        if m:\n            end = m.end()\n            shebang, data_after_shebang = data[:end], data[end:]\n            # Preserve any arguments after the interpreter\n            if b'pythonw' in shebang.lower():\n                shebang_python = SHEBANG_PYTHONW\n            else:\n                shebang_python = SHEBANG_PYTHON\n            m = SHEBANG_DETAIL_RE.match(shebang)\n            if m:\n                args = b' ' + m.groups()[-1]\n            else:\n                args = b''\n            shebang = shebang_python + args\n            data = shebang + data_after_shebang\n        else:\n            cr = data.find(b'\\r')\n            lf = data.find(b'\\n')\n            if cr < 0 or cr > lf:\n                term = b'\\n'\n            else:\n                if data[cr:cr + 2] == b'\\r\\n':\n                    term = b'\\r\\n'\n                else:\n                    term = b'\\r'\n            data = SHEBANG_PYTHON + term + data\n        return data\n\n    def get_hash(self, data, hash_kind=None):\n        if hash_kind is None:\n            hash_kind = self.hash_kind\n        try:\n            hasher = getattr(hashlib, hash_kind)\n        except AttributeError:\n            raise DistlibException('Unsupported hash algorithm: %r' %\n                                   hash_kind)\n        result = hasher(data).digest()\n        result = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')\n        return hash_kind, result\n\n    def write_record(self, records, record_path, archive_record_path):\n        records = list(records)  # make a copy, as mutated\n        records.append((archive_record_path, '', ''))\n        with CSVWriter(record_path) as writer:\n            for row in records:\n                writer.writerow(row)\n\n    def write_records(self, info, libdir, archive_paths):\n        records = []\n        distinfo, info_dir = info\n        # hasher = getattr(hashlib, self.hash_kind)\n        for ap, p in archive_paths:\n            with open(p, 'rb') as f:\n                data = f.read()\n            digest = '%s=%s' % self.get_hash(data)\n            size = os.path.getsize(p)\n            records.append((ap, digest, size))\n\n        p = os.path.join(distinfo, 'RECORD')\n        ap = to_posix(os.path.join(info_dir, 'RECORD'))\n        self.write_record(records, p, ap)\n        archive_paths.append((ap, p))\n\n    def build_zip(self, pathname, archive_paths):\n        with ZipFile(pathname, 'w', zipfile.ZIP_DEFLATED) as zf:\n            for ap, p in archive_paths:\n                logger.debug('Wrote %s to %s in wheel', p, ap)\n                zf.write(p, ap)\n\n    def build(self, paths, tags=None, wheel_version=None):\n        \"\"\"\n        Build a wheel from files in specified paths, and use any specified tags\n        when determining the name of the wheel.\n        \"\"\"\n        if tags is None:\n            tags = {}\n\n        libkey = list(filter(lambda o: o in paths, ('purelib', 'platlib')))[0]\n        if libkey == 'platlib':\n            is_pure = 'false'\n            default_pyver = [IMPVER]\n            default_abi = [ABI]\n            default_arch = [ARCH]\n        else:\n            is_pure = 'true'\n            default_pyver = [PYVER]\n            default_abi = ['none']\n            default_arch = ['any']\n\n        self.pyver = tags.get('pyver', default_pyver)\n        self.abi = tags.get('abi', default_abi)\n        self.arch = tags.get('arch', default_arch)\n\n        libdir = paths[libkey]\n\n        name_ver = '%s-%s' % (self.name, self.version)\n        data_dir = '%s.data' % name_ver\n        info_dir = '%s.dist-info' % name_ver\n\n        archive_paths = []\n\n        # First, stuff which is not in site-packages\n        for key in ('data', 'headers', 'scripts'):\n            if key not in paths:\n                continue\n            path = paths[key]\n            if os.path.isdir(path):\n                for root, dirs, files in os.walk(path):\n                    for fn in files:\n                        p = fsdecode(os.path.join(root, fn))\n                        rp = os.path.relpath(p, path)\n                        ap = to_posix(os.path.join(data_dir, key, rp))\n                        archive_paths.append((ap, p))\n                        if key == 'scripts' and not p.endswith('.exe'):\n                            with open(p, 'rb') as f:\n                                data = f.read()\n                            data = self.process_shebang(data)\n                            with open(p, 'wb') as f:\n                                f.write(data)\n\n        # Now, stuff which is in site-packages, other than the\n        # distinfo stuff.\n        path = libdir\n        distinfo = None\n        for root, dirs, files in os.walk(path):\n            if root == path:\n                # At the top level only, save distinfo for later\n                # and skip it for now\n                for i, dn in enumerate(dirs):\n                    dn = fsdecode(dn)\n                    if dn.endswith('.dist-info'):\n                        distinfo = os.path.join(root, dn)\n                        del dirs[i]\n                        break\n                assert distinfo, '.dist-info directory expected, not found'\n\n            for fn in files:\n                # comment out next suite to leave .pyc files in\n                if fsdecode(fn).endswith(('.pyc', '.pyo')):\n                    continue\n                p = os.path.join(root, fn)\n                rp = to_posix(os.path.relpath(p, path))\n                archive_paths.append((rp, p))\n\n        # Now distinfo. Assumed to be flat, i.e. os.listdir is enough.\n        files = os.listdir(distinfo)\n        for fn in files:\n            if fn not in ('RECORD', 'INSTALLER', 'SHARED', 'WHEEL'):\n                p = fsdecode(os.path.join(distinfo, fn))\n                ap = to_posix(os.path.join(info_dir, fn))\n                archive_paths.append((ap, p))\n\n        wheel_metadata = [\n            'Wheel-Version: %d.%d' % (wheel_version or self.wheel_version),\n            'Generator: distlib %s' % __version__,\n            'Root-Is-Purelib: %s' % is_pure,\n        ]\n        for pyver, abi, arch in self.tags:\n            wheel_metadata.append('Tag: %s-%s-%s' % (pyver, abi, arch))\n        p = os.path.join(distinfo, 'WHEEL')\n        with open(p, 'w') as f:\n            f.write('\\n'.join(wheel_metadata))\n        ap = to_posix(os.path.join(info_dir, 'WHEEL'))\n        archive_paths.append((ap, p))\n\n        # sort the entries by archive path. Not needed by any spec, but it\n        # keeps the archive listing and RECORD tidier than they would otherwise\n        # be. Use the number of path segments to keep directory entries together,\n        # and keep the dist-info stuff at the end.\n        def sorter(t):\n            ap = t[0]\n            n = ap.count('/')\n            if '.dist-info' in ap:\n                n += 10000\n            return (n, ap)\n\n        archive_paths = sorted(archive_paths, key=sorter)\n\n        # Now, at last, RECORD.\n        # Paths in here are archive paths - nothing else makes sense.\n        self.write_records((distinfo, info_dir), libdir, archive_paths)\n        # Now, ready to build the zip file\n        pathname = os.path.join(self.dirname, self.filename)\n        self.build_zip(pathname, archive_paths)\n        return pathname\n\n    def skip_entry(self, arcname):\n        \"\"\"\n        Determine whether an archive entry should be skipped when verifying\n        or installing.\n        \"\"\"\n        # The signature file won't be in RECORD,\n        # and we  don't currently don't do anything with it\n        # We also skip directories, as they won't be in RECORD\n        # either. See:\n        #\n        # https://github.com/pypa/wheel/issues/294\n        # https://github.com/pypa/wheel/issues/287\n        # https://github.com/pypa/wheel/pull/289\n        #\n        return arcname.endswith(('/', '/RECORD.jws'))\n\n    def install(self, paths, maker, **kwargs):\n        \"\"\"\n        Install a wheel to the specified paths. If kwarg ``warner`` is\n        specified, it should be a callable, which will be called with two\n        tuples indicating the wheel version of this software and the wheel\n        version in the file, if there is a discrepancy in the versions.\n        This can be used to issue any warnings to raise any exceptions.\n        If kwarg ``lib_only`` is True, only the purelib/platlib files are\n        installed, and the headers, scripts, data and dist-info metadata are\n        not written. If kwarg ``bytecode_hashed_invalidation`` is True, written\n        bytecode will try to use file-hash based invalidation (PEP-552) on\n        supported interpreter versions (CPython 2.7+).\n\n        The return value is a :class:`InstalledDistribution` instance unless\n        ``options.lib_only`` is True, in which case the return value is ``None``.\n        \"\"\"\n\n        dry_run = maker.dry_run\n        warner = kwargs.get('warner')\n        lib_only = kwargs.get('lib_only', False)\n        bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation',\n                                            False)\n\n        pathname = os.path.join(self.dirname, self.filename)\n        name_ver = '%s-%s' % (self.name, self.version)\n        data_dir = '%s.data' % name_ver\n        info_dir = '%s.dist-info' % name_ver\n\n        metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)\n        wheel_metadata_name = posixpath.join(info_dir, 'WHEEL')\n        record_name = posixpath.join(info_dir, 'RECORD')\n\n        wrapper = codecs.getreader('utf-8')\n\n        with ZipFile(pathname, 'r') as zf:\n            with zf.open(wheel_metadata_name) as bwf:\n                wf = wrapper(bwf)\n                message = message_from_file(wf)\n            wv = message['Wheel-Version'].split('.', 1)\n            file_version = tuple([int(i) for i in wv])\n            if (file_version != self.wheel_version) and warner:\n                warner(self.wheel_version, file_version)\n\n            if message['Root-Is-Purelib'] == 'true':\n                libdir = paths['purelib']\n            else:\n                libdir = paths['platlib']\n\n            records = {}\n            with zf.open(record_name) as bf:\n                with CSVReader(stream=bf) as reader:\n                    for row in reader:\n                        p = row[0]\n                        records[p] = row\n\n            data_pfx = posixpath.join(data_dir, '')\n            info_pfx = posixpath.join(info_dir, '')\n            script_pfx = posixpath.join(data_dir, 'scripts', '')\n\n            # make a new instance rather than a copy of maker's,\n            # as we mutate it\n            fileop = FileOperator(dry_run=dry_run)\n            fileop.record = True  # so we can rollback if needed\n\n            bc = not sys.dont_write_bytecode  # Double negatives. Lovely!\n\n            outfiles = []  # for RECORD writing\n\n            # for script copying/shebang processing\n            workdir = tempfile.mkdtemp()\n            # set target dir later\n            # we default add_launchers to False, as the\n            # Python Launcher should be used instead\n            maker.source_dir = workdir\n            maker.target_dir = None\n            try:\n                for zinfo in zf.infolist():\n                    arcname = zinfo.filename\n                    if isinstance(arcname, text_type):\n                        u_arcname = arcname\n                    else:\n                        u_arcname = arcname.decode('utf-8')\n                    if self.skip_entry(u_arcname):\n                        continue\n                    row = records[u_arcname]\n                    if row[2] and str(zinfo.file_size) != row[2]:\n                        raise DistlibException('size mismatch for '\n                                               '%s' % u_arcname)\n                    if row[1]:\n                        kind, value = row[1].split('=', 1)\n                        with zf.open(arcname) as bf:\n                            data = bf.read()\n                        _, digest = self.get_hash(data, kind)\n                        if digest != value:\n                            raise DistlibException('digest mismatch for '\n                                                   '%s' % arcname)\n\n                    if lib_only and u_arcname.startswith((info_pfx, data_pfx)):\n                        logger.debug('lib_only: skipping %s', u_arcname)\n                        continue\n                    is_script = (u_arcname.startswith(script_pfx)\n                                 and not u_arcname.endswith('.exe'))\n\n                    if u_arcname.startswith(data_pfx):\n                        _, where, rp = u_arcname.split('/', 2)\n                        outfile = os.path.join(paths[where], convert_path(rp))\n                    else:\n                        # meant for site-packages.\n                        if u_arcname in (wheel_metadata_name, record_name):\n                            continue\n                        outfile = os.path.join(libdir, convert_path(u_arcname))\n                    if not is_script:\n                        with zf.open(arcname) as bf:\n                            fileop.copy_stream(bf, outfile)\n                        # Issue #147: permission bits aren't preserved. Using\n                        # zf.extract(zinfo, libdir) should have worked, but didn't,\n                        # see https://www.thetopsites.net/article/53834422.shtml\n                        # So ... manually preserve permission bits as given in zinfo\n                        if os.name == 'posix':\n                            # just set the normal permission bits\n                            os.chmod(outfile,\n                                     (zinfo.external_attr >> 16) & 0x1FF)\n                        outfiles.append(outfile)\n                        # Double check the digest of the written file\n                        if not dry_run and row[1]:\n                            with open(outfile, 'rb') as bf:\n                                data = bf.read()\n                                _, newdigest = self.get_hash(data, kind)\n                                if newdigest != digest:\n                                    raise DistlibException('digest mismatch '\n                                                           'on write for '\n                                                           '%s' % outfile)\n                        if bc and outfile.endswith('.py'):\n                            try:\n                                pyc = fileop.byte_compile(\n                                    outfile,\n                                    hashed_invalidation=bc_hashed_invalidation)\n                                outfiles.append(pyc)\n                            except Exception:\n                                # Don't give up if byte-compilation fails,\n                                # but log it and perhaps warn the user\n                                logger.warning('Byte-compilation failed',\n                                               exc_info=True)\n                    else:\n                        fn = os.path.basename(convert_path(arcname))\n                        workname = os.path.join(workdir, fn)\n                        with zf.open(arcname) as bf:\n                            fileop.copy_stream(bf, workname)\n\n                        dn, fn = os.path.split(outfile)\n                        maker.target_dir = dn\n                        filenames = maker.make(fn)\n                        fileop.set_executable_mode(filenames)\n                        outfiles.extend(filenames)\n\n                if lib_only:\n                    logger.debug('lib_only: returning None')\n                    dist = None\n                else:\n                    # Generate scripts\n\n                    # Try to get pydist.json so we can see if there are\n                    # any commands to generate. If this fails (e.g. because\n                    # of a legacy wheel), log a warning but don't give up.\n                    commands = None\n                    file_version = self.info['Wheel-Version']\n                    if file_version == '1.0':\n                        # Use legacy info\n                        ep = posixpath.join(info_dir, 'entry_points.txt')\n                        try:\n                            with zf.open(ep) as bwf:\n                                epdata = read_exports(bwf)\n                            commands = {}\n                            for key in ('console', 'gui'):\n                                k = '%s_scripts' % key\n                                if k in epdata:\n                                    commands['wrap_%s' % key] = d = {}\n                                    for v in epdata[k].values():\n                                        s = '%s:%s' % (v.prefix, v.suffix)\n                                        if v.flags:\n                                            s += ' [%s]' % ','.join(v.flags)\n                                        d[v.name] = s\n                        except Exception:\n                            logger.warning('Unable to read legacy script '\n                                           'metadata, so cannot generate '\n                                           'scripts')\n                    else:\n                        try:\n                            with zf.open(metadata_name) as bwf:\n                                wf = wrapper(bwf)\n                                commands = json.load(wf).get('extensions')\n                                if commands:\n                                    commands = commands.get('python.commands')\n                        except Exception:\n                            logger.warning('Unable to read JSON metadata, so '\n                                           'cannot generate scripts')\n                    if commands:\n                        console_scripts = commands.get('wrap_console', {})\n                        gui_scripts = commands.get('wrap_gui', {})\n                        if console_scripts or gui_scripts:\n                            script_dir = paths.get('scripts', '')\n                            if not os.path.isdir(script_dir):\n                                raise ValueError('Valid script path not '\n                                                 'specified')\n                            maker.target_dir = script_dir\n                            for k, v in console_scripts.items():\n                                script = '%s = %s' % (k, v)\n                                filenames = maker.make(script)\n                                fileop.set_executable_mode(filenames)\n\n                            if gui_scripts:\n                                options = {'gui': True}\n                                for k, v in gui_scripts.items():\n                                    script = '%s = %s' % (k, v)\n                                    filenames = maker.make(script, options)\n                                    fileop.set_executable_mode(filenames)\n\n                    p = os.path.join(libdir, info_dir)\n                    dist = InstalledDistribution(p)\n\n                    # Write SHARED\n                    paths = dict(paths)  # don't change passed in dict\n                    del paths['purelib']\n                    del paths['platlib']\n                    paths['lib'] = libdir\n                    p = dist.write_shared_locations(paths, dry_run)\n                    if p:\n                        outfiles.append(p)\n\n                    # Write RECORD\n                    dist.write_installed_files(outfiles, paths['prefix'],\n                                               dry_run)\n                return dist\n            except Exception:  # pragma: no cover\n                logger.exception('installation failed.')\n                fileop.rollback()\n                raise\n            finally:\n                shutil.rmtree(workdir)\n\n    def _get_dylib_cache(self):\n        global cache\n        if cache is None:\n            # Use native string to avoid issues on 2.x: see Python #20140.\n            base = os.path.join(get_cache_base(), str('dylib-cache'),\n                                '%s.%s' % sys.version_info[:2])\n            cache = Cache(base)\n        return cache\n\n    def _get_extensions(self):\n        pathname = os.path.join(self.dirname, self.filename)\n        name_ver = '%s-%s' % (self.name, self.version)\n        info_dir = '%s.dist-info' % name_ver\n        arcname = posixpath.join(info_dir, 'EXTENSIONS')\n        wrapper = codecs.getreader('utf-8')\n        result = []\n        with ZipFile(pathname, 'r') as zf:\n            try:\n                with zf.open(arcname) as bf:\n                    wf = wrapper(bf)\n                    extensions = json.load(wf)\n                    cache = self._get_dylib_cache()\n                    prefix = cache.prefix_to_dir(pathname)\n                    cache_base = os.path.join(cache.base, prefix)\n                    if not os.path.isdir(cache_base):\n                        os.makedirs(cache_base)\n                    for name, relpath in extensions.items():\n                        dest = os.path.join(cache_base, convert_path(relpath))\n                        if not os.path.exists(dest):\n                            extract = True\n                        else:\n                            file_time = os.stat(dest).st_mtime\n                            file_time = datetime.datetime.fromtimestamp(\n                                file_time)\n                            info = zf.getinfo(relpath)\n                            wheel_time = datetime.datetime(*info.date_time)\n                            extract = wheel_time > file_time\n                        if extract:\n                            zf.extract(relpath, cache_base)\n                        result.append((name, dest))\n            except KeyError:\n                pass\n        return result\n\n    def is_compatible(self):\n        \"\"\"\n        Determine if a wheel is compatible with the running system.\n        \"\"\"\n        return is_compatible(self)\n\n    def is_mountable(self):\n        \"\"\"\n        Determine if a wheel is asserted as mountable by its metadata.\n        \"\"\"\n        return True  # for now - metadata details TBD\n\n    def mount(self, append=False):\n        pathname = os.path.abspath(os.path.join(self.dirname, self.filename))\n        if not self.is_compatible():\n            msg = 'Wheel %s not compatible with this Python.' % pathname\n            raise DistlibException(msg)\n        if not self.is_mountable():\n            msg = 'Wheel %s is marked as not mountable.' % pathname\n            raise DistlibException(msg)\n        if pathname in sys.path:\n            logger.debug('%s already in path', pathname)\n        else:\n            if append:\n                sys.path.append(pathname)\n            else:\n                sys.path.insert(0, pathname)\n            extensions = self._get_extensions()\n            if extensions:\n                if _hook not in sys.meta_path:\n                    sys.meta_path.append(_hook)\n                _hook.add(pathname, extensions)\n\n    def unmount(self):\n        pathname = os.path.abspath(os.path.join(self.dirname, self.filename))\n        if pathname not in sys.path:\n            logger.debug('%s not in path', pathname)\n        else:\n            sys.path.remove(pathname)\n            if pathname in _hook.impure_wheels:\n                _hook.remove(pathname)\n            if not _hook.impure_wheels:\n                if _hook in sys.meta_path:\n                    sys.meta_path.remove(_hook)\n\n    def verify(self):\n        pathname = os.path.join(self.dirname, self.filename)\n        name_ver = '%s-%s' % (self.name, self.version)\n        # data_dir = '%s.data' % name_ver\n        info_dir = '%s.dist-info' % name_ver\n\n        # metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)\n        wheel_metadata_name = posixpath.join(info_dir, 'WHEEL')\n        record_name = posixpath.join(info_dir, 'RECORD')\n\n        wrapper = codecs.getreader('utf-8')\n\n        with ZipFile(pathname, 'r') as zf:\n            with zf.open(wheel_metadata_name) as bwf:\n                wf = wrapper(bwf)\n                message_from_file(wf)\n            # wv = message['Wheel-Version'].split('.', 1)\n            # file_version = tuple([int(i) for i in wv])\n            # TODO version verification\n\n            records = {}\n            with zf.open(record_name) as bf:\n                with CSVReader(stream=bf) as reader:\n                    for row in reader:\n                        p = row[0]\n                        records[p] = row\n\n            for zinfo in zf.infolist():\n                arcname = zinfo.filename\n                if isinstance(arcname, text_type):\n                    u_arcname = arcname\n                else:\n                    u_arcname = arcname.decode('utf-8')\n                # See issue #115: some wheels have .. in their entries, but\n                # in the filename ... e.g. __main__..py ! So the check is\n                # updated to look for .. in the directory portions\n                p = u_arcname.split('/')\n                if '..' in p:\n                    raise DistlibException('invalid entry in '\n                                           'wheel: %r' % u_arcname)\n\n                if self.skip_entry(u_arcname):\n                    continue\n                row = records[u_arcname]\n                if row[2] and str(zinfo.file_size) != row[2]:\n                    raise DistlibException('size mismatch for '\n                                           '%s' % u_arcname)\n                if row[1]:\n                    kind, value = row[1].split('=', 1)\n                    with zf.open(arcname) as bf:\n                        data = bf.read()\n                    _, digest = self.get_hash(data, kind)\n                    if digest != value:\n                        raise DistlibException('digest mismatch for '\n                                               '%s' % arcname)\n\n    def update(self, modifier, dest_dir=None, **kwargs):\n        \"\"\"\n        Update the contents of a wheel in a generic way. The modifier should\n        be a callable which expects a dictionary argument: its keys are\n        archive-entry paths, and its values are absolute filesystem paths\n        where the contents the corresponding archive entries can be found. The\n        modifier is free to change the contents of the files pointed to, add\n        new entries and remove entries, before returning. This method will\n        extract the entire contents of the wheel to a temporary location, call\n        the modifier, and then use the passed (and possibly updated)\n        dictionary to write a new wheel. If ``dest_dir`` is specified, the new\n        wheel is written there -- otherwise, the original wheel is overwritten.\n\n        The modifier should return True if it updated the wheel, else False.\n        This method returns the same value the modifier returns.\n        \"\"\"\n\n        def get_version(path_map, info_dir):\n            version = path = None\n            key = '%s/%s' % (info_dir, LEGACY_METADATA_FILENAME)\n            if key not in path_map:\n                key = '%s/PKG-INFO' % info_dir\n            if key in path_map:\n                path = path_map[key]\n                version = Metadata(path=path).version\n            return version, path\n\n        def update_version(version, path):\n            updated = None\n            try:\n                NormalizedVersion(version)\n                i = version.find('-')\n                if i < 0:\n                    updated = '%s+1' % version\n                else:\n                    parts = [int(s) for s in version[i + 1:].split('.')]\n                    parts[-1] += 1\n                    updated = '%s+%s' % (version[:i], '.'.join(\n                        str(i) for i in parts))\n            except UnsupportedVersionError:\n                logger.debug(\n                    'Cannot update non-compliant (PEP-440) '\n                    'version %r', version)\n            if updated:\n                md = Metadata(path=path)\n                md.version = updated\n                legacy = path.endswith(LEGACY_METADATA_FILENAME)\n                md.write(path=path, legacy=legacy)\n                logger.debug('Version updated from %r to %r', version, updated)\n\n        pathname = os.path.join(self.dirname, self.filename)\n        name_ver = '%s-%s' % (self.name, self.version)\n        info_dir = '%s.dist-info' % name_ver\n        record_name = posixpath.join(info_dir, 'RECORD')\n        with tempdir() as workdir:\n            with ZipFile(pathname, 'r') as zf:\n                path_map = {}\n                for zinfo in zf.infolist():\n                    arcname = zinfo.filename\n                    if isinstance(arcname, text_type):\n                        u_arcname = arcname\n                    else:\n                        u_arcname = arcname.decode('utf-8')\n                    if u_arcname == record_name:\n                        continue\n                    if '..' in u_arcname:\n                        raise DistlibException('invalid entry in '\n                                               'wheel: %r' % u_arcname)\n                    zf.extract(zinfo, workdir)\n                    path = os.path.join(workdir, convert_path(u_arcname))\n                    path_map[u_arcname] = path\n\n            # Remember the version.\n            original_version, _ = get_version(path_map, info_dir)\n            # Files extracted. Call the modifier.\n            modified = modifier(path_map, **kwargs)\n            if modified:\n                # Something changed - need to build a new wheel.\n                current_version, path = get_version(path_map, info_dir)\n                if current_version and (current_version == original_version):\n                    # Add or update local version to signify changes.\n                    update_version(current_version, path)\n                # Decide where the new wheel goes.\n                if dest_dir is None:\n                    fd, newpath = tempfile.mkstemp(suffix='.whl',\n                                                   prefix='wheel-update-',\n                                                   dir=workdir)\n                    os.close(fd)\n                else:\n                    if not os.path.isdir(dest_dir):\n                        raise DistlibException('Not a directory: %r' %\n                                               dest_dir)\n                    newpath = os.path.join(dest_dir, self.filename)\n                archive_paths = list(path_map.items())\n                distinfo = os.path.join(workdir, info_dir)\n                info = distinfo, info_dir\n                self.write_records(info, workdir, archive_paths)\n                self.build_zip(newpath, archive_paths)\n                if dest_dir is None:\n                    shutil.copyfile(newpath, pathname)\n        return modified\n\n\ndef _get_glibc_version():\n    import platform\n    ver = platform.libc_ver()\n    result = []\n    if ver[0] == 'glibc':\n        for s in ver[1].split('.'):\n            result.append(int(s) if s.isdigit() else 0)\n        result = tuple(result)\n    return result\n\n\ndef compatible_tags():\n    \"\"\"\n    Return (pyver, abi, arch) tuples compatible with this Python.\n    \"\"\"\n    versions = [VER_SUFFIX]\n    major = VER_SUFFIX[0]\n    for minor in range(sys.version_info[1] - 1, -1, -1):\n        versions.append(''.join([major, str(minor)]))\n\n    abis = []\n    for suffix in _get_suffixes():\n        if suffix.startswith('.abi'):\n            abis.append(suffix.split('.', 2)[1])\n    abis.sort()\n    if ABI != 'none':\n        abis.insert(0, ABI)\n    abis.append('none')\n    result = []\n\n    arches = [ARCH]\n    if sys.platform == 'darwin':\n        m = re.match(r'(\\w+)_(\\d+)_(\\d+)_(\\w+)$', ARCH)\n        if m:\n            name, major, minor, arch = m.groups()\n            minor = int(minor)\n            matches = [arch]\n            if arch in ('i386', 'ppc'):\n                matches.append('fat')\n            if arch in ('i386', 'ppc', 'x86_64'):\n                matches.append('fat3')\n            if arch in ('ppc64', 'x86_64'):\n                matches.append('fat64')\n            if arch in ('i386', 'x86_64'):\n                matches.append('intel')\n            if arch in ('i386', 'x86_64', 'intel', 'ppc', 'ppc64'):\n                matches.append('universal')\n            while minor >= 0:\n                for match in matches:\n                    s = '%s_%s_%s_%s' % (name, major, minor, match)\n                    if s != ARCH:  # already there\n                        arches.append(s)\n                minor -= 1\n\n    # Most specific - our Python version, ABI and arch\n    for abi in abis:\n        for arch in arches:\n            result.append((''.join((IMP_PREFIX, versions[0])), abi, arch))\n            # manylinux\n            if abi != 'none' and sys.platform.startswith('linux'):\n                arch = arch.replace('linux_', '')\n                parts = _get_glibc_version()\n                if len(parts) == 2:\n                    if parts >= (2, 5):\n                        result.append((''.join((IMP_PREFIX, versions[0])), abi,\n                                       'manylinux1_%s' % arch))\n                    if parts >= (2, 12):\n                        result.append((''.join((IMP_PREFIX, versions[0])), abi,\n                                       'manylinux2010_%s' % arch))\n                    if parts >= (2, 17):\n                        result.append((''.join((IMP_PREFIX, versions[0])), abi,\n                                       'manylinux2014_%s' % arch))\n                    result.append(\n                        (''.join((IMP_PREFIX, versions[0])), abi,\n                         'manylinux_%s_%s_%s' % (parts[0], parts[1], arch)))\n\n    # where no ABI / arch dependency, but IMP_PREFIX dependency\n    for i, version in enumerate(versions):\n        result.append((''.join((IMP_PREFIX, version)), 'none', 'any'))\n        if i == 0:\n            result.append((''.join((IMP_PREFIX, version[0])), 'none', 'any'))\n\n    # no IMP_PREFIX, ABI or arch dependency\n    for i, version in enumerate(versions):\n        result.append((''.join(('py', version)), 'none', 'any'))\n        if i == 0:\n            result.append((''.join(('py', version[0])), 'none', 'any'))\n\n    return set(result)\n\n\nCOMPATIBLE_TAGS = compatible_tags()\n\ndel compatible_tags\n\n\ndef is_compatible(wheel, tags=None):\n    if not isinstance(wheel, Wheel):\n        wheel = Wheel(wheel)  # assume it's a filename\n    result = False\n    if tags is None:\n        tags = COMPATIBLE_TAGS\n    for ver, abi, arch in tags:\n        if ver in wheel.pyver and abi in wheel.abi and arch in wheel.arch:\n            result = True\n            break\n    return result\n"},"hash":"j9XAC5r9Qv"}