{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:tests:test_lxml.py","body":"\"\"\"Tests to ensure that the lxml tree builder generates good trees.\"\"\"\n\nimport pickle\nimport pytest\nimport re\nimport warnings\nfrom . import LXML_PRESENT, LXML_VERSION\n\nif LXML_PRESENT:\n    from bs4.builder import LXMLTreeBuilder, LXMLTreeBuilderForXML\n\nfrom bs4 import (\n    BeautifulSoup,\n    BeautifulStoneSoup,\n    )\nfrom bs4.element import Comment, Doctype, SoupStrainer\nfrom . import (\n    HTMLTreeBuilderSmokeTest,\n    XMLTreeBuilderSmokeTest,\n    SOUP_SIEVE_PRESENT,\n    SoupTest,\n)\n\n@pytest.mark.skipif(\n    not LXML_PRESENT,\n    reason=\"lxml seems not to be present, not testing its tree builder.\"\n)\nclass TestLXMLTreeBuilder(SoupTest, HTMLTreeBuilderSmokeTest):\n    \"\"\"See ``HTMLTreeBuilderSmokeTest``.\"\"\"\n\n    @property\n    def default_builder(self):\n        return LXMLTreeBuilder\n\n    def test_out_of_range_entity(self):\n        self.assert_soup(\n            \"<p>foo&#10000000000000;bar</p>\", \"<p>foobar</p>\")\n        self.assert_soup(\n            \"<p>foo&#x10000000000000;bar</p>\", \"<p>foobar</p>\")\n        self.assert_soup(\n            \"<p>foo&#1000000000;bar</p>\", \"<p>foobar</p>\")\n        \n    def test_entities_in_foreign_document_encoding(self):\n        # We can't implement this case correctly because by the time we\n        # hear about markup like \"&#147;\", it's been (incorrectly) converted into\n        # a string like u'\\x93'\n        pass\n        \n    # In lxml < 2.3.5, an empty doctype causes a segfault. Skip this\n    # test if an old version of lxml is installed.\n\n    @pytest.mark.skipif(\n        not LXML_PRESENT or LXML_VERSION < (2,3,5,0),\n        reason=\"Skipping doctype test for old version of lxml to avoid segfault.\"\n    )\n    def test_empty_doctype(self):\n        soup = self.soup(\"<!DOCTYPE>\")\n        doctype = soup.contents[0]\n        assert \"\" == doctype.strip()\n\n    def test_beautifulstonesoup_is_xml_parser(self):\n        # Make sure that the deprecated BSS class uses an xml builder\n        # if one is installed.\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulStoneSoup(\"<b />\")\n        assert \"<b/>\" == str(soup.b)\n        [warning] = w\n        assert warning.filename == __file__\n        assert \"BeautifulStoneSoup class is deprecated\" in str(warning.message)\n\n    def test_tracking_line_numbers(self):\n        # The lxml TreeBuilder cannot keep track of line numbers from\n        # the original markup. Even if you ask for line numbers, we\n        # don't have 'em.\n        #\n        # This means that if you have a tag like <sourceline> or\n        # <sourcepos>, attribute access will find it rather than\n        # giving you a numeric answer.\n        soup = self.soup(\n            \"\\n   <p>\\n\\n<sourceline>\\n<b>text</b></sourceline><sourcepos></p>\",\n            store_line_numbers=True\n        )\n        assert \"sourceline\" == soup.p.sourceline.name\n        assert \"sourcepos\" == soup.p.sourcepos.name\n        \n@pytest.mark.skipif(\n    not LXML_PRESENT,\n    reason=\"lxml seems not to be present, not testing its XML tree builder.\"\n)\nclass TestLXMLXMLTreeBuilder(SoupTest, XMLTreeBuilderSmokeTest):\n    \"\"\"See ``HTMLTreeBuilderSmokeTest``.\"\"\"\n\n    @property\n    def default_builder(self):\n        return LXMLTreeBuilderForXML\n\n    def test_namespace_indexing(self):\n        soup = self.soup(\n            '<?xml version=\"1.1\"?>\\n'\n            '<root>'\n            '<tag xmlns=\"http://unprefixed-namespace.com\">content</tag>'\n            '<prefix:tag2 xmlns:prefix=\"http://prefixed-namespace.com\">content</prefix:tag2>'\n            '<prefix2:tag3 xmlns:prefix2=\"http://another-namespace.com\">'\n            '<subtag xmlns=\"http://another-unprefixed-namespace.com\">'\n            '<subsubtag xmlns=\"http://yet-another-unprefixed-namespace.com\">'\n            '</prefix2:tag3>'\n            '</root>'\n        )\n\n        # The BeautifulSoup object includes every namespace prefix\n        # defined in the entire document. This is the default set of\n        # namespaces used by soupsieve.\n        #\n        # Un-prefixed namespaces are not included, and if a given\n        # prefix is defined twice, only the first prefix encountered\n        # in the document shows up here.\n        assert soup._namespaces == {\n            'xml': 'http://www.w3.org/XML/1998/namespace',\n            'prefix': 'http://prefixed-namespace.com',\n            'prefix2': 'http://another-namespace.com'\n        }\n\n        # A Tag object includes only the namespace prefixes\n        # that were in scope when it was parsed.\n\n        # We do not track un-prefixed namespaces as we can only hold\n        # one (the first one), and it will be recognized as the\n        # default namespace by soupsieve, even when operating from a\n        # tag with a different un-prefixed namespace.\n        assert soup.tag._namespaces == {\n            'xml': 'http://www.w3.org/XML/1998/namespace',\n        }\n\n        assert soup.tag2._namespaces == {\n            'prefix': 'http://prefixed-namespace.com',\n            'xml': 'http://www.w3.org/XML/1998/namespace',\n        }\n\n        assert soup.subtag._namespaces == {\n            'prefix2': 'http://another-namespace.com',\n            'xml': 'http://www.w3.org/XML/1998/namespace',\n        }\n\n        assert soup.subsubtag._namespaces == {\n            'prefix2': 'http://another-namespace.com',\n            'xml': 'http://www.w3.org/XML/1998/namespace',\n        }\n\n\n    @pytest.mark.skipif(\n        not SOUP_SIEVE_PRESENT, reason=\"Soup Sieve not installed\"\n    )\n    def test_namespace_interaction_with_select_and_find(self):\n        # Demonstrate how namespaces interact with select* and\n        # find* methods.\n        \n        soup = self.soup(\n            '<?xml version=\"1.1\"?>\\n'\n            '<root>'\n            '<tag xmlns=\"http://unprefixed-namespace.com\">content</tag>'\n            '<prefix:tag2 xmlns:prefix=\"http://prefixed-namespace.com\">content</tag>'\n            '<subtag xmlns:prefix=\"http://another-namespace-same-prefix.com\">'\n             '<prefix:tag3>'\n            '</subtag>'\n            '</root>'\n        )\n\n        # soupselect uses namespace URIs.\n        assert soup.select_one('tag').name == 'tag'\n        assert soup.select_one('prefix|tag2').name == 'tag2'\n\n        # If a prefix is declared more than once, only the first usage\n        # is registered with the BeautifulSoup object.\n        assert soup.select_one('prefix|tag3') is None\n\n        # But you can always explicitly specify a namespace dictionary.\n        assert soup.select_one(\n            'prefix|tag3', namespaces=soup.subtag._namespaces\n        ).name == 'tag3'\n\n        # And a Tag (as opposed to the BeautifulSoup object) will\n        # have a set of default namespaces scoped to that Tag.\n        assert soup.subtag.select_one('prefix|tag3').name=='tag3'\n\n        # the find() methods aren't fully namespace-aware; they just\n        # look at prefixes.\n        assert soup.find('tag').name == 'tag'\n        assert soup.find('prefix:tag2').name == 'tag2'\n        assert soup.find('prefix:tag3').name == 'tag3'\n        assert soup.subtag.find('prefix:tag3').name == 'tag3'\n\n    def test_pickle_restores_builder(self):\n        # The lxml TreeBuilder is not picklable, so when unpickling\n        # a document created with it, a new TreeBuilder of the\n        # appropriate class is created.\n        soup = self.soup(\"<a>some markup</a>\")\n        assert isinstance(soup.builder, self.default_builder)\n        pickled = pickle.dumps(soup)\n        unpickled = pickle.loads(pickled)\n\n        assert \"some markup\" == unpickled.a.string\n        assert unpickled.builder != soup.builder\n        assert isinstance(unpickled.builder, self.default_builder)\n"},"hash":"9NvNPtvETE"}