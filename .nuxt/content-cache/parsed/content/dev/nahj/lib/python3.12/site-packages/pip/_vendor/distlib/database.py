{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:distlib:database.py","body":"# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2012-2023 The Python Software Foundation.\n# See LICENSE.txt and CONTRIBUTORS.txt.\n#\n\"\"\"PEP 376 implementation.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport base64\nimport codecs\nimport contextlib\nimport hashlib\nimport logging\nimport os\nimport posixpath\nimport sys\nimport zipimport\n\nfrom . import DistlibException, resources\nfrom .compat import StringIO\nfrom .version import get_scheme, UnsupportedVersionError\nfrom .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,\n                       LEGACY_METADATA_FILENAME)\nfrom .util import (parse_requirement, cached_property, parse_name_and_version,\n                   read_exports, write_exports, CSVReader, CSVWriter)\n\n__all__ = [\n    'Distribution', 'BaseInstalledDistribution', 'InstalledDistribution',\n    'EggInfoDistribution', 'DistributionPath'\n]\n\nlogger = logging.getLogger(__name__)\n\nEXPORTS_FILENAME = 'pydist-exports.json'\nCOMMANDS_FILENAME = 'pydist-commands.json'\n\nDIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED',\n              'RESOURCES', EXPORTS_FILENAME, 'SHARED')\n\nDISTINFO_EXT = '.dist-info'\n\n\nclass _Cache(object):\n    \"\"\"\n    A simple cache mapping names and .dist-info paths to distributions\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialise an instance. There is normally one for each DistributionPath.\n        \"\"\"\n        self.name = {}\n        self.path = {}\n        self.generated = False\n\n    def clear(self):\n        \"\"\"\n        Clear the cache, setting it to its initial state.\n        \"\"\"\n        self.name.clear()\n        self.path.clear()\n        self.generated = False\n\n    def add(self, dist):\n        \"\"\"\n        Add a distribution to the cache.\n        :param dist: The distribution to add.\n        \"\"\"\n        if dist.path not in self.path:\n            self.path[dist.path] = dist\n            self.name.setdefault(dist.key, []).append(dist)\n\n\nclass DistributionPath(object):\n    \"\"\"\n    Represents a set of distributions installed on a path (typically sys.path).\n    \"\"\"\n\n    def __init__(self, path=None, include_egg=False):\n        \"\"\"\n        Create an instance from a path, optionally including legacy (distutils/\n        setuptools/distribute) distributions.\n        :param path: The path to use, as a list of directories. If not specified,\n                     sys.path is used.\n        :param include_egg: If True, this instance will look for and return legacy\n                            distributions as well as those based on PEP 376.\n        \"\"\"\n        if path is None:\n            path = sys.path\n        self.path = path\n        self._include_dist = True\n        self._include_egg = include_egg\n\n        self._cache = _Cache()\n        self._cache_egg = _Cache()\n        self._cache_enabled = True\n        self._scheme = get_scheme('default')\n\n    def _get_cache_enabled(self):\n        return self._cache_enabled\n\n    def _set_cache_enabled(self, value):\n        self._cache_enabled = value\n\n    cache_enabled = property(_get_cache_enabled, _set_cache_enabled)\n\n    def clear_cache(self):\n        \"\"\"\n        Clears the internal cache.\n        \"\"\"\n        self._cache.clear()\n        self._cache_egg.clear()\n\n    def _yield_distributions(self):\n        \"\"\"\n        Yield .dist-info and/or .egg(-info) distributions.\n        \"\"\"\n        # We need to check if we've seen some resources already, because on\n        # some Linux systems (e.g. some Debian/Ubuntu variants) there are\n        # symlinks which alias other files in the environment.\n        seen = set()\n        for path in self.path:\n            finder = resources.finder_for_path(path)\n            if finder is None:\n                continue\n            r = finder.find('')\n            if not r or not r.is_container:\n                continue\n            rset = sorted(r.resources)\n            for entry in rset:\n                r = finder.find(entry)\n                if not r or r.path in seen:\n                    continue\n                try:\n                    if self._include_dist and entry.endswith(DISTINFO_EXT):\n                        possible_filenames = [\n                            METADATA_FILENAME, WHEEL_METADATA_FILENAME,\n                            LEGACY_METADATA_FILENAME\n                        ]\n                        for metadata_filename in possible_filenames:\n                            metadata_path = posixpath.join(\n                                entry, metadata_filename)\n                            pydist = finder.find(metadata_path)\n                            if pydist:\n                                break\n                        else:\n                            continue\n\n                        with contextlib.closing(pydist.as_stream()) as stream:\n                            metadata = Metadata(fileobj=stream,\n                                                scheme='legacy')\n                        logger.debug('Found %s', r.path)\n                        seen.add(r.path)\n                        yield new_dist_class(r.path,\n                                             metadata=metadata,\n                                             env=self)\n                    elif self._include_egg and entry.endswith(\n                            ('.egg-info', '.egg')):\n                        logger.debug('Found %s', r.path)\n                        seen.add(r.path)\n                        yield old_dist_class(r.path, self)\n                except Exception as e:\n                    msg = 'Unable to read distribution at %s, perhaps due to bad metadata: %s'\n                    logger.warning(msg, r.path, e)\n                    import warnings\n                    warnings.warn(msg % (r.path, e), stacklevel=2)\n\n    def _generate_cache(self):\n        \"\"\"\n        Scan the path for distributions and populate the cache with\n        those that are found.\n        \"\"\"\n        gen_dist = not self._cache.generated\n        gen_egg = self._include_egg and not self._cache_egg.generated\n        if gen_dist or gen_egg:\n            for dist in self._yield_distributions():\n                if isinstance(dist, InstalledDistribution):\n                    self._cache.add(dist)\n                else:\n                    self._cache_egg.add(dist)\n\n            if gen_dist:\n                self._cache.generated = True\n            if gen_egg:\n                self._cache_egg.generated = True\n\n    @classmethod\n    def distinfo_dirname(cls, name, version):\n        \"\"\"\n        The *name* and *version* parameters are converted into their\n        filename-escaped form, i.e. any ``'-'`` characters are replaced\n        with ``'_'`` other than the one in ``'dist-info'`` and the one\n        separating the name from the version number.\n\n        :parameter name: is converted to a standard distribution name by replacing\n                         any runs of non- alphanumeric characters with a single\n                         ``'-'``.\n        :type name: string\n        :parameter version: is converted to a standard version string. Spaces\n                            become dots, and all other non-alphanumeric characters\n                            (except dots) become dashes, with runs of multiple\n                            dashes condensed to a single dash.\n        :type version: string\n        :returns: directory name\n        :rtype: string\"\"\"\n        name = name.replace('-', '_')\n        return '-'.join([name, version]) + DISTINFO_EXT\n\n    def get_distributions(self):\n        \"\"\"\n        Provides an iterator that looks for distributions and returns\n        :class:`InstalledDistribution` or\n        :class:`EggInfoDistribution` instances for each one of them.\n\n        :rtype: iterator of :class:`InstalledDistribution` and\n                :class:`EggInfoDistribution` instances\n        \"\"\"\n        if not self._cache_enabled:\n            for dist in self._yield_distributions():\n                yield dist\n        else:\n            self._generate_cache()\n\n            for dist in self._cache.path.values():\n                yield dist\n\n            if self._include_egg:\n                for dist in self._cache_egg.path.values():\n                    yield dist\n\n    def get_distribution(self, name):\n        \"\"\"\n        Looks for a named distribution on the path.\n\n        This function only returns the first result found, as no more than one\n        value is expected. If nothing is found, ``None`` is returned.\n\n        :rtype: :class:`InstalledDistribution`, :class:`EggInfoDistribution`\n                or ``None``\n        \"\"\"\n        result = None\n        name = name.lower()\n        if not self._cache_enabled:\n            for dist in self._yield_distributions():\n                if dist.key == name:\n                    result = dist\n                    break\n        else:\n            self._generate_cache()\n\n            if name in self._cache.name:\n                result = self._cache.name[name][0]\n            elif self._include_egg and name in self._cache_egg.name:\n                result = self._cache_egg.name[name][0]\n        return result\n\n    def provides_distribution(self, name, version=None):\n        \"\"\"\n        Iterates over all distributions to find which distributions provide *name*.\n        If a *version* is provided, it will be used to filter the results.\n\n        This function only returns the first result found, since no more than\n        one values are expected. If the directory is not found, returns ``None``.\n\n        :parameter version: a version specifier that indicates the version\n                            required, conforming to the format in ``PEP-345``\n\n        :type name: string\n        :type version: string\n        \"\"\"\n        matcher = None\n        if version is not None:\n            try:\n                matcher = self._scheme.matcher('%s (%s)' % (name, version))\n            except ValueError:\n                raise DistlibException('invalid name or version: %r, %r' %\n                                       (name, version))\n\n        for dist in self.get_distributions():\n            # We hit a problem on Travis where enum34 was installed and doesn't\n            # have a provides attribute ...\n            if not hasattr(dist, 'provides'):\n                logger.debug('No \"provides\": %s', dist)\n            else:\n                provided = dist.provides\n\n                for p in provided:\n                    p_name, p_ver = parse_name_and_version(p)\n                    if matcher is None:\n                        if p_name == name:\n                            yield dist\n                            break\n                    else:\n                        if p_name == name and matcher.match(p_ver):\n                            yield dist\n                            break\n\n    def get_file_path(self, name, relative_path):\n        \"\"\"\n        Return the path to a resource file.\n        \"\"\"\n        dist = self.get_distribution(name)\n        if dist is None:\n            raise LookupError('no distribution named %r found' % name)\n        return dist.get_resource_path(relative_path)\n\n    def get_exported_entries(self, category, name=None):\n        \"\"\"\n        Return all of the exported entries in a particular category.\n\n        :param category: The category to search for entries.\n        :param name: If specified, only entries with that name are returned.\n        \"\"\"\n        for dist in self.get_distributions():\n            r = dist.exports\n            if category in r:\n                d = r[category]\n                if name is not None:\n                    if name in d:\n                        yield d[name]\n                else:\n                    for v in d.values():\n                        yield v\n\n\nclass Distribution(object):\n    \"\"\"\n    A base class for distributions, whether installed or from indexes.\n    Either way, it must have some metadata, so that's all that's needed\n    for construction.\n    \"\"\"\n\n    build_time_dependency = False\n    \"\"\"\n    Set to True if it's known to be only a build-time dependency (i.e.\n    not needed after installation).\n    \"\"\"\n\n    requested = False\n    \"\"\"A boolean that indicates whether the ``REQUESTED`` metadata file is\n    present (in other words, whether the package was installed by user\n    request or it was installed as a dependency).\"\"\"\n\n    def __init__(self, metadata):\n        \"\"\"\n        Initialise an instance.\n        :param metadata: The instance of :class:`Metadata` describing this\n        distribution.\n        \"\"\"\n        self.metadata = metadata\n        self.name = metadata.name\n        self.key = self.name.lower()  # for case-insensitive comparisons\n        self.version = metadata.version\n        self.locator = None\n        self.digest = None\n        self.extras = None  # additional features requested\n        self.context = None  # environment marker overrides\n        self.download_urls = set()\n        self.digests = {}\n\n    @property\n    def source_url(self):\n        \"\"\"\n        The source archive download URL for this distribution.\n        \"\"\"\n        return self.metadata.source_url\n\n    download_url = source_url  # Backward compatibility\n\n    @property\n    def name_and_version(self):\n        \"\"\"\n        A utility property which displays the name and version in parentheses.\n        \"\"\"\n        return '%s (%s)' % (self.name, self.version)\n\n    @property\n    def provides(self):\n        \"\"\"\n        A set of distribution names and versions provided by this distribution.\n        :return: A set of \"name (version)\" strings.\n        \"\"\"\n        plist = self.metadata.provides\n        s = '%s (%s)' % (self.name, self.version)\n        if s not in plist:\n            plist.append(s)\n        return plist\n\n    def _get_requirements(self, req_attr):\n        md = self.metadata\n        reqts = getattr(md, req_attr)\n        logger.debug('%s: got requirements %r from metadata: %r', self.name,\n                     req_attr, reqts)\n        return set(\n            md.get_requirements(reqts, extras=self.extras, env=self.context))\n\n    @property\n    def run_requires(self):\n        return self._get_requirements('run_requires')\n\n    @property\n    def meta_requires(self):\n        return self._get_requirements('meta_requires')\n\n    @property\n    def build_requires(self):\n        return self._get_requirements('build_requires')\n\n    @property\n    def test_requires(self):\n        return self._get_requirements('test_requires')\n\n    @property\n    def dev_requires(self):\n        return self._get_requirements('dev_requires')\n\n    def matches_requirement(self, req):\n        \"\"\"\n        Say if this instance matches (fulfills) a requirement.\n        :param req: The requirement to match.\n        :rtype req: str\n        :return: True if it matches, else False.\n        \"\"\"\n        # Requirement may contain extras - parse to lose those\n        # from what's passed to the matcher\n        r = parse_requirement(req)\n        scheme = get_scheme(self.metadata.scheme)\n        try:\n            matcher = scheme.matcher(r.requirement)\n        except UnsupportedVersionError:\n            # XXX compat-mode if cannot read the version\n            logger.warning('could not read version %r - using name only', req)\n            name = req.split()[0]\n            matcher = scheme.matcher(name)\n\n        name = matcher.key  # case-insensitive\n\n        result = False\n        for p in self.provides:\n            p_name, p_ver = parse_name_and_version(p)\n            if p_name != name:\n                continue\n            try:\n                result = matcher.match(p_ver)\n                break\n            except UnsupportedVersionError:\n                pass\n        return result\n\n    def __repr__(self):\n        \"\"\"\n        Return a textual representation of this instance,\n        \"\"\"\n        if self.source_url:\n            suffix = ' [%s]' % self.source_url\n        else:\n            suffix = ''\n        return '<Distribution %s (%s)%s>' % (self.name, self.version, suffix)\n\n    def __eq__(self, other):\n        \"\"\"\n        See if this distribution is the same as another.\n        :param other: The distribution to compare with. To be equal to one\n                      another. distributions must have the same type, name,\n                      version and source_url.\n        :return: True if it is the same, else False.\n        \"\"\"\n        if type(other) is not type(self):\n            result = False\n        else:\n            result = (self.name == other.name and self.version == other.version\n                      and self.source_url == other.source_url)\n        return result\n\n    def __hash__(self):\n        \"\"\"\n        Compute hash in a way which matches the equality test.\n        \"\"\"\n        return hash(self.name) + hash(self.version) + hash(self.source_url)\n\n\nclass BaseInstalledDistribution(Distribution):\n    \"\"\"\n    This is the base class for installed distributions (whether PEP 376 or\n    legacy).\n    \"\"\"\n\n    hasher = None\n\n    def __init__(self, metadata, path, env=None):\n        \"\"\"\n        Initialise an instance.\n        :param metadata: An instance of :class:`Metadata` which describes the\n                         distribution. This will normally have been initialised\n                         from a metadata file in the ``path``.\n        :param path:     The path of the ``.dist-info`` or ``.egg-info``\n                         directory for the distribution.\n        :param env:      This is normally the :class:`DistributionPath`\n                         instance where this distribution was found.\n        \"\"\"\n        super(BaseInstalledDistribution, self).__init__(metadata)\n        self.path = path\n        self.dist_path = env\n\n    def get_hash(self, data, hasher=None):\n        \"\"\"\n        Get the hash of some data, using a particular hash algorithm, if\n        specified.\n\n        :param data: The data to be hashed.\n        :type data: bytes\n        :param hasher: The name of a hash implementation, supported by hashlib,\n                       or ``None``. Examples of valid values are ``'sha1'``,\n                       ``'sha224'``, ``'sha384'``, '``sha256'``, ``'md5'`` and\n                       ``'sha512'``. If no hasher is specified, the ``hasher``\n                       attribute of the :class:`InstalledDistribution` instance\n                       is used. If the hasher is determined to be ``None``, MD5\n                       is used as the hashing algorithm.\n        :returns: The hash of the data. If a hasher was explicitly specified,\n                  the returned hash will be prefixed with the specified hasher\n                  followed by '='.\n        :rtype: str\n        \"\"\"\n        if hasher is None:\n            hasher = self.hasher\n        if hasher is None:\n            hasher = hashlib.md5\n            prefix = ''\n        else:\n            hasher = getattr(hashlib, hasher)\n            prefix = '%s=' % self.hasher\n        digest = hasher(data).digest()\n        digest = base64.urlsafe_b64encode(digest).rstrip(b'=').decode('ascii')\n        return '%s%s' % (prefix, digest)\n\n\nclass InstalledDistribution(BaseInstalledDistribution):\n    \"\"\"\n    Created with the *path* of the ``.dist-info`` directory provided to the\n    constructor. It reads the metadata contained in ``pydist.json`` when it is\n    instantiated., or uses a passed in Metadata instance (useful for when\n    dry-run mode is being used).\n    \"\"\"\n\n    hasher = 'sha256'\n\n    def __init__(self, path, metadata=None, env=None):\n        self.modules = []\n        self.finder = finder = resources.finder_for_path(path)\n        if finder is None:\n            raise ValueError('finder unavailable for %s' % path)\n        if env and env._cache_enabled and path in env._cache.path:\n            metadata = env._cache.path[path].metadata\n        elif metadata is None:\n            r = finder.find(METADATA_FILENAME)\n            # Temporary - for Wheel 0.23 support\n            if r is None:\n                r = finder.find(WHEEL_METADATA_FILENAME)\n            # Temporary - for legacy support\n            if r is None:\n                r = finder.find(LEGACY_METADATA_FILENAME)\n            if r is None:\n                raise ValueError('no %s found in %s' %\n                                 (METADATA_FILENAME, path))\n            with contextlib.closing(r.as_stream()) as stream:\n                metadata = Metadata(fileobj=stream, scheme='legacy')\n\n        super(InstalledDistribution, self).__init__(metadata, path, env)\n\n        if env and env._cache_enabled:\n            env._cache.add(self)\n\n        r = finder.find('REQUESTED')\n        self.requested = r is not None\n        p = os.path.join(path, 'top_level.txt')\n        if os.path.exists(p):\n            with open(p, 'rb') as f:\n                data = f.read().decode('utf-8')\n            self.modules = data.splitlines()\n\n    def __repr__(self):\n        return '<InstalledDistribution %r %s at %r>' % (\n            self.name, self.version, self.path)\n\n    def __str__(self):\n        return \"%s %s\" % (self.name, self.version)\n\n    def _get_records(self):\n        \"\"\"\n        Get the list of installed files for the distribution\n        :return: A list of tuples of path, hash and size. Note that hash and\n                 size might be ``None`` for some entries. The path is exactly\n                 as stored in the file (which is as in PEP 376).\n        \"\"\"\n        results = []\n        r = self.get_distinfo_resource('RECORD')\n        with contextlib.closing(r.as_stream()) as stream:\n            with CSVReader(stream=stream) as record_reader:\n                # Base location is parent dir of .dist-info dir\n                # base_location = os.path.dirname(self.path)\n                # base_location = os.path.abspath(base_location)\n                for row in record_reader:\n                    missing = [None for i in range(len(row), 3)]\n                    path, checksum, size = row + missing\n                    # if not os.path.isabs(path):\n                    #     path = path.replace('/', os.sep)\n                    #     path = os.path.join(base_location, path)\n                    results.append((path, checksum, size))\n        return results\n\n    @cached_property\n    def exports(self):\n        \"\"\"\n        Return the information exported by this distribution.\n        :return: A dictionary of exports, mapping an export category to a dict\n                 of :class:`ExportEntry` instances describing the individual\n                 export entries, and keyed by name.\n        \"\"\"\n        result = {}\n        r = self.get_distinfo_resource(EXPORTS_FILENAME)\n        if r:\n            result = self.read_exports()\n        return result\n\n    def read_exports(self):\n        \"\"\"\n        Read exports data from a file in .ini format.\n\n        :return: A dictionary of exports, mapping an export category to a list\n                 of :class:`ExportEntry` instances describing the individual\n                 export entries.\n        \"\"\"\n        result = {}\n        r = self.get_distinfo_resource(EXPORTS_FILENAME)\n        if r:\n            with contextlib.closing(r.as_stream()) as stream:\n                result = read_exports(stream)\n        return result\n\n    def write_exports(self, exports):\n        \"\"\"\n        Write a dictionary of exports to a file in .ini format.\n        :param exports: A dictionary of exports, mapping an export category to\n                        a list of :class:`ExportEntry` instances describing the\n                        individual export entries.\n        \"\"\"\n        rf = self.get_distinfo_file(EXPORTS_FILENAME)\n        with open(rf, 'w') as f:\n            write_exports(exports, f)\n\n    def get_resource_path(self, relative_path):\n        \"\"\"\n        NOTE: This API may change in the future.\n\n        Return the absolute path to a resource file with the given relative\n        path.\n\n        :param relative_path: The path, relative to .dist-info, of the resource\n                              of interest.\n        :return: The absolute path where the resource is to be found.\n        \"\"\"\n        r = self.get_distinfo_resource('RESOURCES')\n        with contextlib.closing(r.as_stream()) as stream:\n            with CSVReader(stream=stream) as resources_reader:\n                for relative, destination in resources_reader:\n                    if relative == relative_path:\n                        return destination\n        raise KeyError('no resource file with relative path %r '\n                       'is installed' % relative_path)\n\n    def list_installed_files(self):\n        \"\"\"\n        Iterates over the ``RECORD`` entries and returns a tuple\n        ``(path, hash, size)`` for each line.\n\n        :returns: iterator of (path, hash, size)\n        \"\"\"\n        for result in self._get_records():\n            yield result\n\n    def write_installed_files(self, paths, prefix, dry_run=False):\n        \"\"\"\n        Writes the ``RECORD`` file, using the ``paths`` iterable passed in. Any\n        existing ``RECORD`` file is silently overwritten.\n\n        prefix is used to determine when to write absolute paths.\n        \"\"\"\n        prefix = os.path.join(prefix, '')\n        base = os.path.dirname(self.path)\n        base_under_prefix = base.startswith(prefix)\n        base = os.path.join(base, '')\n        record_path = self.get_distinfo_file('RECORD')\n        logger.info('creating %s', record_path)\n        if dry_run:\n            return None\n        with CSVWriter(record_path) as writer:\n            for path in paths:\n                if os.path.isdir(path) or path.endswith(('.pyc', '.pyo')):\n                    # do not put size and hash, as in PEP-376\n                    hash_value = size = ''\n                else:\n                    size = '%d' % os.path.getsize(path)\n                    with open(path, 'rb') as fp:\n                        hash_value = self.get_hash(fp.read())\n                if path.startswith(base) or (base_under_prefix\n                                             and path.startswith(prefix)):\n                    path = os.path.relpath(path, base)\n                writer.writerow((path, hash_value, size))\n\n            # add the RECORD file itself\n            if record_path.startswith(base):\n                record_path = os.path.relpath(record_path, base)\n            writer.writerow((record_path, '', ''))\n        return record_path\n\n    def check_installed_files(self):\n        \"\"\"\n        Checks that the hashes and sizes of the files in ``RECORD`` are\n        matched by the files themselves. Returns a (possibly empty) list of\n        mismatches. Each entry in the mismatch list will be a tuple consisting\n        of the path, 'exists', 'size' or 'hash' according to what didn't match\n        (existence is checked first, then size, then hash), the expected\n        value and the actual value.\n        \"\"\"\n        mismatches = []\n        base = os.path.dirname(self.path)\n        record_path = self.get_distinfo_file('RECORD')\n        for path, hash_value, size in self.list_installed_files():\n            if not os.path.isabs(path):\n                path = os.path.join(base, path)\n            if path == record_path:\n                continue\n            if not os.path.exists(path):\n                mismatches.append((path, 'exists', True, False))\n            elif os.path.isfile(path):\n                actual_size = str(os.path.getsize(path))\n                if size and actual_size != size:\n                    mismatches.append((path, 'size', size, actual_size))\n                elif hash_value:\n                    if '=' in hash_value:\n                        hasher = hash_value.split('=', 1)[0]\n                    else:\n                        hasher = None\n\n                    with open(path, 'rb') as f:\n                        actual_hash = self.get_hash(f.read(), hasher)\n                        if actual_hash != hash_value:\n                            mismatches.append(\n                                (path, 'hash', hash_value, actual_hash))\n        return mismatches\n\n    @cached_property\n    def shared_locations(self):\n        \"\"\"\n        A dictionary of shared locations whose keys are in the set 'prefix',\n        'purelib', 'platlib', 'scripts', 'headers', 'data' and 'namespace'.\n        The corresponding value is the absolute path of that category for\n        this distribution, and takes into account any paths selected by the\n        user at installation time (e.g. via command-line arguments). In the\n        case of the 'namespace' key, this would be a list of absolute paths\n        for the roots of namespace packages in this distribution.\n\n        The first time this property is accessed, the relevant information is\n        read from the SHARED file in the .dist-info directory.\n        \"\"\"\n        result = {}\n        shared_path = os.path.join(self.path, 'SHARED')\n        if os.path.isfile(shared_path):\n            with codecs.open(shared_path, 'r', encoding='utf-8') as f:\n                lines = f.read().splitlines()\n            for line in lines:\n                key, value = line.split('=', 1)\n                if key == 'namespace':\n                    result.setdefault(key, []).append(value)\n                else:\n                    result[key] = value\n        return result\n\n    def write_shared_locations(self, paths, dry_run=False):\n        \"\"\"\n        Write shared location information to the SHARED file in .dist-info.\n        :param paths: A dictionary as described in the documentation for\n        :meth:`shared_locations`.\n        :param dry_run: If True, the action is logged but no file is actually\n                        written.\n        :return: The path of the file written to.\n        \"\"\"\n        shared_path = os.path.join(self.path, 'SHARED')\n        logger.info('creating %s', shared_path)\n        if dry_run:\n            return None\n        lines = []\n        for key in ('prefix', 'lib', 'headers', 'scripts', 'data'):\n            path = paths[key]\n            if os.path.isdir(paths[key]):\n                lines.append('%s=%s' % (key, path))\n        for ns in paths.get('namespace', ()):\n            lines.append('namespace=%s' % ns)\n\n        with codecs.open(shared_path, 'w', encoding='utf-8') as f:\n            f.write('\\n'.join(lines))\n        return shared_path\n\n    def get_distinfo_resource(self, path):\n        if path not in DIST_FILES:\n            raise DistlibException('invalid path for a dist-info file: '\n                                   '%r at %r' % (path, self.path))\n        finder = resources.finder_for_path(self.path)\n        if finder is None:\n            raise DistlibException('Unable to get a finder for %s' % self.path)\n        return finder.find(path)\n\n    def get_distinfo_file(self, path):\n        \"\"\"\n        Returns a path located under the ``.dist-info`` directory. Returns a\n        string representing the path.\n\n        :parameter path: a ``'/'``-separated path relative to the\n                         ``.dist-info`` directory or an absolute path;\n                         If *path* is an absolute path and doesn't start\n                         with the ``.dist-info`` directory path,\n                         a :class:`DistlibException` is raised\n        :type path: str\n        :rtype: str\n        \"\"\"\n        # Check if it is an absolute path  # XXX use relpath, add tests\n        if path.find(os.sep) >= 0:\n            # it's an absolute path?\n            distinfo_dirname, path = path.split(os.sep)[-2:]\n            if distinfo_dirname != self.path.split(os.sep)[-1]:\n                raise DistlibException(\n                    'dist-info file %r does not belong to the %r %s '\n                    'distribution' % (path, self.name, self.version))\n\n        # The file must be relative\n        if path not in DIST_FILES:\n            raise DistlibException('invalid path for a dist-info file: '\n                                   '%r at %r' % (path, self.path))\n\n        return os.path.join(self.path, path)\n\n    def list_distinfo_files(self):\n        \"\"\"\n        Iterates over the ``RECORD`` entries and returns paths for each line if\n        the path is pointing to a file located in the ``.dist-info`` directory\n        or one of its subdirectories.\n\n        :returns: iterator of paths\n        \"\"\"\n        base = os.path.dirname(self.path)\n        for path, checksum, size in self._get_records():\n            # XXX add separator or use real relpath algo\n            if not os.path.isabs(path):\n                path = os.path.join(base, path)\n            if path.startswith(self.path):\n                yield path\n\n    def __eq__(self, other):\n        return (isinstance(other, InstalledDistribution)\n                and self.path == other.path)\n\n    # See http://docs.python.org/reference/datamodel#object.__hash__\n    __hash__ = object.__hash__\n\n\nclass EggInfoDistribution(BaseInstalledDistribution):\n    \"\"\"Created with the *path* of the ``.egg-info`` directory or file provided\n    to the constructor. It reads the metadata contained in the file itself, or\n    if the given path happens to be a directory, the metadata is read from the\n    file ``PKG-INFO`` under that directory.\"\"\"\n\n    requested = True  # as we have no way of knowing, assume it was\n    shared_locations = {}\n\n    def __init__(self, path, env=None):\n\n        def set_name_and_version(s, n, v):\n            s.name = n\n            s.key = n.lower()  # for case-insensitive comparisons\n            s.version = v\n\n        self.path = path\n        self.dist_path = env\n        if env and env._cache_enabled and path in env._cache_egg.path:\n            metadata = env._cache_egg.path[path].metadata\n            set_name_and_version(self, metadata.name, metadata.version)\n        else:\n            metadata = self._get_metadata(path)\n\n            # Need to be set before caching\n            set_name_and_version(self, metadata.name, metadata.version)\n\n            if env and env._cache_enabled:\n                env._cache_egg.add(self)\n        super(EggInfoDistribution, self).__init__(metadata, path, env)\n\n    def _get_metadata(self, path):\n        requires = None\n\n        def parse_requires_data(data):\n            \"\"\"Create a list of dependencies from a requires.txt file.\n\n            *data*: the contents of a setuptools-produced requires.txt file.\n            \"\"\"\n            reqs = []\n            lines = data.splitlines()\n            for line in lines:\n                line = line.strip()\n                # sectioned files have bare newlines (separating sections)\n                if not line:  # pragma: no cover\n                    continue\n                if line.startswith('['):  # pragma: no cover\n                    logger.warning(\n                        'Unexpected line: quitting requirement scan: %r', line)\n                    break\n                r = parse_requirement(line)\n                if not r:  # pragma: no cover\n                    logger.warning('Not recognised as a requirement: %r', line)\n                    continue\n                if r.extras:  # pragma: no cover\n                    logger.warning('extra requirements in requires.txt are '\n                                   'not supported')\n                if not r.constraints:\n                    reqs.append(r.name)\n                else:\n                    cons = ', '.join('%s%s' % c for c in r.constraints)\n                    reqs.append('%s (%s)' % (r.name, cons))\n            return reqs\n\n        def parse_requires_path(req_path):\n            \"\"\"Create a list of dependencies from a requires.txt file.\n\n            *req_path*: the path to a setuptools-produced requires.txt file.\n            \"\"\"\n\n            reqs = []\n            try:\n                with codecs.open(req_path, 'r', 'utf-8') as fp:\n                    reqs = parse_requires_data(fp.read())\n            except IOError:\n                pass\n            return reqs\n\n        tl_path = tl_data = None\n        if path.endswith('.egg'):\n            if os.path.isdir(path):\n                p = os.path.join(path, 'EGG-INFO')\n                meta_path = os.path.join(p, 'PKG-INFO')\n                metadata = Metadata(path=meta_path, scheme='legacy')\n                req_path = os.path.join(p, 'requires.txt')\n                tl_path = os.path.join(p, 'top_level.txt')\n                requires = parse_requires_path(req_path)\n            else:\n                # FIXME handle the case where zipfile is not available\n                zipf = zipimport.zipimporter(path)\n                fileobj = StringIO(\n                    zipf.get_data('EGG-INFO/PKG-INFO').decode('utf8'))\n                metadata = Metadata(fileobj=fileobj, scheme='legacy')\n                try:\n                    data = zipf.get_data('EGG-INFO/requires.txt')\n                    tl_data = zipf.get_data('EGG-INFO/top_level.txt').decode(\n                        'utf-8')\n                    requires = parse_requires_data(data.decode('utf-8'))\n                except IOError:\n                    requires = None\n        elif path.endswith('.egg-info'):\n            if os.path.isdir(path):\n                req_path = os.path.join(path, 'requires.txt')\n                requires = parse_requires_path(req_path)\n                path = os.path.join(path, 'PKG-INFO')\n                tl_path = os.path.join(path, 'top_level.txt')\n            metadata = Metadata(path=path, scheme='legacy')\n        else:\n            raise DistlibException('path must end with .egg-info or .egg, '\n                                   'got %r' % path)\n\n        if requires:\n            metadata.add_requirements(requires)\n        # look for top-level modules in top_level.txt, if present\n        if tl_data is None:\n            if tl_path is not None and os.path.exists(tl_path):\n                with open(tl_path, 'rb') as f:\n                    tl_data = f.read().decode('utf-8')\n        if not tl_data:\n            tl_data = []\n        else:\n            tl_data = tl_data.splitlines()\n        self.modules = tl_data\n        return metadata\n\n    def __repr__(self):\n        return '<EggInfoDistribution %r %s at %r>' % (self.name, self.version,\n                                                      self.path)\n\n    def __str__(self):\n        return \"%s %s\" % (self.name, self.version)\n\n    def check_installed_files(self):\n        \"\"\"\n        Checks that the hashes and sizes of the files in ``RECORD`` are\n        matched by the files themselves. Returns a (possibly empty) list of\n        mismatches. Each entry in the mismatch list will be a tuple consisting\n        of the path, 'exists', 'size' or 'hash' according to what didn't match\n        (existence is checked first, then size, then hash), the expected\n        value and the actual value.\n        \"\"\"\n        mismatches = []\n        record_path = os.path.join(self.path, 'installed-files.txt')\n        if os.path.exists(record_path):\n            for path, _, _ in self.list_installed_files():\n                if path == record_path:\n                    continue\n                if not os.path.exists(path):\n                    mismatches.append((path, 'exists', True, False))\n        return mismatches\n\n    def list_installed_files(self):\n        \"\"\"\n        Iterates over the ``installed-files.txt`` entries and returns a tuple\n        ``(path, hash, size)`` for each line.\n\n        :returns: a list of (path, hash, size)\n        \"\"\"\n\n        def _md5(path):\n            f = open(path, 'rb')\n            try:\n                content = f.read()\n            finally:\n                f.close()\n            return hashlib.md5(content).hexdigest()\n\n        def _size(path):\n            return os.stat(path).st_size\n\n        record_path = os.path.join(self.path, 'installed-files.txt')\n        result = []\n        if os.path.exists(record_path):\n            with codecs.open(record_path, 'r', encoding='utf-8') as f:\n                for line in f:\n                    line = line.strip()\n                    p = os.path.normpath(os.path.join(self.path, line))\n                    # \"./\" is present as a marker between installed files\n                    # and installation metadata files\n                    if not os.path.exists(p):\n                        logger.warning('Non-existent file: %s', p)\n                        if p.endswith(('.pyc', '.pyo')):\n                            continue\n                        # otherwise fall through and fail\n                    if not os.path.isdir(p):\n                        result.append((p, _md5(p), _size(p)))\n            result.append((record_path, None, None))\n        return result\n\n    def list_distinfo_files(self, absolute=False):\n        \"\"\"\n        Iterates over the ``installed-files.txt`` entries and returns paths for\n        each line if the path is pointing to a file located in the\n        ``.egg-info`` directory or one of its subdirectories.\n\n        :parameter absolute: If *absolute* is ``True``, each returned path is\n                          transformed into a local absolute path. Otherwise the\n                          raw value from ``installed-files.txt`` is returned.\n        :type absolute: boolean\n        :returns: iterator of paths\n        \"\"\"\n        record_path = os.path.join(self.path, 'installed-files.txt')\n        if os.path.exists(record_path):\n            skip = True\n            with codecs.open(record_path, 'r', encoding='utf-8') as f:\n                for line in f:\n                    line = line.strip()\n                    if line == './':\n                        skip = False\n                        continue\n                    if not skip:\n                        p = os.path.normpath(os.path.join(self.path, line))\n                        if p.startswith(self.path):\n                            if absolute:\n                                yield p\n                            else:\n                                yield line\n\n    def __eq__(self, other):\n        return (isinstance(other, EggInfoDistribution)\n                and self.path == other.path)\n\n    # See http://docs.python.org/reference/datamodel#object.__hash__\n    __hash__ = object.__hash__\n\n\nnew_dist_class = InstalledDistribution\nold_dist_class = EggInfoDistribution\n\n\nclass DependencyGraph(object):\n    \"\"\"\n    Represents a dependency graph between distributions.\n\n    The dependency relationships are stored in an ``adjacency_list`` that maps\n    distributions to a list of ``(other, label)`` tuples where  ``other``\n    is a distribution and the edge is labeled with ``label`` (i.e. the version\n    specifier, if such was provided). Also, for more efficient traversal, for\n    every distribution ``x``, a list of predecessors is kept in\n    ``reverse_list[x]``. An edge from distribution ``a`` to\n    distribution ``b`` means that ``a`` depends on ``b``. If any missing\n    dependencies are found, they are stored in ``missing``, which is a\n    dictionary that maps distributions to a list of requirements that were not\n    provided by any other distributions.\n    \"\"\"\n\n    def __init__(self):\n        self.adjacency_list = {}\n        self.reverse_list = {}\n        self.missing = {}\n\n    def add_distribution(self, distribution):\n        \"\"\"Add the *distribution* to the graph.\n\n        :type distribution: :class:`distutils2.database.InstalledDistribution`\n                            or :class:`distutils2.database.EggInfoDistribution`\n        \"\"\"\n        self.adjacency_list[distribution] = []\n        self.reverse_list[distribution] = []\n        # self.missing[distribution] = []\n\n    def add_edge(self, x, y, label=None):\n        \"\"\"Add an edge from distribution *x* to distribution *y* with the given\n        *label*.\n\n        :type x: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type y: :class:`distutils2.database.InstalledDistribution` or\n                 :class:`distutils2.database.EggInfoDistribution`\n        :type label: ``str`` or ``None``\n        \"\"\"\n        self.adjacency_list[x].append((y, label))\n        # multiple edges are allowed, so be careful\n        if x not in self.reverse_list[y]:\n            self.reverse_list[y].append(x)\n\n    def add_missing(self, distribution, requirement):\n        \"\"\"\n        Add a missing *requirement* for the given *distribution*.\n\n        :type distribution: :class:`distutils2.database.InstalledDistribution`\n                            or :class:`distutils2.database.EggInfoDistribution`\n        :type requirement: ``str``\n        \"\"\"\n        logger.debug('%s missing %r', distribution, requirement)\n        self.missing.setdefault(distribution, []).append(requirement)\n\n    def _repr_dist(self, dist):\n        return '%s %s' % (dist.name, dist.version)\n\n    def repr_node(self, dist, level=1):\n        \"\"\"Prints only a subgraph\"\"\"\n        output = [self._repr_dist(dist)]\n        for other, label in self.adjacency_list[dist]:\n            dist = self._repr_dist(other)\n            if label is not None:\n                dist = '%s [%s]' % (dist, label)\n            output.append('    ' * level + str(dist))\n            suboutput = self.repr_node(other, level + 1)\n            subs = suboutput.split('\\n')\n            output.extend(subs[1:])\n        return '\\n'.join(output)\n\n    def to_dot(self, f, skip_disconnected=True):\n        \"\"\"Writes a DOT output for the graph to the provided file *f*.\n\n        If *skip_disconnected* is set to ``True``, then all distributions\n        that are not dependent on any other distribution are skipped.\n\n        :type f: has to support ``file``-like operations\n        :type skip_disconnected: ``bool``\n        \"\"\"\n        disconnected = []\n\n        f.write(\"digraph dependencies {\\n\")\n        for dist, adjs in self.adjacency_list.items():\n            if len(adjs) == 0 and not skip_disconnected:\n                disconnected.append(dist)\n            for other, label in adjs:\n                if label is not None:\n                    f.write('\"%s\" -> \"%s\" [label=\"%s\"]\\n' %\n                            (dist.name, other.name, label))\n                else:\n                    f.write('\"%s\" -> \"%s\"\\n' % (dist.name, other.name))\n        if not skip_disconnected and len(disconnected) > 0:\n            f.write('subgraph disconnected {\\n')\n            f.write('label = \"Disconnected\"\\n')\n            f.write('bgcolor = red\\n')\n\n            for dist in disconnected:\n                f.write('\"%s\"' % dist.name)\n                f.write('\\n')\n            f.write('}\\n')\n        f.write('}\\n')\n\n    def topological_sort(self):\n        \"\"\"\n        Perform a topological sort of the graph.\n        :return: A tuple, the first element of which is a topologically sorted\n                 list of distributions, and the second element of which is a\n                 list of distributions that cannot be sorted because they have\n                 circular dependencies and so form a cycle.\n        \"\"\"\n        result = []\n        # Make a shallow copy of the adjacency list\n        alist = {}\n        for k, v in self.adjacency_list.items():\n            alist[k] = v[:]\n        while True:\n            # See what we can remove in this run\n            to_remove = []\n            for k, v in list(alist.items())[:]:\n                if not v:\n                    to_remove.append(k)\n                    del alist[k]\n            if not to_remove:\n                # What's left in alist (if anything) is a cycle.\n                break\n            # Remove from the adjacency list of others\n            for k, v in alist.items():\n                alist[k] = [(d, r) for d, r in v if d not in to_remove]\n            logger.debug('Moving to result: %s',\n                         ['%s (%s)' % (d.name, d.version) for d in to_remove])\n            result.extend(to_remove)\n        return result, list(alist.keys())\n\n    def __repr__(self):\n        \"\"\"Representation of the graph\"\"\"\n        output = []\n        for dist, adjs in self.adjacency_list.items():\n            output.append(self.repr_node(dist))\n        return '\\n'.join(output)\n\n\ndef make_graph(dists, scheme='default'):\n    \"\"\"Makes a dependency graph from the given distributions.\n\n    :parameter dists: a list of distributions\n    :type dists: list of :class:`distutils2.database.InstalledDistribution` and\n                 :class:`distutils2.database.EggInfoDistribution` instances\n    :rtype: a :class:`DependencyGraph` instance\n    \"\"\"\n    scheme = get_scheme(scheme)\n    graph = DependencyGraph()\n    provided = {}  # maps names to lists of (version, dist) tuples\n\n    # first, build the graph and find out what's provided\n    for dist in dists:\n        graph.add_distribution(dist)\n\n        for p in dist.provides:\n            name, version = parse_name_and_version(p)\n            logger.debug('Add to provided: %s, %s, %s', name, version, dist)\n            provided.setdefault(name, []).append((version, dist))\n\n    # now make the edges\n    for dist in dists:\n        requires = (dist.run_requires | dist.meta_requires\n                    | dist.build_requires | dist.dev_requires)\n        for req in requires:\n            try:\n                matcher = scheme.matcher(req)\n            except UnsupportedVersionError:\n                # XXX compat-mode if cannot read the version\n                logger.warning('could not read version %r - using name only',\n                               req)\n                name = req.split()[0]\n                matcher = scheme.matcher(name)\n\n            name = matcher.key  # case-insensitive\n\n            matched = False\n            if name in provided:\n                for version, provider in provided[name]:\n                    try:\n                        match = matcher.match(version)\n                    except UnsupportedVersionError:\n                        match = False\n\n                    if match:\n                        graph.add_edge(dist, provider, req)\n                        matched = True\n                        break\n            if not matched:\n                graph.add_missing(dist, req)\n    return graph\n\n\ndef get_dependent_dists(dists, dist):\n    \"\"\"Recursively generate a list of distributions from *dists* that are\n    dependent on *dist*.\n\n    :param dists: a list of distributions\n    :param dist: a distribution, member of *dists* for which we are interested\n    \"\"\"\n    if dist not in dists:\n        raise DistlibException('given distribution %r is not a member '\n                               'of the list' % dist.name)\n    graph = make_graph(dists)\n\n    dep = [dist]  # dependent distributions\n    todo = graph.reverse_list[dist]  # list of nodes we should inspect\n\n    while todo:\n        d = todo.pop()\n        dep.append(d)\n        for succ in graph.reverse_list[d]:\n            if succ not in dep:\n                todo.append(succ)\n\n    dep.pop(0)  # remove dist from dep, was there to prevent infinite loops\n    return dep\n\n\ndef get_required_dists(dists, dist):\n    \"\"\"Recursively generate a list of distributions from *dists* that are\n    required by *dist*.\n\n    :param dists: a list of distributions\n    :param dist: a distribution, member of *dists* for which we are interested\n                 in finding the dependencies.\n    \"\"\"\n    if dist not in dists:\n        raise DistlibException('given distribution %r is not a member '\n                               'of the list' % dist.name)\n    graph = make_graph(dists)\n\n    req = set()  # required distributions\n    todo = graph.adjacency_list[dist]  # list of nodes we should inspect\n    seen = set(t[0] for t in todo)  # already added to todo\n\n    while todo:\n        d = todo.pop()[0]\n        req.add(d)\n        pred_list = graph.adjacency_list[d]\n        for pred in pred_list:\n            d = pred[0]\n            if d not in req and d not in seen:\n                seen.add(d)\n                todo.append(pred)\n    return req\n\n\ndef make_dist(name, version, **kwargs):\n    \"\"\"\n    A convenience method for making a dist given just a name and version.\n    \"\"\"\n    summary = kwargs.pop('summary', 'Placeholder for summary')\n    md = Metadata(**kwargs)\n    md.name = name\n    md.version = version\n    md.summary = summary or 'Placeholder for summary'\n    return Distribution(md)\n"},"hash":"zvhEgSuKec"}