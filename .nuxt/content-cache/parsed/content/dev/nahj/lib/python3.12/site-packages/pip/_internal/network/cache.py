{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_internal:network:cache.py","body":"\"\"\"HTTP cache implementation.\n\"\"\"\n\nimport os\nfrom contextlib import contextmanager\nfrom datetime import datetime\nfrom typing import BinaryIO, Generator, Optional, Union\n\nfrom pip._vendor.cachecontrol.cache import SeparateBodyBaseCache\nfrom pip._vendor.cachecontrol.caches import SeparateBodyFileCache\nfrom pip._vendor.requests.models import Response\n\nfrom pip._internal.utils.filesystem import adjacent_tmp_file, replace\nfrom pip._internal.utils.misc import ensure_dir\n\n\ndef is_from_cache(response: Response) -> bool:\n    return getattr(response, \"from_cache\", False)\n\n\n@contextmanager\ndef suppressed_cache_errors() -> Generator[None, None, None]:\n    \"\"\"If we can't access the cache then we can just skip caching and process\n    requests as if caching wasn't enabled.\n    \"\"\"\n    try:\n        yield\n    except OSError:\n        pass\n\n\nclass SafeFileCache(SeparateBodyBaseCache):\n    \"\"\"\n    A file based cache which is safe to use even when the target directory may\n    not be accessible or writable.\n\n    There is a race condition when two processes try to write and/or read the\n    same entry at the same time, since each entry consists of two separate\n    files (https://github.com/psf/cachecontrol/issues/324).  We therefore have\n    additional logic that makes sure that both files to be present before\n    returning an entry; this fixes the read side of the race condition.\n\n    For the write side, we assume that the server will only ever return the\n    same data for the same URL, which ought to be the case for files pip is\n    downloading.  PyPI does not have a mechanism to swap out a wheel for\n    another wheel, for example.  If this assumption is not true, the\n    CacheControl issue will need to be fixed.\n    \"\"\"\n\n    def __init__(self, directory: str) -> None:\n        assert directory is not None, \"Cache directory must not be None.\"\n        super().__init__()\n        self.directory = directory\n\n    def _get_cache_path(self, name: str) -> str:\n        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our\n        # class for backwards-compatibility and to avoid using a non-public\n        # method.\n        hashed = SeparateBodyFileCache.encode(name)\n        parts = list(hashed[:5]) + [hashed]\n        return os.path.join(self.directory, *parts)\n\n    def get(self, key: str) -> Optional[bytes]:\n        # The cache entry is only valid if both metadata and body exist.\n        metadata_path = self._get_cache_path(key)\n        body_path = metadata_path + \".body\"\n        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):\n            return None\n        with suppressed_cache_errors():\n            with open(metadata_path, \"rb\") as f:\n                return f.read()\n\n    def _write(self, path: str, data: bytes) -> None:\n        with suppressed_cache_errors():\n            ensure_dir(os.path.dirname(path))\n\n            with adjacent_tmp_file(path) as f:\n                f.write(data)\n\n            replace(f.name, path)\n\n    def set(\n        self, key: str, value: bytes, expires: Union[int, datetime, None] = None\n    ) -> None:\n        path = self._get_cache_path(key)\n        self._write(path, value)\n\n    def delete(self, key: str) -> None:\n        path = self._get_cache_path(key)\n        with suppressed_cache_errors():\n            os.remove(path)\n        with suppressed_cache_errors():\n            os.remove(path + \".body\")\n\n    def get_body(self, key: str) -> Optional[BinaryIO]:\n        # The cache entry is only valid if both metadata and body exist.\n        metadata_path = self._get_cache_path(key)\n        body_path = metadata_path + \".body\"\n        if not (os.path.exists(metadata_path) and os.path.exists(body_path)):\n            return None\n        with suppressed_cache_errors():\n            return open(body_path, \"rb\")\n\n    def set_body(self, key: str, body: bytes) -> None:\n        path = self._get_cache_path(key) + \".body\"\n        self._write(path, body)\n"},"hash":"8qZT7QiuKt"}