{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:cachecontrol:controller.py","body":"# SPDX-FileCopyrightText: 2015 Eric Larson\n#\n# SPDX-License-Identifier: Apache-2.0\n\n\"\"\"\nThe httplib2 algorithms ported for use with requests.\n\"\"\"\nfrom __future__ import annotations\n\nimport calendar\nimport logging\nimport re\nimport time\nfrom email.utils import parsedate_tz\nfrom typing import TYPE_CHECKING, Collection, Mapping\n\nfrom pip._vendor.requests.structures import CaseInsensitiveDict\n\nfrom pip._vendor.cachecontrol.cache import DictCache, SeparateBodyBaseCache\nfrom pip._vendor.cachecontrol.serialize import Serializer\n\nif TYPE_CHECKING:\n    from typing import Literal\n\n    from pip._vendor.requests import PreparedRequest\n    from pip._vendor.urllib3 import HTTPResponse\n\n    from pip._vendor.cachecontrol.cache import BaseCache\n\nlogger = logging.getLogger(__name__)\n\nURI = re.compile(r\"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?\")\n\nPERMANENT_REDIRECT_STATUSES = (301, 308)\n\n\ndef parse_uri(uri: str) -> tuple[str, str, str, str, str]:\n    \"\"\"Parses a URI using the regex given in Appendix B of RFC 3986.\n\n    (scheme, authority, path, query, fragment) = parse_uri(uri)\n    \"\"\"\n    match = URI.match(uri)\n    assert match is not None\n    groups = match.groups()\n    return (groups[1], groups[3], groups[4], groups[6], groups[8])\n\n\nclass CacheController:\n    \"\"\"An interface to see if request should cached or not.\"\"\"\n\n    def __init__(\n        self,\n        cache: BaseCache | None = None,\n        cache_etags: bool = True,\n        serializer: Serializer | None = None,\n        status_codes: Collection[int] | None = None,\n    ):\n        self.cache = DictCache() if cache is None else cache\n        self.cache_etags = cache_etags\n        self.serializer = serializer or Serializer()\n        self.cacheable_status_codes = status_codes or (200, 203, 300, 301, 308)\n\n    @classmethod\n    def _urlnorm(cls, uri: str) -> str:\n        \"\"\"Normalize the URL to create a safe key for the cache\"\"\"\n        (scheme, authority, path, query, fragment) = parse_uri(uri)\n        if not scheme or not authority:\n            raise Exception(\"Only absolute URIs are allowed. uri = %s\" % uri)\n\n        scheme = scheme.lower()\n        authority = authority.lower()\n\n        if not path:\n            path = \"/\"\n\n        # Could do syntax based normalization of the URI before\n        # computing the digest. See Section 6.2.2 of Std 66.\n        request_uri = query and \"?\".join([path, query]) or path\n        defrag_uri = scheme + \"://\" + authority + request_uri\n\n        return defrag_uri\n\n    @classmethod\n    def cache_url(cls, uri: str) -> str:\n        return cls._urlnorm(uri)\n\n    def parse_cache_control(self, headers: Mapping[str, str]) -> dict[str, int | None]:\n        known_directives = {\n            # https://tools.ietf.org/html/rfc7234#section-5.2\n            \"max-age\": (int, True),\n            \"max-stale\": (int, False),\n            \"min-fresh\": (int, True),\n            \"no-cache\": (None, False),\n            \"no-store\": (None, False),\n            \"no-transform\": (None, False),\n            \"only-if-cached\": (None, False),\n            \"must-revalidate\": (None, False),\n            \"public\": (None, False),\n            \"private\": (None, False),\n            \"proxy-revalidate\": (None, False),\n            \"s-maxage\": (int, True),\n        }\n\n        cc_headers = headers.get(\"cache-control\", headers.get(\"Cache-Control\", \"\"))\n\n        retval: dict[str, int | None] = {}\n\n        for cc_directive in cc_headers.split(\",\"):\n            if not cc_directive.strip():\n                continue\n\n            parts = cc_directive.split(\"=\", 1)\n            directive = parts[0].strip()\n\n            try:\n                typ, required = known_directives[directive]\n            except KeyError:\n                logger.debug(\"Ignoring unknown cache-control directive: %s\", directive)\n                continue\n\n            if not typ or not required:\n                retval[directive] = None\n            if typ:\n                try:\n                    retval[directive] = typ(parts[1].strip())\n                except IndexError:\n                    if required:\n                        logger.debug(\n                            \"Missing value for cache-control \" \"directive: %s\",\n                            directive,\n                        )\n                except ValueError:\n                    logger.debug(\n                        \"Invalid value for cache-control directive \" \"%s, must be %s\",\n                        directive,\n                        typ.__name__,\n                    )\n\n        return retval\n\n    def _load_from_cache(self, request: PreparedRequest) -> HTTPResponse | None:\n        \"\"\"\n        Load a cached response, or return None if it's not available.\n        \"\"\"\n        cache_url = request.url\n        assert cache_url is not None\n        cache_data = self.cache.get(cache_url)\n        if cache_data is None:\n            logger.debug(\"No cache entry available\")\n            return None\n\n        if isinstance(self.cache, SeparateBodyBaseCache):\n            body_file = self.cache.get_body(cache_url)\n        else:\n            body_file = None\n\n        result = self.serializer.loads(request, cache_data, body_file)\n        if result is None:\n            logger.warning(\"Cache entry deserialization failed, entry ignored\")\n        return result\n\n    def cached_request(self, request: PreparedRequest) -> HTTPResponse | Literal[False]:\n        \"\"\"\n        Return a cached response if it exists in the cache, otherwise\n        return False.\n        \"\"\"\n        assert request.url is not None\n        cache_url = self.cache_url(request.url)\n        logger.debug('Looking up \"%s\" in the cache', cache_url)\n        cc = self.parse_cache_control(request.headers)\n\n        # Bail out if the request insists on fresh data\n        if \"no-cache\" in cc:\n            logger.debug('Request header has \"no-cache\", cache bypassed')\n            return False\n\n        if \"max-age\" in cc and cc[\"max-age\"] == 0:\n            logger.debug('Request header has \"max_age\" as 0, cache bypassed')\n            return False\n\n        # Check whether we can load the response from the cache:\n        resp = self._load_from_cache(request)\n        if not resp:\n            return False\n\n        # If we have a cached permanent redirect, return it immediately. We\n        # don't need to test our response for other headers b/c it is\n        # intrinsically \"cacheable\" as it is Permanent.\n        #\n        # See:\n        #   https://tools.ietf.org/html/rfc7231#section-6.4.2\n        #\n        # Client can try to refresh the value by repeating the request\n        # with cache busting headers as usual (ie no-cache).\n        if int(resp.status) in PERMANENT_REDIRECT_STATUSES:\n            msg = (\n                \"Returning cached permanent redirect response \"\n                \"(ignoring date and etag information)\"\n            )\n            logger.debug(msg)\n            return resp\n\n        headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)\n        if not headers or \"date\" not in headers:\n            if \"etag\" not in headers:\n                # Without date or etag, the cached response can never be used\n                # and should be deleted.\n                logger.debug(\"Purging cached response: no date or etag\")\n                self.cache.delete(cache_url)\n            logger.debug(\"Ignoring cached response: no date\")\n            return False\n\n        now = time.time()\n        time_tuple = parsedate_tz(headers[\"date\"])\n        assert time_tuple is not None\n        date = calendar.timegm(time_tuple[:6])\n        current_age = max(0, now - date)\n        logger.debug(\"Current age based on date: %i\", current_age)\n\n        # TODO: There is an assumption that the result will be a\n        #       urllib3 response object. This may not be best since we\n        #       could probably avoid instantiating or constructing the\n        #       response until we know we need it.\n        resp_cc = self.parse_cache_control(headers)\n\n        # determine freshness\n        freshness_lifetime = 0\n\n        # Check the max-age pragma in the cache control header\n        max_age = resp_cc.get(\"max-age\")\n        if max_age is not None:\n            freshness_lifetime = max_age\n            logger.debug(\"Freshness lifetime from max-age: %i\", freshness_lifetime)\n\n        # If there isn't a max-age, check for an expires header\n        elif \"expires\" in headers:\n            expires = parsedate_tz(headers[\"expires\"])\n            if expires is not None:\n                expire_time = calendar.timegm(expires[:6]) - date\n                freshness_lifetime = max(0, expire_time)\n                logger.debug(\"Freshness lifetime from expires: %i\", freshness_lifetime)\n\n        # Determine if we are setting freshness limit in the\n        # request. Note, this overrides what was in the response.\n        max_age = cc.get(\"max-age\")\n        if max_age is not None:\n            freshness_lifetime = max_age\n            logger.debug(\n                \"Freshness lifetime from request max-age: %i\", freshness_lifetime\n            )\n\n        min_fresh = cc.get(\"min-fresh\")\n        if min_fresh is not None:\n            # adjust our current age by our min fresh\n            current_age += min_fresh\n            logger.debug(\"Adjusted current age from min-fresh: %i\", current_age)\n\n        # Return entry if it is fresh enough\n        if freshness_lifetime > current_age:\n            logger.debug('The response is \"fresh\", returning cached response')\n            logger.debug(\"%i > %i\", freshness_lifetime, current_age)\n            return resp\n\n        # we're not fresh. If we don't have an Etag, clear it out\n        if \"etag\" not in headers:\n            logger.debug('The cached response is \"stale\" with no etag, purging')\n            self.cache.delete(cache_url)\n\n        # return the original handler\n        return False\n\n    def conditional_headers(self, request: PreparedRequest) -> dict[str, str]:\n        resp = self._load_from_cache(request)\n        new_headers = {}\n\n        if resp:\n            headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(resp.headers)\n\n            if \"etag\" in headers:\n                new_headers[\"If-None-Match\"] = headers[\"ETag\"]\n\n            if \"last-modified\" in headers:\n                new_headers[\"If-Modified-Since\"] = headers[\"Last-Modified\"]\n\n        return new_headers\n\n    def _cache_set(\n        self,\n        cache_url: str,\n        request: PreparedRequest,\n        response: HTTPResponse,\n        body: bytes | None = None,\n        expires_time: int | None = None,\n    ) -> None:\n        \"\"\"\n        Store the data in the cache.\n        \"\"\"\n        if isinstance(self.cache, SeparateBodyBaseCache):\n            # We pass in the body separately; just put a placeholder empty\n            # string in the metadata.\n            self.cache.set(\n                cache_url,\n                self.serializer.dumps(request, response, b\"\"),\n                expires=expires_time,\n            )\n            # body is None can happen when, for example, we're only updating\n            # headers, as is the case in update_cached_response().\n            if body is not None:\n                self.cache.set_body(cache_url, body)\n        else:\n            self.cache.set(\n                cache_url,\n                self.serializer.dumps(request, response, body),\n                expires=expires_time,\n            )\n\n    def cache_response(\n        self,\n        request: PreparedRequest,\n        response: HTTPResponse,\n        body: bytes | None = None,\n        status_codes: Collection[int] | None = None,\n    ) -> None:\n        \"\"\"\n        Algorithm for caching requests.\n\n        This assumes a requests Response object.\n        \"\"\"\n        # From httplib2: Don't cache 206's since we aren't going to\n        #                handle byte range requests\n        cacheable_status_codes = status_codes or self.cacheable_status_codes\n        if response.status not in cacheable_status_codes:\n            logger.debug(\n                \"Status code %s not in %s\", response.status, cacheable_status_codes\n            )\n            return\n\n        response_headers: CaseInsensitiveDict[str] = CaseInsensitiveDict(\n            response.headers\n        )\n\n        if \"date\" in response_headers:\n            time_tuple = parsedate_tz(response_headers[\"date\"])\n            assert time_tuple is not None\n            date = calendar.timegm(time_tuple[:6])\n        else:\n            date = 0\n\n        # If we've been given a body, our response has a Content-Length, that\n        # Content-Length is valid then we can check to see if the body we've\n        # been given matches the expected size, and if it doesn't we'll just\n        # skip trying to cache it.\n        if (\n            body is not None\n            and \"content-length\" in response_headers\n            and response_headers[\"content-length\"].isdigit()\n            and int(response_headers[\"content-length\"]) != len(body)\n        ):\n            return\n\n        cc_req = self.parse_cache_control(request.headers)\n        cc = self.parse_cache_control(response_headers)\n\n        assert request.url is not None\n        cache_url = self.cache_url(request.url)\n        logger.debug('Updating cache with response from \"%s\"', cache_url)\n\n        # Delete it from the cache if we happen to have it stored there\n        no_store = False\n        if \"no-store\" in cc:\n            no_store = True\n            logger.debug('Response header has \"no-store\"')\n        if \"no-store\" in cc_req:\n            no_store = True\n            logger.debug('Request header has \"no-store\"')\n        if no_store and self.cache.get(cache_url):\n            logger.debug('Purging existing cache entry to honor \"no-store\"')\n            self.cache.delete(cache_url)\n        if no_store:\n            return\n\n        # https://tools.ietf.org/html/rfc7234#section-4.1:\n        # A Vary header field-value of \"*\" always fails to match.\n        # Storing such a response leads to a deserialization warning\n        # during cache lookup and is not allowed to ever be served,\n        # so storing it can be avoided.\n        if \"*\" in response_headers.get(\"vary\", \"\"):\n            logger.debug('Response header has \"Vary: *\"')\n            return\n\n        # If we've been given an etag, then keep the response\n        if self.cache_etags and \"etag\" in response_headers:\n            expires_time = 0\n            if response_headers.get(\"expires\"):\n                expires = parsedate_tz(response_headers[\"expires\"])\n                if expires is not None:\n                    expires_time = calendar.timegm(expires[:6]) - date\n\n            expires_time = max(expires_time, 14 * 86400)\n\n            logger.debug(f\"etag object cached for {expires_time} seconds\")\n            logger.debug(\"Caching due to etag\")\n            self._cache_set(cache_url, request, response, body, expires_time)\n\n        # Add to the cache any permanent redirects. We do this before looking\n        # that the Date headers.\n        elif int(response.status) in PERMANENT_REDIRECT_STATUSES:\n            logger.debug(\"Caching permanent redirect\")\n            self._cache_set(cache_url, request, response, b\"\")\n\n        # Add to the cache if the response headers demand it. If there\n        # is no date header then we can't do anything about expiring\n        # the cache.\n        elif \"date\" in response_headers:\n            time_tuple = parsedate_tz(response_headers[\"date\"])\n            assert time_tuple is not None\n            date = calendar.timegm(time_tuple[:6])\n            # cache when there is a max-age > 0\n            max_age = cc.get(\"max-age\")\n            if max_age is not None and max_age > 0:\n                logger.debug(\"Caching b/c date exists and max-age > 0\")\n                expires_time = max_age\n                self._cache_set(\n                    cache_url,\n                    request,\n                    response,\n                    body,\n                    expires_time,\n                )\n\n            # If the request can expire, it means we should cache it\n            # in the meantime.\n            elif \"expires\" in response_headers:\n                if response_headers[\"expires\"]:\n                    expires = parsedate_tz(response_headers[\"expires\"])\n                    if expires is not None:\n                        expires_time = calendar.timegm(expires[:6]) - date\n                    else:\n                        expires_time = None\n\n                    logger.debug(\n                        \"Caching b/c of expires header. expires in {} seconds\".format(\n                            expires_time\n                        )\n                    )\n                    self._cache_set(\n                        cache_url,\n                        request,\n                        response,\n                        body,\n                        expires_time,\n                    )\n\n    def update_cached_response(\n        self, request: PreparedRequest, response: HTTPResponse\n    ) -> HTTPResponse:\n        \"\"\"On a 304 we will get a new set of headers that we want to\n        update our cached value with, assuming we have one.\n\n        This should only ever be called when we've sent an ETag and\n        gotten a 304 as the response.\n        \"\"\"\n        assert request.url is not None\n        cache_url = self.cache_url(request.url)\n        cached_response = self._load_from_cache(request)\n\n        if not cached_response:\n            # we didn't have a cached response\n            return response\n\n        # Lets update our headers with the headers from the new request:\n        # http://tools.ietf.org/html/draft-ietf-httpbis-p4-conditional-26#section-4.1\n        #\n        # The server isn't supposed to send headers that would make\n        # the cached body invalid. But... just in case, we'll be sure\n        # to strip out ones we know that might be problmatic due to\n        # typical assumptions.\n        excluded_headers = [\"content-length\"]\n\n        cached_response.headers.update(\n            {\n                k: v\n                for k, v in response.headers.items()  # type: ignore[no-untyped-call]\n                if k.lower() not in excluded_headers\n            }\n        )\n\n        # we want a 200 b/c we have content via the cache\n        cached_response.status = 200\n\n        # update our cache\n        self._cache_set(cache_url, request, cached_response)\n\n        return cached_response\n"},"hash":"P2qoNrf95S"}