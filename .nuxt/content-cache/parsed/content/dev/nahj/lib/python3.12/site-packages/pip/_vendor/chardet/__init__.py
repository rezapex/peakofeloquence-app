{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:chardet:__init__.py","body":"######################## BEGIN LICENSE BLOCK ########################\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\nfrom typing import List, Union\n\nfrom .charsetgroupprober import CharSetGroupProber\nfrom .charsetprober import CharSetProber\nfrom .enums import InputState\nfrom .resultdict import ResultDict\nfrom .universaldetector import UniversalDetector\nfrom .version import VERSION, __version__\n\n__all__ = [\"UniversalDetector\", \"detect\", \"detect_all\", \"__version__\", \"VERSION\"]\n\n\ndef detect(\n    byte_str: Union[bytes, bytearray], should_rename_legacy: bool = False\n) -> ResultDict:\n    \"\"\"\n    Detect the encoding of the given byte string.\n\n    :param byte_str:     The byte sequence to examine.\n    :type byte_str:      ``bytes`` or ``bytearray``\n    :param should_rename_legacy:  Should we rename legacy encodings\n                                  to their more modern equivalents?\n    :type should_rename_legacy:   ``bool``\n    \"\"\"\n    if not isinstance(byte_str, bytearray):\n        if not isinstance(byte_str, bytes):\n            raise TypeError(\n                f\"Expected object of type bytes or bytearray, got: {type(byte_str)}\"\n            )\n        byte_str = bytearray(byte_str)\n    detector = UniversalDetector(should_rename_legacy=should_rename_legacy)\n    detector.feed(byte_str)\n    return detector.close()\n\n\ndef detect_all(\n    byte_str: Union[bytes, bytearray],\n    ignore_threshold: bool = False,\n    should_rename_legacy: bool = False,\n) -> List[ResultDict]:\n    \"\"\"\n    Detect all the possible encodings of the given byte string.\n\n    :param byte_str:          The byte sequence to examine.\n    :type byte_str:           ``bytes`` or ``bytearray``\n    :param ignore_threshold:  Include encodings that are below\n                              ``UniversalDetector.MINIMUM_THRESHOLD``\n                              in results.\n    :type ignore_threshold:   ``bool``\n    :param should_rename_legacy:  Should we rename legacy encodings\n                                  to their more modern equivalents?\n    :type should_rename_legacy:   ``bool``\n    \"\"\"\n    if not isinstance(byte_str, bytearray):\n        if not isinstance(byte_str, bytes):\n            raise TypeError(\n                f\"Expected object of type bytes or bytearray, got: {type(byte_str)}\"\n            )\n        byte_str = bytearray(byte_str)\n\n    detector = UniversalDetector(should_rename_legacy=should_rename_legacy)\n    detector.feed(byte_str)\n    detector.close()\n\n    if detector.input_state == InputState.HIGH_BYTE:\n        results: List[ResultDict] = []\n        probers: List[CharSetProber] = []\n        for prober in detector.charset_probers:\n            if isinstance(prober, CharSetGroupProber):\n                probers.extend(p for p in prober.probers)\n            else:\n                probers.append(prober)\n        for prober in probers:\n            if ignore_threshold or prober.get_confidence() > detector.MINIMUM_THRESHOLD:\n                charset_name = prober.charset_name or \"\"\n                lower_charset_name = charset_name.lower()\n                # Use Windows encoding name instead of ISO-8859 if we saw any\n                # extra Windows-specific bytes\n                if lower_charset_name.startswith(\"iso-8859\") and detector.has_win_bytes:\n                    charset_name = detector.ISO_WIN_MAP.get(\n                        lower_charset_name, charset_name\n                    )\n                # Rename legacy encodings with superset encodings if asked\n                if should_rename_legacy:\n                    charset_name = detector.LEGACY_MAP.get(\n                        charset_name.lower(), charset_name\n                    )\n                results.append(\n                    {\n                        \"encoding\": charset_name,\n                        \"confidence\": prober.get_confidence(),\n                        \"language\": prober.language,\n                    }\n                )\n        if len(results) > 0:\n            return sorted(results, key=lambda result: -result[\"confidence\"])\n\n    return [detector.result]\n"},"hash":"4a5p8BOSoB"}