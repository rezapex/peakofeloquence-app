{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:tests:test_pageelement.py","body":"\"\"\"Tests of the bs4.element.PageElement class\"\"\"\nimport copy\nimport pickle\nimport pytest\nimport sys\n\nfrom bs4 import BeautifulSoup\nfrom bs4.element import (\n    Comment,\n    ResultSet,\n    SoupStrainer,\n)\nfrom . import (\n    SoupTest,\n)\n\nclass TestEncoding(SoupTest):\n    \"\"\"Test the ability to encode objects into strings.\"\"\"\n\n    def test_unicode_string_can_be_encoded(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert soup.b.string.encode(\"utf-8\") == \"\\N{SNOWMAN}\".encode(\"utf-8\")\n\n    def test_tag_containing_unicode_string_can_be_encoded(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert soup.b.encode(\"utf-8\") == html.encode(\"utf-8\")\n\n    def test_encoding_substitutes_unrecognized_characters_by_default(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert soup.b.encode(\"ascii\") == b\"<b>&#9731;</b>\"\n\n    def test_encoding_can_be_made_strict(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        with pytest.raises(UnicodeEncodeError):\n            soup.encode(\"ascii\", errors=\"strict\")\n\n    def test_decode_contents(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert \"\\N{SNOWMAN}\" == soup.b.decode_contents()\n\n    def test_encode_contents(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert \"\\N{SNOWMAN}\".encode(\"utf8\") == soup.b.encode_contents(\n            encoding=\"utf8\"\n        )\n        \n    def test_encode_deeply_nested_document(self):\n        # This test verifies that encoding a string doesn't involve\n        # any recursive function calls. If it did, this test would\n        # overflow the Python interpreter stack.\n        limit = sys.getrecursionlimit() + 1\n        markup = \"<span>\" * limit\n        soup = self.soup(markup)\n        encoded = soup.encode()\n        assert limit == encoded.count(b\"<span>\")\n\n    def test_deprecated_renderContents(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        soup.renderContents()\n        assert \"\\N{SNOWMAN}\".encode(\"utf8\") == soup.b.renderContents()\n\n    def test_repr(self):\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        assert html == repr(soup)\n\n        \nclass TestFormatters(SoupTest):\n    \"\"\"Test the formatting feature, used by methods like decode() and\n    prettify(), and the formatters themselves.\n    \"\"\"\n    \n    def test_default_formatter_is_minimal(self):\n        markup = \"<b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter=\"minimal\")\n        # The < is converted back into &lt; but the e-with-acute is left alone.\n        assert decoded == self.document_for(\n                \"<b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        )\n\n    def test_formatter_html(self):\n        markup = \"<br><b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter=\"html\")\n        assert decoded == self.document_for(\n            \"<br/><b>&lt;&lt;Sacr&eacute; bleu!&gt;&gt;</b>\"\n        )\n\n    def test_formatter_html5(self):\n        markup = \"<br><b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter=\"html5\")\n        assert decoded == self.document_for(\n            \"<br><b>&lt;&lt;Sacr&eacute; bleu!&gt;&gt;</b>\"\n        )\n        \n    def test_formatter_minimal(self):\n        markup = \"<b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter=\"minimal\")\n        # The < is converted back into &lt; but the e-with-acute is left alone.\n        assert decoded == self.document_for(\n                \"<b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        )\n\n    def test_formatter_null(self):\n        markup = \"<b>&lt;&lt;Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!&gt;&gt;</b>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter=None)\n        # Neither the angle brackets nor the e-with-acute are converted.\n        # This is not valid HTML, but it's what the user wanted.\n        assert decoded == self.document_for(\n            \"<b><<Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!>></b>\"\n        )\n\n    def test_formatter_custom(self):\n        markup = \"<b>&lt;foo&gt;</b><b>bar</b><br/>\"\n        soup = self.soup(markup)\n        decoded = soup.decode(formatter = lambda x: x.upper())\n        # Instead of normal entity conversion code, the custom\n        # callable is called on every string.\n        assert decoded == self.document_for(\"<b><FOO></b><b>BAR</b><br/>\")\n\n    def test_formatter_is_run_on_attribute_values(self):\n        markup = '<a href=\"http://a.com?a=b&c=é\">e</a>'\n        soup = self.soup(markup)\n        a = soup.a\n\n        expect_minimal = '<a href=\"http://a.com?a=b&amp;c=é\">e</a>'\n\n        assert expect_minimal == a.decode()\n        assert expect_minimal == a.decode(formatter=\"minimal\")\n\n        expect_html = '<a href=\"http://a.com?a=b&amp;c=&eacute;\">e</a>'\n        assert expect_html == a.decode(formatter=\"html\")\n\n        assert markup == a.decode(formatter=None)\n        expect_upper = '<a href=\"HTTP://A.COM?A=B&C=É\">E</a>'\n        assert expect_upper == a.decode(formatter=lambda x: x.upper())\n\n    def test_formatter_skips_script_tag_for_html_documents(self):\n        doc = \"\"\"\n  <script type=\"text/javascript\">\n   console.log(\"< < hey > > \");\n  </script>\n\"\"\"\n        encoded = BeautifulSoup(doc, 'html.parser').encode()\n        assert b\"< < hey > >\" in encoded\n\n    def test_formatter_skips_style_tag_for_html_documents(self):\n        doc = \"\"\"\n  <style type=\"text/css\">\n   console.log(\"< < hey > > \");\n  </style>\n\"\"\"\n        encoded = BeautifulSoup(doc, 'html.parser').encode()\n        assert b\"< < hey > >\" in encoded\n\n    def test_prettify_leaves_preformatted_text_alone(self):\n        soup = self.soup(\"<div>  foo  <pre>  \\tbar\\n  \\n  </pre>  baz  <textarea> eee\\nfff\\t</textarea></div>\")\n        # Everything outside the <pre> tag is reformatted, but everything\n        # inside is left alone.\n        assert '<div>\\n foo\\n <pre>  \\tbar\\n  \\n  </pre>\\n baz\\n <textarea> eee\\nfff\\t</textarea>\\n</div>\\n' == soup.div.prettify()\n\n    def test_prettify_handles_nested_string_literal_tags(self):\n        # Most of this markup is inside a <pre> tag, so prettify()\n        # only does three things to it:\n        # 1. Add a newline and a space between the <div> and the <pre>\n        # 2. Add a newline after the </pre>\n        # 3. Add a newline at the end.\n        #\n        # The contents of the <pre> tag are left completely alone.  In\n        # particular, we don't start adding whitespace again once we\n        # encounter the first </pre> tag, because we know it's not\n        # the one that put us into string literal mode.\n        markup = \"\"\"<div><pre><code>some\n<script><pre>code</pre></script> for you \n</code></pre></div>\"\"\"\n\n        expect = \"\"\"<div>\n <pre><code>some\n<script><pre>code</pre></script> for you \n</code></pre>\n</div>\n\"\"\"\n        soup = self.soup(markup)\n        assert expect == soup.div.prettify()\n\n    def test_prettify_accepts_formatter_function(self):\n        soup = BeautifulSoup(\"<html><body>foo</body></html>\", 'html.parser')\n        pretty = soup.prettify(formatter = lambda x: x.upper())\n        assert \"FOO\" in pretty\n\n    def test_prettify_outputs_unicode_by_default(self):\n        soup = self.soup(\"<a></a>\")\n        assert str == type(soup.prettify())\n\n    def test_prettify_can_encode_data(self):\n        soup = self.soup(\"<a></a>\")\n        assert bytes == type(soup.prettify(\"utf-8\"))\n\n    def test_html_entity_substitution_off_by_default(self):\n        markup = \"<b>Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</b>\"\n        soup = self.soup(markup)\n        encoded = soup.b.encode(\"utf-8\")\n        assert encoded == markup.encode('utf-8')\n\n    def test_encoding_substitution(self):\n        # Here's the <meta> tag saying that a document is\n        # encoded in Shift-JIS.\n        meta_tag = ('<meta content=\"text/html; charset=x-sjis\" '\n                    'http-equiv=\"Content-type\"/>')\n        soup = self.soup(meta_tag)\n\n        # Parse the document, and the charset apprears unchanged.\n        assert soup.meta['content'] == 'text/html; charset=x-sjis'\n\n        # Encode the document into some encoding, and the encoding is\n        # substituted into the meta tag.\n        utf_8 = soup.encode(\"utf-8\")\n        assert b\"charset=utf-8\" in utf_8\n\n        euc_jp = soup.encode(\"euc_jp\")\n        assert b\"charset=euc_jp\" in euc_jp\n\n        shift_jis = soup.encode(\"shift-jis\")\n        assert b\"charset=shift-jis\" in shift_jis\n\n        utf_16_u = soup.encode(\"utf-16\").decode(\"utf-16\")\n        assert \"charset=utf-16\" in utf_16_u\n\n    def test_encoding_substitution_doesnt_happen_if_tag_is_strained(self):\n        markup = ('<head><meta content=\"text/html; charset=x-sjis\" '\n                    'http-equiv=\"Content-type\"/></head><pre>foo</pre>')\n\n        # Beautiful Soup used to try to rewrite the meta tag even if the\n        # meta tag got filtered out by the strainer. This test makes\n        # sure that doesn't happen.\n        strainer = SoupStrainer('pre')\n        soup = self.soup(markup, parse_only=strainer)\n        assert soup.contents[0].name == 'pre'\n\n\nclass TestPersistence(SoupTest):\n    \"Testing features like pickle and deepcopy.\"\n\n    def setup_method(self):\n        self.page = \"\"\"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\n<meta name=\"Description\" content=\"Beautiful Soup: an HTML parser optimized for screen-scraping.\">\n<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\n<meta name=\"author\" content=\"Leonard Richardson\">\n</head>\n<body>\n<a href=\"foo\">foo</a>\n<a href=\"foo\"><b>bar</b></a>\n</body>\n</html>\"\"\"\n        self.tree = self.soup(self.page)\n\n    def test_pickle_and_unpickle_identity(self):\n        # Pickling a tree, then unpickling it, yields a tree identical\n        # to the original.\n        dumped = pickle.dumps(self.tree, 2)\n        loaded = pickle.loads(dumped)\n        assert loaded.__class__ == BeautifulSoup\n        assert loaded.decode() == self.tree.decode()\n        \n    def test_deepcopy_identity(self):\n        # Making a deepcopy of a tree yields an identical tree.\n        copied = copy.deepcopy(self.tree)\n        assert copied.decode() == self.tree.decode()\n\n    def test_copy_deeply_nested_document(self):\n        # This test verifies that copy and deepcopy don't involve any\n        # recursive function calls. If they did, this test would\n        # overflow the Python interpreter stack.\n        limit = sys.getrecursionlimit() + 1\n        markup = \"<span>\" * limit\n\n        soup = self.soup(markup)\n        \n        copied = copy.copy(soup)\n        copied = copy.deepcopy(soup)\n\n    def test_copy_preserves_encoding(self):\n        soup = BeautifulSoup(b'<p>&nbsp;</p>', 'html.parser')\n        encoding = soup.original_encoding\n        copy = soup.__copy__()\n        assert \"<p> </p>\" == str(copy)\n        assert encoding == copy.original_encoding\n\n    def test_copy_preserves_builder_information(self):\n\n        tag = self.soup('<p></p>').p\n\n        # Simulate a tag obtained from a source file.\n        tag.sourceline = 10\n        tag.sourcepos = 33\n        \n        copied = tag.__copy__()\n\n        # The TreeBuilder object is no longer availble, but information\n        # obtained from it gets copied over to the new Tag object.\n        assert tag.sourceline == copied.sourceline\n        assert tag.sourcepos == copied.sourcepos\n        assert tag.can_be_empty_element == copied.can_be_empty_element\n        assert tag.cdata_list_attributes == copied.cdata_list_attributes\n        assert tag.preserve_whitespace_tags == copied.preserve_whitespace_tags\n        assert tag.interesting_string_types == copied.interesting_string_types\n        \n    def test_unicode_pickle(self):\n        # A tree containing Unicode characters can be pickled.\n        html = \"<b>\\N{SNOWMAN}</b>\"\n        soup = self.soup(html)\n        dumped = pickle.dumps(soup, pickle.HIGHEST_PROTOCOL)\n        loaded = pickle.loads(dumped)\n        assert loaded.decode() == soup.decode()\n\n    def test_copy_navigablestring_is_not_attached_to_tree(self):\n        html = \"<b>Foo<a></a></b><b>Bar</b>\"\n        soup = self.soup(html)\n        s1 = soup.find(string=\"Foo\")\n        s2 = copy.copy(s1)\n        assert s1 == s2\n        assert None == s2.parent\n        assert None == s2.next_element\n        assert None != s1.next_sibling\n        assert None == s2.next_sibling\n        assert None == s2.previous_element\n\n    def test_copy_navigablestring_subclass_has_same_type(self):\n        html = \"<b><!--Foo--></b>\"\n        soup = self.soup(html)\n        s1 = soup.string\n        s2 = copy.copy(s1)\n        assert s1 == s2\n        assert isinstance(s2, Comment)\n\n    def test_copy_entire_soup(self):\n        html = \"<div><b>Foo<a></a></b><b>Bar</b></div>end\"\n        soup = self.soup(html)\n        soup_copy = copy.copy(soup)\n        assert soup == soup_copy\n\n    def test_copy_tag_copies_contents(self):\n        html = \"<div><b>Foo<a></a></b><b>Bar</b></div>end\"\n        soup = self.soup(html)\n        div = soup.div\n        div_copy = copy.copy(div)\n\n        # The two tags look the same, and evaluate to equal.\n        assert str(div) == str(div_copy)\n        assert div == div_copy\n\n        # But they're not the same object.\n        assert div is not div_copy\n\n        # And they don't have the same relation to the parse tree. The\n        # copy is not associated with a parse tree at all.\n        assert None == div_copy.parent\n        assert None == div_copy.previous_element\n        assert None == div_copy.find(string='Bar').next_element\n        assert None != div.find(string='Bar').next_element\n\n"},"hash":"cOji686l2h"}