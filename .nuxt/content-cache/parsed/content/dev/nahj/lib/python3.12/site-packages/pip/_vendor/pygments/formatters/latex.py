{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_vendor:pygments:formatters:latex.py","body":"\"\"\"\n    pygments.formatters.latex\n    ~~~~~~~~~~~~~~~~~~~~~~~~~\n\n    Formatter for LaTeX fancyvrb output.\n\n    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nfrom io import StringIO\n\nfrom pip._vendor.pygments.formatter import Formatter\nfrom pip._vendor.pygments.lexer import Lexer, do_insertions\nfrom pip._vendor.pygments.token import Token, STANDARD_TYPES\nfrom pip._vendor.pygments.util import get_bool_opt, get_int_opt\n\n\n__all__ = ['LatexFormatter']\n\n\ndef escape_tex(text, commandprefix):\n    return text.replace('\\\\', '\\x00'). \\\n                replace('{', '\\x01'). \\\n                replace('}', '\\x02'). \\\n                replace('\\x00', r'\\%sZbs{}' % commandprefix). \\\n                replace('\\x01', r'\\%sZob{}' % commandprefix). \\\n                replace('\\x02', r'\\%sZcb{}' % commandprefix). \\\n                replace('^', r'\\%sZca{}' % commandprefix). \\\n                replace('_', r'\\%sZus{}' % commandprefix). \\\n                replace('&', r'\\%sZam{}' % commandprefix). \\\n                replace('<', r'\\%sZlt{}' % commandprefix). \\\n                replace('>', r'\\%sZgt{}' % commandprefix). \\\n                replace('#', r'\\%sZsh{}' % commandprefix). \\\n                replace('%', r'\\%sZpc{}' % commandprefix). \\\n                replace('$', r'\\%sZdl{}' % commandprefix). \\\n                replace('-', r'\\%sZhy{}' % commandprefix). \\\n                replace(\"'\", r'\\%sZsq{}' % commandprefix). \\\n                replace('\"', r'\\%sZdq{}' % commandprefix). \\\n                replace('~', r'\\%sZti{}' % commandprefix)\n\n\nDOC_TEMPLATE = r'''\n\\documentclass{%(docclass)s}\n\\usepackage{fancyvrb}\n\\usepackage{color}\n\\usepackage[%(encoding)s]{inputenc}\n%(preamble)s\n\n%(styledefs)s\n\n\\begin{document}\n\n\\section*{%(title)s}\n\n%(code)s\n\\end{document}\n'''\n\n## Small explanation of the mess below :)\n#\n# The previous version of the LaTeX formatter just assigned a command to\n# each token type defined in the current style.  That obviously is\n# problematic if the highlighted code is produced for a different style\n# than the style commands themselves.\n#\n# This version works much like the HTML formatter which assigns multiple\n# CSS classes to each <span> tag, from the most specific to the least\n# specific token type, thus falling back to the parent token type if one\n# is not defined.  Here, the classes are there too and use the same short\n# forms given in token.STANDARD_TYPES.\n#\n# Highlighted code now only uses one custom command, which by default is\n# \\PY and selectable by the commandprefix option (and in addition the\n# escapes \\PYZat, \\PYZlb and \\PYZrb which haven't been renamed for\n# backwards compatibility purposes).\n#\n# \\PY has two arguments: the classes, separated by +, and the text to\n# render in that style.  The classes are resolved into the respective\n# style commands by magic, which serves to ignore unknown classes.\n#\n# The magic macros are:\n# * \\PY@it, \\PY@bf, etc. are unconditionally wrapped around the text\n#   to render in \\PY@do.  Their definition determines the style.\n# * \\PY@reset resets \\PY@it etc. to do nothing.\n# * \\PY@toks parses the list of classes, using magic inspired by the\n#   keyval package (but modified to use plusses instead of commas\n#   because fancyvrb redefines commas inside its environments).\n# * \\PY@tok processes one class, calling the \\PY@tok@classname command\n#   if it exists.\n# * \\PY@tok@classname sets the \\PY@it etc. to reflect the chosen style\n#   for its class.\n# * \\PY resets the style, parses the classnames and then calls \\PY@do.\n#\n# Tip: to read this code, print it out in substituted form using e.g.\n# >>> print STYLE_TEMPLATE % {'cp': 'PY'}\n\nSTYLE_TEMPLATE = r'''\n\\makeatletter\n\\def\\%(cp)s@reset{\\let\\%(cp)s@it=\\relax \\let\\%(cp)s@bf=\\relax%%\n    \\let\\%(cp)s@ul=\\relax \\let\\%(cp)s@tc=\\relax%%\n    \\let\\%(cp)s@bc=\\relax \\let\\%(cp)s@ff=\\relax}\n\\def\\%(cp)s@tok#1{\\csname %(cp)s@tok@#1\\endcsname}\n\\def\\%(cp)s@toks#1+{\\ifx\\relax#1\\empty\\else%%\n    \\%(cp)s@tok{#1}\\expandafter\\%(cp)s@toks\\fi}\n\\def\\%(cp)s@do#1{\\%(cp)s@bc{\\%(cp)s@tc{\\%(cp)s@ul{%%\n    \\%(cp)s@it{\\%(cp)s@bf{\\%(cp)s@ff{#1}}}}}}}\n\\def\\%(cp)s#1#2{\\%(cp)s@reset\\%(cp)s@toks#1+\\relax+\\%(cp)s@do{#2}}\n\n%(styles)s\n\n\\def\\%(cp)sZbs{\\char`\\\\}\n\\def\\%(cp)sZus{\\char`\\_}\n\\def\\%(cp)sZob{\\char`\\{}\n\\def\\%(cp)sZcb{\\char`\\}}\n\\def\\%(cp)sZca{\\char`\\^}\n\\def\\%(cp)sZam{\\char`\\&}\n\\def\\%(cp)sZlt{\\char`\\<}\n\\def\\%(cp)sZgt{\\char`\\>}\n\\def\\%(cp)sZsh{\\char`\\#}\n\\def\\%(cp)sZpc{\\char`\\%%}\n\\def\\%(cp)sZdl{\\char`\\$}\n\\def\\%(cp)sZhy{\\char`\\-}\n\\def\\%(cp)sZsq{\\char`\\'}\n\\def\\%(cp)sZdq{\\char`\\\"}\n\\def\\%(cp)sZti{\\char`\\~}\n%% for compatibility with earlier versions\n\\def\\%(cp)sZat{@}\n\\def\\%(cp)sZlb{[}\n\\def\\%(cp)sZrb{]}\n\\makeatother\n'''\n\n\ndef _get_ttype_name(ttype):\n    fname = STANDARD_TYPES.get(ttype)\n    if fname:\n        return fname\n    aname = ''\n    while fname is None:\n        aname = ttype[-1] + aname\n        ttype = ttype.parent\n        fname = STANDARD_TYPES.get(ttype)\n    return fname + aname\n\n\nclass LatexFormatter(Formatter):\n    r\"\"\"\n    Format tokens as LaTeX code. This needs the `fancyvrb` and `color`\n    standard packages.\n\n    Without the `full` option, code is formatted as one ``Verbatim``\n    environment, like this:\n\n    .. sourcecode:: latex\n\n        \\begin{Verbatim}[commandchars=\\\\\\{\\}]\n        \\PY{k}{def }\\PY{n+nf}{foo}(\\PY{n}{bar}):\n            \\PY{k}{pass}\n        \\end{Verbatim}\n\n    Wrapping can be disabled using the `nowrap` option.\n\n    The special command used here (``\\PY``) and all the other macros it needs\n    are output by the `get_style_defs` method.\n\n    With the `full` option, a complete LaTeX document is output, including\n    the command definitions in the preamble.\n\n    The `get_style_defs()` method of a `LatexFormatter` returns a string\n    containing ``\\def`` commands defining the macros needed inside the\n    ``Verbatim`` environments.\n\n    Additional options accepted:\n\n    `nowrap`\n        If set to ``True``, don't wrap the tokens at all, not even inside a\n        ``\\begin{Verbatim}`` environment. This disables most other options\n        (default: ``False``).\n\n    `style`\n        The style to use, can be a string or a Style subclass (default:\n        ``'default'``).\n\n    `full`\n        Tells the formatter to output a \"full\" document, i.e. a complete\n        self-contained document (default: ``False``).\n\n    `title`\n        If `full` is true, the title that should be used to caption the\n        document (default: ``''``).\n\n    `docclass`\n        If the `full` option is enabled, this is the document class to use\n        (default: ``'article'``).\n\n    `preamble`\n        If the `full` option is enabled, this can be further preamble commands,\n        e.g. ``\\usepackage`` (default: ``''``).\n\n    `linenos`\n        If set to ``True``, output line numbers (default: ``False``).\n\n    `linenostart`\n        The line number for the first line (default: ``1``).\n\n    `linenostep`\n        If set to a number n > 1, only every nth line number is printed.\n\n    `verboptions`\n        Additional options given to the Verbatim environment (see the *fancyvrb*\n        docs for possible values) (default: ``''``).\n\n    `commandprefix`\n        The LaTeX commands used to produce colored output are constructed\n        using this prefix and some letters (default: ``'PY'``).\n\n        .. versionadded:: 0.7\n        .. versionchanged:: 0.10\n           The default is now ``'PY'`` instead of ``'C'``.\n\n    `texcomments`\n        If set to ``True``, enables LaTeX comment lines.  That is, LaTex markup\n        in comment tokens is not escaped so that LaTeX can render it (default:\n        ``False``).\n\n        .. versionadded:: 1.2\n\n    `mathescape`\n        If set to ``True``, enables LaTeX math mode escape in comments. That\n        is, ``'$...$'`` inside a comment will trigger math mode (default:\n        ``False``).\n\n        .. versionadded:: 1.2\n\n    `escapeinside`\n        If set to a string of length 2, enables escaping to LaTeX. Text\n        delimited by these 2 characters is read as LaTeX code and\n        typeset accordingly. It has no effect in string literals. It has\n        no effect in comments if `texcomments` or `mathescape` is\n        set. (default: ``''``).\n\n        .. versionadded:: 2.0\n\n    `envname`\n        Allows you to pick an alternative environment name replacing Verbatim.\n        The alternate environment still has to support Verbatim's option syntax.\n        (default: ``'Verbatim'``).\n\n        .. versionadded:: 2.0\n    \"\"\"\n    name = 'LaTeX'\n    aliases = ['latex', 'tex']\n    filenames = ['*.tex']\n\n    def __init__(self, **options):\n        Formatter.__init__(self, **options)\n        self.nowrap = get_bool_opt(options, 'nowrap', False)\n        self.docclass = options.get('docclass', 'article')\n        self.preamble = options.get('preamble', '')\n        self.linenos = get_bool_opt(options, 'linenos', False)\n        self.linenostart = abs(get_int_opt(options, 'linenostart', 1))\n        self.linenostep = abs(get_int_opt(options, 'linenostep', 1))\n        self.verboptions = options.get('verboptions', '')\n        self.nobackground = get_bool_opt(options, 'nobackground', False)\n        self.commandprefix = options.get('commandprefix', 'PY')\n        self.texcomments = get_bool_opt(options, 'texcomments', False)\n        self.mathescape = get_bool_opt(options, 'mathescape', False)\n        self.escapeinside = options.get('escapeinside', '')\n        if len(self.escapeinside) == 2:\n            self.left = self.escapeinside[0]\n            self.right = self.escapeinside[1]\n        else:\n            self.escapeinside = ''\n        self.envname = options.get('envname', 'Verbatim')\n\n        self._create_stylesheet()\n\n    def _create_stylesheet(self):\n        t2n = self.ttype2name = {Token: ''}\n        c2d = self.cmd2def = {}\n        cp = self.commandprefix\n\n        def rgbcolor(col):\n            if col:\n                return ','.join(['%.2f' % (int(col[i] + col[i + 1], 16) / 255.0)\n                                 for i in (0, 2, 4)])\n            else:\n                return '1,1,1'\n\n        for ttype, ndef in self.style:\n            name = _get_ttype_name(ttype)\n            cmndef = ''\n            if ndef['bold']:\n                cmndef += r'\\let\\$$@bf=\\textbf'\n            if ndef['italic']:\n                cmndef += r'\\let\\$$@it=\\textit'\n            if ndef['underline']:\n                cmndef += r'\\let\\$$@ul=\\underline'\n            if ndef['roman']:\n                cmndef += r'\\let\\$$@ff=\\textrm'\n            if ndef['sans']:\n                cmndef += r'\\let\\$$@ff=\\textsf'\n            if ndef['mono']:\n                cmndef += r'\\let\\$$@ff=\\textsf'\n            if ndef['color']:\n                cmndef += (r'\\def\\$$@tc##1{\\textcolor[rgb]{%s}{##1}}' %\n                           rgbcolor(ndef['color']))\n            if ndef['border']:\n                cmndef += (r'\\def\\$$@bc##1{{\\setlength{\\fboxsep}{\\string -\\fboxrule}'\n                           r'\\fcolorbox[rgb]{%s}{%s}{\\strut ##1}}}' %\n                           (rgbcolor(ndef['border']),\n                            rgbcolor(ndef['bgcolor'])))\n            elif ndef['bgcolor']:\n                cmndef += (r'\\def\\$$@bc##1{{\\setlength{\\fboxsep}{0pt}'\n                           r'\\colorbox[rgb]{%s}{\\strut ##1}}}' %\n                           rgbcolor(ndef['bgcolor']))\n            if cmndef == '':\n                continue\n            cmndef = cmndef.replace('$$', cp)\n            t2n[ttype] = name\n            c2d[name] = cmndef\n\n    def get_style_defs(self, arg=''):\n        \"\"\"\n        Return the command sequences needed to define the commands\n        used to format text in the verbatim environment. ``arg`` is ignored.\n        \"\"\"\n        cp = self.commandprefix\n        styles = []\n        for name, definition in self.cmd2def.items():\n            styles.append(r'\\@namedef{%s@tok@%s}{%s}' % (cp, name, definition))\n        return STYLE_TEMPLATE % {'cp': self.commandprefix,\n                                 'styles': '\\n'.join(styles)}\n\n    def format_unencoded(self, tokensource, outfile):\n        # TODO: add support for background colors\n        t2n = self.ttype2name\n        cp = self.commandprefix\n\n        if self.full:\n            realoutfile = outfile\n            outfile = StringIO()\n\n        if not self.nowrap:\n            outfile.write('\\\\begin{' + self.envname + '}[commandchars=\\\\\\\\\\\\{\\\\}')\n            if self.linenos:\n                start, step = self.linenostart, self.linenostep\n                outfile.write(',numbers=left' +\n                              (start and ',firstnumber=%d' % start or '') +\n                              (step and ',stepnumber=%d' % step or ''))\n            if self.mathescape or self.texcomments or self.escapeinside:\n                outfile.write(',codes={\\\\catcode`\\\\$=3\\\\catcode`\\\\^=7'\n                              '\\\\catcode`\\\\_=8\\\\relax}')\n            if self.verboptions:\n                outfile.write(',' + self.verboptions)\n            outfile.write(']\\n')\n\n        for ttype, value in tokensource:\n            if ttype in Token.Comment:\n                if self.texcomments:\n                    # Try to guess comment starting lexeme and escape it ...\n                    start = value[0:1]\n                    for i in range(1, len(value)):\n                        if start[0] != value[i]:\n                            break\n                        start += value[i]\n\n                    value = value[len(start):]\n                    start = escape_tex(start, cp)\n\n                    # ... but do not escape inside comment.\n                    value = start + value\n                elif self.mathescape:\n                    # Only escape parts not inside a math environment.\n                    parts = value.split('$')\n                    in_math = False\n                    for i, part in enumerate(parts):\n                        if not in_math:\n                            parts[i] = escape_tex(part, cp)\n                        in_math = not in_math\n                    value = '$'.join(parts)\n                elif self.escapeinside:\n                    text = value\n                    value = ''\n                    while text:\n                        a, sep1, text = text.partition(self.left)\n                        if sep1:\n                            b, sep2, text = text.partition(self.right)\n                            if sep2:\n                                value += escape_tex(a, cp) + b\n                            else:\n                                value += escape_tex(a + sep1 + b, cp)\n                        else:\n                            value += escape_tex(a, cp)\n                else:\n                    value = escape_tex(value, cp)\n            elif ttype not in Token.Escape:\n                value = escape_tex(value, cp)\n            styles = []\n            while ttype is not Token:\n                try:\n                    styles.append(t2n[ttype])\n                except KeyError:\n                    # not in current style\n                    styles.append(_get_ttype_name(ttype))\n                ttype = ttype.parent\n            styleval = '+'.join(reversed(styles))\n            if styleval:\n                spl = value.split('\\n')\n                for line in spl[:-1]:\n                    if line:\n                        outfile.write(\"\\\\%s{%s}{%s}\" % (cp, styleval, line))\n                    outfile.write('\\n')\n                if spl[-1]:\n                    outfile.write(\"\\\\%s{%s}{%s}\" % (cp, styleval, spl[-1]))\n            else:\n                outfile.write(value)\n\n        if not self.nowrap:\n            outfile.write('\\\\end{' + self.envname + '}\\n')\n\n        if self.full:\n            encoding = self.encoding or 'utf8'\n            # map known existings encodings from LaTeX distribution\n            encoding = {\n                'utf_8': 'utf8',\n                'latin_1': 'latin1',\n                'iso_8859_1': 'latin1',\n            }.get(encoding.replace('-', '_'), encoding)\n            realoutfile.write(DOC_TEMPLATE %\n                dict(docclass  = self.docclass,\n                     preamble  = self.preamble,\n                     title     = self.title,\n                     encoding  = encoding,\n                     styledefs = self.get_style_defs(),\n                     code      = outfile.getvalue()))\n\n\nclass LatexEmbeddedLexer(Lexer):\n    \"\"\"\n    This lexer takes one lexer as argument, the lexer for the language\n    being formatted, and the left and right delimiters for escaped text.\n\n    First everything is scanned using the language lexer to obtain\n    strings and comments. All other consecutive tokens are merged and\n    the resulting text is scanned for escaped segments, which are given\n    the Token.Escape type. Finally text that is not escaped is scanned\n    again with the language lexer.\n    \"\"\"\n    def __init__(self, left, right, lang, **options):\n        self.left = left\n        self.right = right\n        self.lang = lang\n        Lexer.__init__(self, **options)\n\n    def get_tokens_unprocessed(self, text):\n        # find and remove all the escape tokens (replace with an empty string)\n        # this is very similar to DelegatingLexer.get_tokens_unprocessed.\n        buffered = ''\n        insertions = []\n        insertion_buf = []\n        for i, t, v in self._find_safe_escape_tokens(text):\n            if t is None:\n                if insertion_buf:\n                    insertions.append((len(buffered), insertion_buf))\n                    insertion_buf = []\n                buffered += v\n            else:\n                insertion_buf.append((i, t, v))\n        if insertion_buf:\n            insertions.append((len(buffered), insertion_buf))\n        return do_insertions(insertions,\n                             self.lang.get_tokens_unprocessed(buffered))\n\n    def _find_safe_escape_tokens(self, text):\n        \"\"\" find escape tokens that are not in strings or comments \"\"\"\n        for i, t, v in self._filter_to(\n            self.lang.get_tokens_unprocessed(text),\n            lambda t: t in Token.Comment or t in Token.String\n        ):\n            if t is None:\n                for i2, t2, v2 in self._find_escape_tokens(v):\n                    yield i + i2, t2, v2\n            else:\n                yield i, None, v\n\n    def _filter_to(self, it, pred):\n        \"\"\" Keep only the tokens that match `pred`, merge the others together \"\"\"\n        buf = ''\n        idx = 0\n        for i, t, v in it:\n            if pred(t):\n                if buf:\n                    yield idx, None, buf\n                    buf = ''\n                yield i, t, v\n            else:\n                if not buf:\n                    idx = i\n                buf += v\n        if buf:\n            yield idx, None, buf\n\n    def _find_escape_tokens(self, text):\n        \"\"\" Find escape tokens within text, give token=None otherwise \"\"\"\n        index = 0\n        while text:\n            a, sep1, text = text.partition(self.left)\n            if a:\n                yield index, None, a\n                index += len(a)\n            if sep1:\n                b, sep2, text = text.partition(self.right)\n                if sep2:\n                    yield index + len(sep1), Token.Escape, b\n                    index += len(sep1) + len(b) + len(sep2)\n                else:\n                    yield index, Token.Error, sep1\n                    index += len(sep1)\n                    text = b\n"},"hash":"EeQiJGD9Hu"}