{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:tests:test_soup.py","body":"# -*- coding: utf-8 -*-\n\"\"\"Tests of Beautiful Soup as a whole.\"\"\"\n\nfrom pdb import set_trace\nimport logging\nimport os\nimport pickle\nimport pytest\nimport sys\nimport tempfile\n\nfrom bs4 import (\n    BeautifulSoup,\n    BeautifulStoneSoup,\n    GuessedAtParserWarning,\n    MarkupResemblesLocatorWarning,\n    dammit,\n)\nfrom bs4.builder import (\n    builder_registry,\n    TreeBuilder,\n    ParserRejectedMarkup,\n)\nfrom bs4.element import (\n    Comment,\n    SoupStrainer,\n    PYTHON_SPECIFIC_ENCODINGS,\n    Tag,\n    NavigableString,\n)\n\nfrom . import (\n    default_builder,\n    LXML_PRESENT,\n    SoupTest,\n)\nimport warnings\n    \nclass TestConstructor(SoupTest):\n\n    def test_short_unicode_input(self):\n        data = \"<h1>éé</h1>\"\n        soup = self.soup(data)\n        assert \"éé\" == soup.h1.string\n\n    def test_embedded_null(self):\n        data = \"<h1>foo\\0bar</h1>\"\n        soup = self.soup(data)\n        assert \"foo\\0bar\" == soup.h1.string\n\n    def test_exclude_encodings(self):\n        utf8_data = \"Räksmörgås\".encode(\"utf-8\")\n        soup = self.soup(utf8_data, exclude_encodings=[\"utf-8\"])\n        assert \"windows-1252\" == soup.original_encoding\n\n    def test_custom_builder_class(self):\n        # Verify that you can pass in a custom Builder class and\n        # it'll be instantiated with the appropriate keyword arguments.\n        class Mock(object):\n            def __init__(self, **kwargs):\n                self.called_with = kwargs\n                self.is_xml = True\n                self.store_line_numbers = False\n                self.cdata_list_attributes = []\n                self.preserve_whitespace_tags = []\n                self.string_containers = {}\n            def initialize_soup(self, soup):\n                pass\n            def feed(self, markup):\n                self.fed = markup\n            def reset(self):\n                pass\n            def ignore(self, ignore):\n                pass\n            set_up_substitutions = can_be_empty_element = ignore\n            def prepare_markup(self, *args, **kwargs):\n                yield \"prepared markup\", \"original encoding\", \"declared encoding\", \"contains replacement characters\"\n                \n        kwargs = dict(\n            var=\"value\",\n            # This is a deprecated BS3-era keyword argument, which\n            # will be stripped out.\n            convertEntities=True,\n        )\n        with warnings.catch_warnings(record=True):\n            soup = BeautifulSoup('', builder=Mock, **kwargs)\n        assert isinstance(soup.builder, Mock)\n        assert dict(var=\"value\") == soup.builder.called_with\n        assert \"prepared markup\" == soup.builder.fed\n        \n        # You can also instantiate the TreeBuilder yourself. In this\n        # case, that specific object is used and any keyword arguments\n        # to the BeautifulSoup constructor are ignored.\n        builder = Mock(**kwargs)\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulSoup(\n                '', builder=builder, ignored_value=True,\n            )\n        msg = str(w[0].message)\n        assert msg.startswith(\"Keyword arguments to the BeautifulSoup constructor will be ignored.\")\n        assert builder == soup.builder\n        assert kwargs == builder.called_with\n\n    def test_parser_markup_rejection(self):\n        # If markup is completely rejected by the parser, an\n        # explanatory ParserRejectedMarkup exception is raised.\n        class Mock(TreeBuilder):\n            def feed(self, *args, **kwargs):\n                raise ParserRejectedMarkup(\"Nope.\")\n\n        def prepare_markup(self, *args, **kwargs):\n            # We're going to try two different ways of preparing this markup,\n            # but feed() will reject both of them.\n            yield markup, None, None, False\n            yield markup, None, None, False\n            \n\n        import re\n        with pytest.raises(ParserRejectedMarkup) as exc_info:\n            BeautifulSoup('', builder=Mock)\n        assert \"The markup you provided was rejected by the parser. Trying a different parser or a different encoding may help.\" in str(exc_info.value)\n        \n    def test_cdata_list_attributes(self):\n        # Most attribute values are represented as scalars, but the\n        # HTML standard says that some attributes, like 'class' have\n        # space-separated lists as values.\n        markup = '<a id=\" an id \" class=\" a class \"></a>'\n        soup = self.soup(markup)\n\n        # Note that the spaces are stripped for 'class' but not for 'id'.\n        a = soup.a\n        assert \" an id \" == a['id']\n        assert [\"a\", \"class\"] == a['class']\n\n        # TreeBuilder takes an argument called 'multi_valued_attributes'  which lets\n        # you customize or disable this. As always, you can customize the TreeBuilder\n        # by passing in a keyword argument to the BeautifulSoup constructor.\n        soup = self.soup(markup, builder=default_builder, multi_valued_attributes=None)\n        assert \" a class \" == soup.a['class']\n\n        # Here are two ways of saying that `id` is a multi-valued\n        # attribute in this context, but 'class' is not.\n        for switcheroo in ({'*': 'id'}, {'a': 'id'}):\n            with warnings.catch_warnings(record=True) as w:\n                # This will create a warning about not explicitly\n                # specifying a parser, but we'll ignore it.\n                soup = self.soup(markup, builder=None, multi_valued_attributes=switcheroo)\n            a = soup.a\n            assert [\"an\", \"id\"] == a['id']\n            assert \" a class \" == a['class']\n\n    def test_replacement_classes(self):\n        # Test the ability to pass in replacements for element classes\n        # which will be used when building the tree.\n        class TagPlus(Tag):\n            pass\n\n        class StringPlus(NavigableString):\n            pass\n\n        class CommentPlus(Comment):\n            pass\n        \n        soup = self.soup(\n            \"<a><b>foo</b>bar</a><!--whee-->\",\n            element_classes = {\n                Tag: TagPlus,\n                NavigableString: StringPlus,\n                Comment: CommentPlus,\n            }\n        )\n\n        # The tree was built with TagPlus, StringPlus, and CommentPlus objects,\n        # rather than Tag, String, and Comment objects.\n        assert all(\n            isinstance(x, (TagPlus, StringPlus, CommentPlus))\n            for x in soup.recursiveChildGenerator()\n        )\n\n    def test_alternate_string_containers(self):\n        # Test the ability to customize the string containers for\n        # different types of tags.\n        class PString(NavigableString):\n            pass\n\n        class BString(NavigableString):\n            pass\n\n        soup = self.soup(\n            \"<div>Hello.<p>Here is <b>some <i>bolded</i></b> text\",\n            string_containers = {\n                'b': BString,\n                'p': PString,\n            }\n        )\n\n        # The string before the <p> tag is a regular NavigableString.\n        assert isinstance(soup.div.contents[0], NavigableString)\n        \n        # The string inside the <p> tag, but not inside the <i> tag,\n        # is a PString.\n        assert isinstance(soup.p.contents[0], PString)\n\n        # Every string inside the <b> tag is a BString, even the one that\n        # was also inside an <i> tag.\n        for s in soup.b.strings:\n            assert isinstance(s, BString)\n\n        # Now that parsing was complete, the string_container_stack\n        # (where this information was kept) has been cleared out.\n        assert [] == soup.string_container_stack\n\n\nclass TestOutput(SoupTest):\n\n    @pytest.mark.parametrize(\n        \"eventual_encoding,actual_encoding\", [\n            (\"utf-8\", \"utf-8\"),\n            (\"utf-16\", \"utf-16\"),\n        ]\n    )\n    def test_decode_xml_declaration(self, eventual_encoding, actual_encoding):\n        # Most of the time, calling decode() on an XML document will\n        # give you a document declaration that mentions the encoding\n        # you intend to use when encoding the document as a\n        # bytestring.\n        soup = self.soup(\"<tag></tag>\")\n        soup.is_xml = True\n        assert (f'<?xml version=\"1.0\" encoding=\"{actual_encoding}\"?>\\n<tag></tag>'\n                == soup.decode(eventual_encoding=eventual_encoding))\n\n    @pytest.mark.parametrize(\n        \"eventual_encoding\", [x for x in PYTHON_SPECIFIC_ENCODINGS] + [None]\n    )\n    def test_decode_xml_declaration_with_missing_or_python_internal_eventual_encoding(self, eventual_encoding):\n        # But if you pass a Python internal encoding into decode(), or\n        # omit the eventual_encoding altogether, the document\n        # declaration won't mention any particular encoding.\n        soup = BeautifulSoup(\"<tag></tag>\", \"html.parser\")\n        soup.is_xml = True\n        assert (f'<?xml version=\"1.0\"?>\\n<tag></tag>'\n                == soup.decode(eventual_encoding=eventual_encoding))\n\n    def test(self):\n        # BeautifulSoup subclasses Tag and extends the decode() method.\n        # Make sure the other Tag methods which call decode() call\n        # it correctly.\n        soup = self.soup(\"<tag></tag>\")\n        assert b\"<tag></tag>\" == soup.encode(encoding=\"utf-8\")\n        assert b\"<tag></tag>\" == soup.encode_contents(encoding=\"utf-8\")\n        assert \"<tag></tag>\" == soup.decode_contents()\n        assert \"<tag>\\n</tag>\\n\" == soup.prettify()\n\n        \nclass TestWarnings(SoupTest):\n    # Note that some of the tests in this class create BeautifulSoup\n    # objects directly rather than using self.soup(). That's\n    # because SoupTest.soup is defined in a different file,\n    # which will throw off the assertion in _assert_warning\n    # that the code that triggered the warning is in the same\n    # file as the test.\n\n    def _assert_warning(self, warnings, cls):\n        for w in warnings:\n            if isinstance(w.message, cls):\n                assert w.filename == __file__\n                return w\n        raise Exception(\"%s warning not found in %r\" % (cls, warnings))\n    \n    def _assert_no_parser_specified(self, w):\n        warning = self._assert_warning(w, GuessedAtParserWarning)\n        message = str(warning.message)\n        assert message.startswith(BeautifulSoup.NO_PARSER_SPECIFIED_WARNING[:60])\n\n    def test_warning_if_no_parser_specified(self):\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulSoup(\"<a><b></b></a>\")\n        self._assert_no_parser_specified(w)\n\n    def test_warning_if_parser_specified_too_vague(self):\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulSoup(\"<a><b></b></a>\", \"html\")\n        self._assert_no_parser_specified(w)\n\n    def test_no_warning_if_explicit_parser_specified(self):\n        with warnings.catch_warnings(record=True) as w:\n            soup = self.soup(\"<a><b></b></a>\")\n        assert [] == w\n\n    def test_parseOnlyThese_renamed_to_parse_only(self):\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulSoup(\n                \"<a><b></b></a>\", \"html.parser\",\n                parseOnlyThese=SoupStrainer(\"b\"),\n            )\n        warning = self._assert_warning(w, DeprecationWarning)\n        msg = str(warning.message)\n        assert \"parseOnlyThese\" in msg\n        assert \"parse_only\" in msg\n        assert b\"<b></b>\" == soup.encode()\n\n    def test_fromEncoding_renamed_to_from_encoding(self):\n        with warnings.catch_warnings(record=True) as w:\n            utf8 = b\"\\xc3\\xa9\"\n            soup = BeautifulSoup(\n                utf8, \"html.parser\", fromEncoding=\"utf8\"\n            )\n        warning = self._assert_warning(w, DeprecationWarning)\n        msg = str(warning.message)\n        assert \"fromEncoding\" in msg\n        assert \"from_encoding\" in msg\n        assert \"utf8\" == soup.original_encoding\n\n    def test_unrecognized_keyword_argument(self):\n        with pytest.raises(TypeError):\n            self.soup(\"<a>\", no_such_argument=True)\n\n    @pytest.mark.parametrize(\n        \"extension\",\n        ['markup.html', 'markup.htm', 'markup.HTML', 'markup.txt',\n         'markup.xhtml', 'markup.xml', \"/home/user/file\", \"c:\\\\user\\file\"]\n    )\n    def test_resembles_filename_warning(self, extension):\n        # A warning is issued if the \"markup\" looks like the name of\n        # an HTML or text file, or a full path to a file on disk.\n        with warnings.catch_warnings(record=True) as w:\n            soup = BeautifulSoup(\"markup\" + extension, \"html.parser\")\n            warning = self._assert_warning(w, MarkupResemblesLocatorWarning)\n            assert \"looks more like a filename\" in str(warning.message)\n\n    @pytest.mark.parametrize(\n        \"extension\",\n        ['markuphtml', 'markup.com', '', 'markup.js']\n    )\n    def test_resembles_filename_no_warning(self, extension):\n        # The 'looks more like a filename' warning is not issued if\n        # the markup looks like a bare string, a domain name, or a\n        # file that's not an HTML file.\n        with warnings.catch_warnings(record=True) as w:\n            soup = self.soup(\"markup\" + extension)\n        assert [] == w\n\n    def test_url_warning_with_bytes_url(self):\n        url = b\"http://www.crummybytes.com/\"\n        with warnings.catch_warnings(record=True) as warning_list:\n            soup = BeautifulSoup(url, \"html.parser\")\n        warning = self._assert_warning(\n            warning_list, MarkupResemblesLocatorWarning\n        )\n        assert \"looks more like a URL\" in str(warning.message)\n        assert url not in str(warning.message).encode(\"utf8\")\n        \n    def test_url_warning_with_unicode_url(self):\n        url = \"http://www.crummyunicode.com/\"\n        with warnings.catch_warnings(record=True) as warning_list:\n            # note - this url must differ from the bytes one otherwise\n            # python's warnings system swallows the second warning\n            soup = BeautifulSoup(url, \"html.parser\")\n        warning = self._assert_warning(\n            warning_list, MarkupResemblesLocatorWarning\n        )\n        assert \"looks more like a URL\" in str(warning.message)\n        assert url not in str(warning.message)\n\n    def test_url_warning_with_bytes_and_space(self):\n        # Here the markup contains something besides a URL, so no warning\n        # is issued.\n        with warnings.catch_warnings(record=True) as warning_list:\n            soup = self.soup(b\"http://www.crummybytes.com/ is great\")\n        assert not any(\"looks more like a URL\" in str(w.message) \n                       for w in warning_list)\n\n    def test_url_warning_with_unicode_and_space(self):\n        with warnings.catch_warnings(record=True) as warning_list:\n            soup = self.soup(\"http://www.crummyunicode.com/ is great\")\n        assert not any(\"looks more like a URL\" in str(w.message) \n                       for w in warning_list)\n\n\nclass TestSelectiveParsing(SoupTest):\n\n    def test_parse_with_soupstrainer(self):\n        markup = \"No<b>Yes</b><a>No<b>Yes <c>Yes</c></b>\"\n        strainer = SoupStrainer(\"b\")\n        soup = self.soup(markup, parse_only=strainer)\n        assert soup.encode() == b\"<b>Yes</b><b>Yes <c>Yes</c></b>\"\n\n        \nclass TestNewTag(SoupTest):\n    \"\"\"Test the BeautifulSoup.new_tag() method.\"\"\"\n    def test_new_tag(self):\n        soup = self.soup(\"\")\n        new_tag = soup.new_tag(\"foo\", bar=\"baz\", attrs={\"name\": \"a name\"})\n        assert isinstance(new_tag, Tag)\n        assert \"foo\" == new_tag.name\n        assert dict(bar=\"baz\", name=\"a name\") == new_tag.attrs\n        assert None == new_tag.parent\n\n    @pytest.mark.skipif(\n        not LXML_PRESENT,\n        reason=\"lxml not installed, cannot parse XML document\"\n    )\n    def test_xml_tag_inherits_self_closing_rules_from_builder(self):\n        xml_soup = BeautifulSoup(\"\", \"xml\")\n        xml_br = xml_soup.new_tag(\"br\")\n        xml_p = xml_soup.new_tag(\"p\")\n\n        # Both the <br> and <p> tag are empty-element, just because\n        # they have no contents.\n        assert b\"<br/>\" == xml_br.encode()\n        assert b\"<p/>\" == xml_p.encode()\n\n    def test_tag_inherits_self_closing_rules_from_builder(self):\n        html_soup = BeautifulSoup(\"\", \"html.parser\")\n        html_br = html_soup.new_tag(\"br\")\n        html_p = html_soup.new_tag(\"p\")\n\n        # The HTML builder users HTML's rules about which tags are\n        # empty-element tags, and the new tags reflect these rules.\n        assert b\"<br/>\" == html_br.encode()\n        assert b\"<p></p>\" == html_p.encode()\n\nclass TestNewString(SoupTest):\n    \"\"\"Test the BeautifulSoup.new_string() method.\"\"\"\n    def test_new_string_creates_navigablestring(self):\n        soup = self.soup(\"\")\n        s = soup.new_string(\"foo\")\n        assert \"foo\" == s\n        assert isinstance(s, NavigableString)\n\n    def test_new_string_can_create_navigablestring_subclass(self):\n        soup = self.soup(\"\")\n        s = soup.new_string(\"foo\", Comment)\n        assert \"foo\" == s\n        assert isinstance(s, Comment)\n\n\nclass TestPickle(SoupTest):\n   # Test our ability to pickle the BeautifulSoup object itself.\n\n    def test_normal_pickle(self):\n        soup = self.soup(\"<a>some markup</a>\")\n        pickled = pickle.dumps(soup)\n        unpickled = pickle.loads(pickled)\n        assert \"some markup\" == unpickled.a.string\n        \n    def test_pickle_with_no_builder(self):\n        # We had a bug that prevented pickling from working if\n        # the builder wasn't set.\n        soup = self.soup(\"some markup\")\n        soup.builder = None\n        pickled = pickle.dumps(soup)\n        unpickled = pickle.loads(pickled)\n        assert \"some markup\" == unpickled.string\n\nclass TestEncodingConversion(SoupTest):\n    # Test Beautiful Soup's ability to decode and encode from various\n    # encodings.\n\n    def setup_method(self):\n        self.unicode_data = '<html><head><meta charset=\"utf-8\"/></head><body><foo>Sacr\\N{LATIN SMALL LETTER E WITH ACUTE} bleu!</foo></body></html>'\n        self.utf8_data = self.unicode_data.encode(\"utf-8\")\n        # Just so you know what it looks like.\n        assert self.utf8_data == b'<html><head><meta charset=\"utf-8\"/></head><body><foo>Sacr\\xc3\\xa9 bleu!</foo></body></html>'\n\n    def test_ascii_in_unicode_out(self):\n        # ASCII input is converted to Unicode. The original_encoding\n        # attribute is set to 'utf-8', a superset of ASCII.\n        chardet = dammit.chardet_dammit\n        logging.disable(logging.WARNING)\n        try:\n            def noop(str):\n                return None\n            # Disable chardet, which will realize that the ASCII is ASCII.\n            dammit.chardet_dammit = noop\n            ascii = b\"<foo>a</foo>\"\n            soup_from_ascii = self.soup(ascii)\n            unicode_output = soup_from_ascii.decode()\n            assert isinstance(unicode_output, str)\n            assert unicode_output == self.document_for(ascii.decode())\n            assert soup_from_ascii.original_encoding.lower() == \"utf-8\"\n        finally:\n            logging.disable(logging.NOTSET)\n            dammit.chardet_dammit = chardet\n\n    def test_unicode_in_unicode_out(self):\n        # Unicode input is left alone. The original_encoding attribute\n        # is not set.\n        soup_from_unicode = self.soup(self.unicode_data)\n        assert soup_from_unicode.decode() == self.unicode_data\n        assert soup_from_unicode.foo.string == 'Sacr\\xe9 bleu!'\n        assert soup_from_unicode.original_encoding == None\n\n    def test_utf8_in_unicode_out(self):\n        # UTF-8 input is converted to Unicode. The original_encoding\n        # attribute is set.\n        soup_from_utf8 = self.soup(self.utf8_data)\n        assert soup_from_utf8.decode() == self.unicode_data\n        assert soup_from_utf8.foo.string == 'Sacr\\xe9 bleu!'\n\n    def test_utf8_out(self):\n        # The internal data structures can be encoded as UTF-8.\n        soup_from_unicode = self.soup(self.unicode_data)\n        assert soup_from_unicode.encode('utf-8') == self.utf8_data\n"},"hash":"HnCuElTDm1"}