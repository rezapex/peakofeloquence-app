{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:pip:_internal:operations:install:wheel.py","body":"\"\"\"Support for installing and building the \"wheel\" binary package format.\n\"\"\"\n\nimport collections\nimport compileall\nimport contextlib\nimport csv\nimport importlib\nimport logging\nimport os.path\nimport re\nimport shutil\nimport sys\nimport warnings\nfrom base64 import urlsafe_b64encode\nfrom email.message import Message\nfrom itertools import chain, filterfalse, starmap\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    BinaryIO,\n    Callable,\n    Dict,\n    Generator,\n    Iterable,\n    Iterator,\n    List,\n    NewType,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Union,\n    cast,\n)\nfrom zipfile import ZipFile, ZipInfo\n\nfrom pip._vendor.distlib.scripts import ScriptMaker\nfrom pip._vendor.distlib.util import get_export_entry\nfrom pip._vendor.packaging.utils import canonicalize_name\n\nfrom pip._internal.exceptions import InstallationError\nfrom pip._internal.locations import get_major_minor_version\nfrom pip._internal.metadata import (\n    BaseDistribution,\n    FilesystemWheel,\n    get_wheel_distribution,\n)\nfrom pip._internal.models.direct_url import DIRECT_URL_METADATA_NAME, DirectUrl\nfrom pip._internal.models.scheme import SCHEME_KEYS, Scheme\nfrom pip._internal.utils.filesystem import adjacent_tmp_file, replace\nfrom pip._internal.utils.misc import captured_stdout, ensure_dir, hash_file, partition\nfrom pip._internal.utils.unpacking import (\n    current_umask,\n    is_within_directory,\n    set_extracted_file_to_default_mode_plus_executable,\n    zip_item_is_executable,\n)\nfrom pip._internal.utils.wheel import parse_wheel\n\nif TYPE_CHECKING:\n    from typing import Protocol\n\n    class File(Protocol):\n        src_record_path: \"RecordPath\"\n        dest_path: str\n        changed: bool\n\n        def save(self) -> None:\n            pass\n\n\nlogger = logging.getLogger(__name__)\n\nRecordPath = NewType(\"RecordPath\", str)\nInstalledCSVRow = Tuple[RecordPath, str, Union[int, str]]\n\n\ndef rehash(path: str, blocksize: int = 1 << 20) -> Tuple[str, str]:\n    \"\"\"Return (encoded_digest, length) for path using hashlib.sha256()\"\"\"\n    h, length = hash_file(path, blocksize)\n    digest = \"sha256=\" + urlsafe_b64encode(h.digest()).decode(\"latin1\").rstrip(\"=\")\n    return (digest, str(length))\n\n\ndef csv_io_kwargs(mode: str) -> Dict[str, Any]:\n    \"\"\"Return keyword arguments to properly open a CSV file\n    in the given mode.\n    \"\"\"\n    return {\"mode\": mode, \"newline\": \"\", \"encoding\": \"utf-8\"}\n\n\ndef fix_script(path: str) -> bool:\n    \"\"\"Replace #!python with #!/path/to/python\n    Return True if file was changed.\n    \"\"\"\n    # XXX RECORD hashes will need to be updated\n    assert os.path.isfile(path)\n\n    with open(path, \"rb\") as script:\n        firstline = script.readline()\n        if not firstline.startswith(b\"#!python\"):\n            return False\n        exename = sys.executable.encode(sys.getfilesystemencoding())\n        firstline = b\"#!\" + exename + os.linesep.encode(\"ascii\")\n        rest = script.read()\n    with open(path, \"wb\") as script:\n        script.write(firstline)\n        script.write(rest)\n    return True\n\n\ndef wheel_root_is_purelib(metadata: Message) -> bool:\n    return metadata.get(\"Root-Is-Purelib\", \"\").lower() == \"true\"\n\n\ndef get_entrypoints(dist: BaseDistribution) -> Tuple[Dict[str, str], Dict[str, str]]:\n    console_scripts = {}\n    gui_scripts = {}\n    for entry_point in dist.iter_entry_points():\n        if entry_point.group == \"console_scripts\":\n            console_scripts[entry_point.name] = entry_point.value\n        elif entry_point.group == \"gui_scripts\":\n            gui_scripts[entry_point.name] = entry_point.value\n    return console_scripts, gui_scripts\n\n\ndef message_about_scripts_not_on_PATH(scripts: Sequence[str]) -> Optional[str]:\n    \"\"\"Determine if any scripts are not on PATH and format a warning.\n    Returns a warning message if one or more scripts are not on PATH,\n    otherwise None.\n    \"\"\"\n    if not scripts:\n        return None\n\n    # Group scripts by the path they were installed in\n    grouped_by_dir: Dict[str, Set[str]] = collections.defaultdict(set)\n    for destfile in scripts:\n        parent_dir = os.path.dirname(destfile)\n        script_name = os.path.basename(destfile)\n        grouped_by_dir[parent_dir].add(script_name)\n\n    # We don't want to warn for directories that are on PATH.\n    not_warn_dirs = [\n        os.path.normcase(os.path.normpath(i)).rstrip(os.sep)\n        for i in os.environ.get(\"PATH\", \"\").split(os.pathsep)\n    ]\n    # If an executable sits with sys.executable, we don't warn for it.\n    #     This covers the case of venv invocations without activating the venv.\n    not_warn_dirs.append(\n        os.path.normcase(os.path.normpath(os.path.dirname(sys.executable)))\n    )\n    warn_for: Dict[str, Set[str]] = {\n        parent_dir: scripts\n        for parent_dir, scripts in grouped_by_dir.items()\n        if os.path.normcase(os.path.normpath(parent_dir)) not in not_warn_dirs\n    }\n    if not warn_for:\n        return None\n\n    # Format a message\n    msg_lines = []\n    for parent_dir, dir_scripts in warn_for.items():\n        sorted_scripts: List[str] = sorted(dir_scripts)\n        if len(sorted_scripts) == 1:\n            start_text = f\"script {sorted_scripts[0]} is\"\n        else:\n            start_text = \"scripts {} are\".format(\n                \", \".join(sorted_scripts[:-1]) + \" and \" + sorted_scripts[-1]\n            )\n\n        msg_lines.append(\n            f\"The {start_text} installed in '{parent_dir}' which is not on PATH.\"\n        )\n\n    last_line_fmt = (\n        \"Consider adding {} to PATH or, if you prefer \"\n        \"to suppress this warning, use --no-warn-script-location.\"\n    )\n    if len(msg_lines) == 1:\n        msg_lines.append(last_line_fmt.format(\"this directory\"))\n    else:\n        msg_lines.append(last_line_fmt.format(\"these directories\"))\n\n    # Add a note if any directory starts with ~\n    warn_for_tilde = any(\n        i[0] == \"~\" for i in os.environ.get(\"PATH\", \"\").split(os.pathsep) if i\n    )\n    if warn_for_tilde:\n        tilde_warning_msg = (\n            \"NOTE: The current PATH contains path(s) starting with `~`, \"\n            \"which may not be expanded by all applications.\"\n        )\n        msg_lines.append(tilde_warning_msg)\n\n    # Returns the formatted multiline message\n    return \"\\n\".join(msg_lines)\n\n\ndef _normalized_outrows(\n    outrows: Iterable[InstalledCSVRow],\n) -> List[Tuple[str, str, str]]:\n    \"\"\"Normalize the given rows of a RECORD file.\n\n    Items in each row are converted into str. Rows are then sorted to make\n    the value more predictable for tests.\n\n    Each row is a 3-tuple (path, hash, size) and corresponds to a record of\n    a RECORD file (see PEP 376 and PEP 427 for details).  For the rows\n    passed to this function, the size can be an integer as an int or string,\n    or the empty string.\n    \"\"\"\n    # Normally, there should only be one row per path, in which case the\n    # second and third elements don't come into play when sorting.\n    # However, in cases in the wild where a path might happen to occur twice,\n    # we don't want the sort operation to trigger an error (but still want\n    # determinism).  Since the third element can be an int or string, we\n    # coerce each element to a string to avoid a TypeError in this case.\n    # For additional background, see--\n    # https://github.com/pypa/pip/issues/5868\n    return sorted(\n        (record_path, hash_, str(size)) for record_path, hash_, size in outrows\n    )\n\n\ndef _record_to_fs_path(record_path: RecordPath, lib_dir: str) -> str:\n    return os.path.join(lib_dir, record_path)\n\n\ndef _fs_to_record_path(path: str, lib_dir: str) -> RecordPath:\n    # On Windows, do not handle relative paths if they belong to different\n    # logical disks\n    if os.path.splitdrive(path)[0].lower() == os.path.splitdrive(lib_dir)[0].lower():\n        path = os.path.relpath(path, lib_dir)\n\n    path = path.replace(os.path.sep, \"/\")\n    return cast(\"RecordPath\", path)\n\n\ndef get_csv_rows_for_installed(\n    old_csv_rows: List[List[str]],\n    installed: Dict[RecordPath, RecordPath],\n    changed: Set[RecordPath],\n    generated: List[str],\n    lib_dir: str,\n) -> List[InstalledCSVRow]:\n    \"\"\"\n    :param installed: A map from archive RECORD path to installation RECORD\n        path.\n    \"\"\"\n    installed_rows: List[InstalledCSVRow] = []\n    for row in old_csv_rows:\n        if len(row) > 3:\n            logger.warning(\"RECORD line has more than three elements: %s\", row)\n        old_record_path = cast(\"RecordPath\", row[0])\n        new_record_path = installed.pop(old_record_path, old_record_path)\n        if new_record_path in changed:\n            digest, length = rehash(_record_to_fs_path(new_record_path, lib_dir))\n        else:\n            digest = row[1] if len(row) > 1 else \"\"\n            length = row[2] if len(row) > 2 else \"\"\n        installed_rows.append((new_record_path, digest, length))\n    for f in generated:\n        path = _fs_to_record_path(f, lib_dir)\n        digest, length = rehash(f)\n        installed_rows.append((path, digest, length))\n    return installed_rows + [\n        (installed_record_path, \"\", \"\") for installed_record_path in installed.values()\n    ]\n\n\ndef get_console_script_specs(console: Dict[str, str]) -> List[str]:\n    \"\"\"\n    Given the mapping from entrypoint name to callable, return the relevant\n    console script specs.\n    \"\"\"\n    # Don't mutate caller's version\n    console = console.copy()\n\n    scripts_to_generate = []\n\n    # Special case pip and setuptools to generate versioned wrappers\n    #\n    # The issue is that some projects (specifically, pip and setuptools) use\n    # code in setup.py to create \"versioned\" entry points - pip2.7 on Python\n    # 2.7, pip3.3 on Python 3.3, etc. But these entry points are baked into\n    # the wheel metadata at build time, and so if the wheel is installed with\n    # a *different* version of Python the entry points will be wrong. The\n    # correct fix for this is to enhance the metadata to be able to describe\n    # such versioned entry points, but that won't happen till Metadata 2.0 is\n    # available.\n    # In the meantime, projects using versioned entry points will either have\n    # incorrect versioned entry points, or they will not be able to distribute\n    # \"universal\" wheels (i.e., they will need a wheel per Python version).\n    #\n    # Because setuptools and pip are bundled with _ensurepip and virtualenv,\n    # we need to use universal wheels. So, as a stopgap until Metadata 2.0, we\n    # override the versioned entry points in the wheel and generate the\n    # correct ones. This code is purely a short-term measure until Metadata 2.0\n    # is available.\n    #\n    # To add the level of hack in this section of code, in order to support\n    # ensurepip this code will look for an ``ENSUREPIP_OPTIONS`` environment\n    # variable which will control which version scripts get installed.\n    #\n    # ENSUREPIP_OPTIONS=altinstall\n    #   - Only pipX.Y and easy_install-X.Y will be generated and installed\n    # ENSUREPIP_OPTIONS=install\n    #   - pipX.Y, pipX, easy_install-X.Y will be generated and installed. Note\n    #     that this option is technically if ENSUREPIP_OPTIONS is set and is\n    #     not altinstall\n    # DEFAULT\n    #   - The default behavior is to install pip, pipX, pipX.Y, easy_install\n    #     and easy_install-X.Y.\n    pip_script = console.pop(\"pip\", None)\n    if pip_script:\n        if \"ENSUREPIP_OPTIONS\" not in os.environ:\n            scripts_to_generate.append(\"pip = \" + pip_script)\n\n        if os.environ.get(\"ENSUREPIP_OPTIONS\", \"\") != \"altinstall\":\n            scripts_to_generate.append(f\"pip{sys.version_info[0]} = {pip_script}\")\n\n        scripts_to_generate.append(f\"pip{get_major_minor_version()} = {pip_script}\")\n        # Delete any other versioned pip entry points\n        pip_ep = [k for k in console if re.match(r\"pip(\\d+(\\.\\d+)?)?$\", k)]\n        for k in pip_ep:\n            del console[k]\n    easy_install_script = console.pop(\"easy_install\", None)\n    if easy_install_script:\n        if \"ENSUREPIP_OPTIONS\" not in os.environ:\n            scripts_to_generate.append(\"easy_install = \" + easy_install_script)\n\n        scripts_to_generate.append(\n            f\"easy_install-{get_major_minor_version()} = {easy_install_script}\"\n        )\n        # Delete any other versioned easy_install entry points\n        easy_install_ep = [\n            k for k in console if re.match(r\"easy_install(-\\d+\\.\\d+)?$\", k)\n        ]\n        for k in easy_install_ep:\n            del console[k]\n\n    # Generate the console entry points specified in the wheel\n    scripts_to_generate.extend(starmap(\"{} = {}\".format, console.items()))\n\n    return scripts_to_generate\n\n\nclass ZipBackedFile:\n    def __init__(\n        self, src_record_path: RecordPath, dest_path: str, zip_file: ZipFile\n    ) -> None:\n        self.src_record_path = src_record_path\n        self.dest_path = dest_path\n        self._zip_file = zip_file\n        self.changed = False\n\n    def _getinfo(self) -> ZipInfo:\n        return self._zip_file.getinfo(self.src_record_path)\n\n    def save(self) -> None:\n        # directory creation is lazy and after file filtering\n        # to ensure we don't install empty dirs; empty dirs can't be\n        # uninstalled.\n        parent_dir = os.path.dirname(self.dest_path)\n        ensure_dir(parent_dir)\n\n        # When we open the output file below, any existing file is truncated\n        # before we start writing the new contents. This is fine in most\n        # cases, but can cause a segfault if pip has loaded a shared\n        # object (e.g. from pyopenssl through its vendored urllib3)\n        # Since the shared object is mmap'd an attempt to call a\n        # symbol in it will then cause a segfault. Unlinking the file\n        # allows writing of new contents while allowing the process to\n        # continue to use the old copy.\n        if os.path.exists(self.dest_path):\n            os.unlink(self.dest_path)\n\n        zipinfo = self._getinfo()\n\n        with self._zip_file.open(zipinfo) as f:\n            with open(self.dest_path, \"wb\") as dest:\n                shutil.copyfileobj(f, dest)\n\n        if zip_item_is_executable(zipinfo):\n            set_extracted_file_to_default_mode_plus_executable(self.dest_path)\n\n\nclass ScriptFile:\n    def __init__(self, file: \"File\") -> None:\n        self._file = file\n        self.src_record_path = self._file.src_record_path\n        self.dest_path = self._file.dest_path\n        self.changed = False\n\n    def save(self) -> None:\n        self._file.save()\n        self.changed = fix_script(self.dest_path)\n\n\nclass MissingCallableSuffix(InstallationError):\n    def __init__(self, entry_point: str) -> None:\n        super().__init__(\n            f\"Invalid script entry point: {entry_point} - A callable \"\n            \"suffix is required. Cf https://packaging.python.org/\"\n            \"specifications/entry-points/#use-for-scripts for more \"\n            \"information.\"\n        )\n\n\ndef _raise_for_invalid_entrypoint(specification: str) -> None:\n    entry = get_export_entry(specification)\n    if entry is not None and entry.suffix is None:\n        raise MissingCallableSuffix(str(entry))\n\n\nclass PipScriptMaker(ScriptMaker):\n    def make(\n        self, specification: str, options: Optional[Dict[str, Any]] = None\n    ) -> List[str]:\n        _raise_for_invalid_entrypoint(specification)\n        return super().make(specification, options)\n\n\ndef _install_wheel(\n    name: str,\n    wheel_zip: ZipFile,\n    wheel_path: str,\n    scheme: Scheme,\n    pycompile: bool = True,\n    warn_script_location: bool = True,\n    direct_url: Optional[DirectUrl] = None,\n    requested: bool = False,\n) -> None:\n    \"\"\"Install a wheel.\n\n    :param name: Name of the project to install\n    :param wheel_zip: open ZipFile for wheel being installed\n    :param scheme: Distutils scheme dictating the install directories\n    :param req_description: String used in place of the requirement, for\n        logging\n    :param pycompile: Whether to byte-compile installed Python files\n    :param warn_script_location: Whether to check that scripts are installed\n        into a directory on PATH\n    :raises UnsupportedWheel:\n        * when the directory holds an unpacked wheel with incompatible\n          Wheel-Version\n        * when the .dist-info dir does not match the wheel\n    \"\"\"\n    info_dir, metadata = parse_wheel(wheel_zip, name)\n\n    if wheel_root_is_purelib(metadata):\n        lib_dir = scheme.purelib\n    else:\n        lib_dir = scheme.platlib\n\n    # Record details of the files moved\n    #   installed = files copied from the wheel to the destination\n    #   changed = files changed while installing (scripts #! line typically)\n    #   generated = files newly generated during the install (script wrappers)\n    installed: Dict[RecordPath, RecordPath] = {}\n    changed: Set[RecordPath] = set()\n    generated: List[str] = []\n\n    def record_installed(\n        srcfile: RecordPath, destfile: str, modified: bool = False\n    ) -> None:\n        \"\"\"Map archive RECORD paths to installation RECORD paths.\"\"\"\n        newpath = _fs_to_record_path(destfile, lib_dir)\n        installed[srcfile] = newpath\n        if modified:\n            changed.add(newpath)\n\n    def is_dir_path(path: RecordPath) -> bool:\n        return path.endswith(\"/\")\n\n    def assert_no_path_traversal(dest_dir_path: str, target_path: str) -> None:\n        if not is_within_directory(dest_dir_path, target_path):\n            message = (\n                \"The wheel {!r} has a file {!r} trying to install\"\n                \" outside the target directory {!r}\"\n            )\n            raise InstallationError(\n                message.format(wheel_path, target_path, dest_dir_path)\n            )\n\n    def root_scheme_file_maker(\n        zip_file: ZipFile, dest: str\n    ) -> Callable[[RecordPath], \"File\"]:\n        def make_root_scheme_file(record_path: RecordPath) -> \"File\":\n            normed_path = os.path.normpath(record_path)\n            dest_path = os.path.join(dest, normed_path)\n            assert_no_path_traversal(dest, dest_path)\n            return ZipBackedFile(record_path, dest_path, zip_file)\n\n        return make_root_scheme_file\n\n    def data_scheme_file_maker(\n        zip_file: ZipFile, scheme: Scheme\n    ) -> Callable[[RecordPath], \"File\"]:\n        scheme_paths = {key: getattr(scheme, key) for key in SCHEME_KEYS}\n\n        def make_data_scheme_file(record_path: RecordPath) -> \"File\":\n            normed_path = os.path.normpath(record_path)\n            try:\n                _, scheme_key, dest_subpath = normed_path.split(os.path.sep, 2)\n            except ValueError:\n                message = (\n                    \"Unexpected file in {}: {!r}. .data directory contents\"\n                    \" should be named like: '<scheme key>/<path>'.\"\n                ).format(wheel_path, record_path)\n                raise InstallationError(message)\n\n            try:\n                scheme_path = scheme_paths[scheme_key]\n            except KeyError:\n                valid_scheme_keys = \", \".join(sorted(scheme_paths))\n                message = (\n                    \"Unknown scheme key used in {}: {} (for file {!r}). .data\"\n                    \" directory contents should be in subdirectories named\"\n                    \" with a valid scheme key ({})\"\n                ).format(wheel_path, scheme_key, record_path, valid_scheme_keys)\n                raise InstallationError(message)\n\n            dest_path = os.path.join(scheme_path, dest_subpath)\n            assert_no_path_traversal(scheme_path, dest_path)\n            return ZipBackedFile(record_path, dest_path, zip_file)\n\n        return make_data_scheme_file\n\n    def is_data_scheme_path(path: RecordPath) -> bool:\n        return path.split(\"/\", 1)[0].endswith(\".data\")\n\n    paths = cast(List[RecordPath], wheel_zip.namelist())\n    file_paths = filterfalse(is_dir_path, paths)\n    root_scheme_paths, data_scheme_paths = partition(is_data_scheme_path, file_paths)\n\n    make_root_scheme_file = root_scheme_file_maker(wheel_zip, lib_dir)\n    files: Iterator[File] = map(make_root_scheme_file, root_scheme_paths)\n\n    def is_script_scheme_path(path: RecordPath) -> bool:\n        parts = path.split(\"/\", 2)\n        return len(parts) > 2 and parts[0].endswith(\".data\") and parts[1] == \"scripts\"\n\n    other_scheme_paths, script_scheme_paths = partition(\n        is_script_scheme_path, data_scheme_paths\n    )\n\n    make_data_scheme_file = data_scheme_file_maker(wheel_zip, scheme)\n    other_scheme_files = map(make_data_scheme_file, other_scheme_paths)\n    files = chain(files, other_scheme_files)\n\n    # Get the defined entry points\n    distribution = get_wheel_distribution(\n        FilesystemWheel(wheel_path),\n        canonicalize_name(name),\n    )\n    console, gui = get_entrypoints(distribution)\n\n    def is_entrypoint_wrapper(file: \"File\") -> bool:\n        # EP, EP.exe and EP-script.py are scripts generated for\n        # entry point EP by setuptools\n        path = file.dest_path\n        name = os.path.basename(path)\n        if name.lower().endswith(\".exe\"):\n            matchname = name[:-4]\n        elif name.lower().endswith(\"-script.py\"):\n            matchname = name[:-10]\n        elif name.lower().endswith(\".pya\"):\n            matchname = name[:-4]\n        else:\n            matchname = name\n        # Ignore setuptools-generated scripts\n        return matchname in console or matchname in gui\n\n    script_scheme_files: Iterator[File] = map(\n        make_data_scheme_file, script_scheme_paths\n    )\n    script_scheme_files = filterfalse(is_entrypoint_wrapper, script_scheme_files)\n    script_scheme_files = map(ScriptFile, script_scheme_files)\n    files = chain(files, script_scheme_files)\n\n    for file in files:\n        file.save()\n        record_installed(file.src_record_path, file.dest_path, file.changed)\n\n    def pyc_source_file_paths() -> Generator[str, None, None]:\n        # We de-duplicate installation paths, since there can be overlap (e.g.\n        # file in .data maps to same location as file in wheel root).\n        # Sorting installation paths makes it easier to reproduce and debug\n        # issues related to permissions on existing files.\n        for installed_path in sorted(set(installed.values())):\n            full_installed_path = os.path.join(lib_dir, installed_path)\n            if not os.path.isfile(full_installed_path):\n                continue\n            if not full_installed_path.endswith(\".py\"):\n                continue\n            yield full_installed_path\n\n    def pyc_output_path(path: str) -> str:\n        \"\"\"Return the path the pyc file would have been written to.\"\"\"\n        return importlib.util.cache_from_source(path)\n\n    # Compile all of the pyc files for the installed files\n    if pycompile:\n        with captured_stdout() as stdout:\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                for path in pyc_source_file_paths():\n                    success = compileall.compile_file(path, force=True, quiet=True)\n                    if success:\n                        pyc_path = pyc_output_path(path)\n                        assert os.path.exists(pyc_path)\n                        pyc_record_path = cast(\n                            \"RecordPath\", pyc_path.replace(os.path.sep, \"/\")\n                        )\n                        record_installed(pyc_record_path, pyc_path)\n        logger.debug(stdout.getvalue())\n\n    maker = PipScriptMaker(None, scheme.scripts)\n\n    # Ensure old scripts are overwritten.\n    # See https://github.com/pypa/pip/issues/1800\n    maker.clobber = True\n\n    # Ensure we don't generate any variants for scripts because this is almost\n    # never what somebody wants.\n    # See https://bitbucket.org/pypa/distlib/issue/35/\n    maker.variants = {\"\"}\n\n    # This is required because otherwise distlib creates scripts that are not\n    # executable.\n    # See https://bitbucket.org/pypa/distlib/issue/32/\n    maker.set_mode = True\n\n    # Generate the console and GUI entry points specified in the wheel\n    scripts_to_generate = get_console_script_specs(console)\n\n    gui_scripts_to_generate = list(starmap(\"{} = {}\".format, gui.items()))\n\n    generated_console_scripts = maker.make_multiple(scripts_to_generate)\n    generated.extend(generated_console_scripts)\n\n    generated.extend(maker.make_multiple(gui_scripts_to_generate, {\"gui\": True}))\n\n    if warn_script_location:\n        msg = message_about_scripts_not_on_PATH(generated_console_scripts)\n        if msg is not None:\n            logger.warning(msg)\n\n    generated_file_mode = 0o666 & ~current_umask()\n\n    @contextlib.contextmanager\n    def _generate_file(path: str, **kwargs: Any) -> Generator[BinaryIO, None, None]:\n        with adjacent_tmp_file(path, **kwargs) as f:\n            yield f\n        os.chmod(f.name, generated_file_mode)\n        replace(f.name, path)\n\n    dest_info_dir = os.path.join(lib_dir, info_dir)\n\n    # Record pip as the installer\n    installer_path = os.path.join(dest_info_dir, \"INSTALLER\")\n    with _generate_file(installer_path) as installer_file:\n        installer_file.write(b\"pip\\n\")\n    generated.append(installer_path)\n\n    # Record the PEP 610 direct URL reference\n    if direct_url is not None:\n        direct_url_path = os.path.join(dest_info_dir, DIRECT_URL_METADATA_NAME)\n        with _generate_file(direct_url_path) as direct_url_file:\n            direct_url_file.write(direct_url.to_json().encode(\"utf-8\"))\n        generated.append(direct_url_path)\n\n    # Record the REQUESTED file\n    if requested:\n        requested_path = os.path.join(dest_info_dir, \"REQUESTED\")\n        with open(requested_path, \"wb\"):\n            pass\n        generated.append(requested_path)\n\n    record_text = distribution.read_text(\"RECORD\")\n    record_rows = list(csv.reader(record_text.splitlines()))\n\n    rows = get_csv_rows_for_installed(\n        record_rows,\n        installed=installed,\n        changed=changed,\n        generated=generated,\n        lib_dir=lib_dir,\n    )\n\n    # Record details of all files installed\n    record_path = os.path.join(dest_info_dir, \"RECORD\")\n\n    with _generate_file(record_path, **csv_io_kwargs(\"w\")) as record_file:\n        # Explicitly cast to typing.IO[str] as a workaround for the mypy error:\n        # \"writer\" has incompatible type \"BinaryIO\"; expected \"_Writer\"\n        writer = csv.writer(cast(\"IO[str]\", record_file))\n        writer.writerows(_normalized_outrows(rows))\n\n\n@contextlib.contextmanager\ndef req_error_context(req_description: str) -> Generator[None, None, None]:\n    try:\n        yield\n    except InstallationError as e:\n        message = f\"For req: {req_description}. {e.args[0]}\"\n        raise InstallationError(message) from e\n\n\ndef install_wheel(\n    name: str,\n    wheel_path: str,\n    scheme: Scheme,\n    req_description: str,\n    pycompile: bool = True,\n    warn_script_location: bool = True,\n    direct_url: Optional[DirectUrl] = None,\n    requested: bool = False,\n) -> None:\n    with ZipFile(wheel_path, allowZip64=True) as z:\n        with req_error_context(req_description):\n            _install_wheel(\n                name=name,\n                wheel_zip=z,\n                wheel_path=wheel_path,\n                scheme=scheme,\n                pycompile=pycompile,\n                warn_script_location=warn_script_location,\n                direct_url=direct_url,\n                requested=requested,\n            )\n"},"hash":"VRKIeqhtR8"}