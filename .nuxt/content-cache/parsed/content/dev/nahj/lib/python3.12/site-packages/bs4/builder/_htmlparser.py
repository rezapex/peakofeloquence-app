{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:builder:_htmlparser.py","body":"# encoding: utf-8\n\"\"\"Use the HTMLParser library to parse HTML files that aren't too bad.\"\"\"\n\n# Use of this source code is governed by the MIT license.\n__license__ = \"MIT\"\n\n__all__ = [\n    'HTMLParserTreeBuilder',\n    ]\n\nfrom html.parser import HTMLParser\n\nimport sys\nimport warnings\n\nfrom bs4.element import (\n    CData,\n    Comment,\n    Declaration,\n    Doctype,\n    ProcessingInstruction,\n    )\nfrom bs4.dammit import EntitySubstitution, UnicodeDammit\n\nfrom bs4.builder import (\n    DetectsXMLParsedAsHTML,\n    ParserRejectedMarkup,\n    HTML,\n    HTMLTreeBuilder,\n    STRICT,\n    )\n\n\nHTMLPARSER = 'html.parser'\n\nclass BeautifulSoupHTMLParser(HTMLParser, DetectsXMLParsedAsHTML):\n    \"\"\"A subclass of the Python standard library's HTMLParser class, which\n    listens for HTMLParser events and translates them into calls\n    to Beautiful Soup's tree construction API.\n    \"\"\"\n\n    # Strategies for handling duplicate attributes\n    IGNORE = 'ignore'\n    REPLACE = 'replace'\n    \n    def __init__(self, *args, **kwargs):\n        \"\"\"Constructor.\n\n        :param on_duplicate_attribute: A strategy for what to do if a\n            tag includes the same attribute more than once. Accepted\n            values are: REPLACE (replace earlier values with later\n            ones, the default), IGNORE (keep the earliest value\n            encountered), or a callable. A callable must take three\n            arguments: the dictionary of attributes already processed,\n            the name of the duplicate attribute, and the most recent value\n            encountered.           \n        \"\"\"\n        self.on_duplicate_attribute = kwargs.pop(\n            'on_duplicate_attribute', self.REPLACE\n        )\n        HTMLParser.__init__(self, *args, **kwargs)\n\n        # Keep a list of empty-element tags that were encountered\n        # without an explicit closing tag. If we encounter a closing tag\n        # of this type, we'll associate it with one of those entries.\n        #\n        # This isn't a stack because we don't care about the\n        # order. It's a list of closing tags we've already handled and\n        # will ignore, assuming they ever show up.\n        self.already_closed_empty_element = []\n\n        self._initialize_xml_detector()\n\n    def error(self, message):\n        # NOTE: This method is required so long as Python 3.9 is\n        # supported. The corresponding code is removed from HTMLParser\n        # in 3.5, but not removed from ParserBase until 3.10.\n        # https://github.com/python/cpython/issues/76025\n        #\n        # The original implementation turned the error into a warning,\n        # but in every case I discovered, this made HTMLParser\n        # immediately crash with an error message that was less\n        # helpful than the warning. The new implementation makes it\n        # more clear that html.parser just can't parse this\n        # markup. The 3.10 implementation does the same, though it\n        # raises AssertionError rather than calling a method. (We\n        # catch this error and wrap it in a ParserRejectedMarkup.)\n        raise ParserRejectedMarkup(message)\n\n    def handle_startendtag(self, name, attrs):\n        \"\"\"Handle an incoming empty-element tag.\n\n        This is only called when the markup looks like <tag/>.\n\n        :param name: Name of the tag.\n        :param attrs: Dictionary of the tag's attributes.\n        \"\"\"\n        # is_startend() tells handle_starttag not to close the tag\n        # just because its name matches a known empty-element tag. We\n        # know that this is an empty-element tag and we want to call\n        # handle_endtag ourselves.\n        tag = self.handle_starttag(name, attrs, handle_empty_element=False)\n        self.handle_endtag(name)\n        \n    def handle_starttag(self, name, attrs, handle_empty_element=True):\n        \"\"\"Handle an opening tag, e.g. '<tag>'\n\n        :param name: Name of the tag.\n        :param attrs: Dictionary of the tag's attributes.\n        :param handle_empty_element: True if this tag is known to be\n            an empty-element tag (i.e. there is not expected to be any\n            closing tag).\n        \"\"\"\n        # XXX namespace\n        attr_dict = {}\n        for key, value in attrs:\n            # Change None attribute values to the empty string\n            # for consistency with the other tree builders.\n            if value is None:\n                value = ''\n            if key in attr_dict:\n                # A single attribute shows up multiple times in this\n                # tag. How to handle it depends on the\n                # on_duplicate_attribute setting.\n                on_dupe = self.on_duplicate_attribute\n                if on_dupe == self.IGNORE:\n                    pass\n                elif on_dupe in (None, self.REPLACE):\n                    attr_dict[key] = value\n                else:\n                    on_dupe(attr_dict, key, value)\n            else:\n                attr_dict[key] = value\n            attrvalue = '\"\"'\n        #print(\"START\", name)\n        sourceline, sourcepos = self.getpos()\n        tag = self.soup.handle_starttag(\n            name, None, None, attr_dict, sourceline=sourceline,\n            sourcepos=sourcepos\n        )\n        if tag and tag.is_empty_element and handle_empty_element:\n            # Unlike other parsers, html.parser doesn't send separate end tag\n            # events for empty-element tags. (It's handled in\n            # handle_startendtag, but only if the original markup looked like\n            # <tag/>.)\n            #\n            # So we need to call handle_endtag() ourselves. Since we\n            # know the start event is identical to the end event, we\n            # don't want handle_endtag() to cross off any previous end\n            # events for tags of this name.\n            self.handle_endtag(name, check_already_closed=False)\n\n            # But we might encounter an explicit closing tag for this tag\n            # later on. If so, we want to ignore it.\n            self.already_closed_empty_element.append(name)\n\n        if self._root_tag is None:\n            self._root_tag_encountered(name)\n            \n    def handle_endtag(self, name, check_already_closed=True):\n        \"\"\"Handle a closing tag, e.g. '</tag>'\n        \n        :param name: A tag name.\n        :param check_already_closed: True if this tag is expected to\n           be the closing portion of an empty-element tag,\n           e.g. '<tag></tag>'.\n        \"\"\"\n        #print(\"END\", name)\n        if check_already_closed and name in self.already_closed_empty_element:\n            # This is a redundant end tag for an empty-element tag.\n            # We've already called handle_endtag() for it, so just\n            # check it off the list.\n            #print(\"ALREADY CLOSED\", name)\n            self.already_closed_empty_element.remove(name)\n        else:\n            self.soup.handle_endtag(name)\n            \n    def handle_data(self, data):\n        \"\"\"Handle some textual data that shows up between tags.\"\"\"\n        self.soup.handle_data(data)\n\n    def handle_charref(self, name):\n        \"\"\"Handle a numeric character reference by converting it to the\n        corresponding Unicode character and treating it as textual\n        data.\n\n        :param name: Character number, possibly in hexadecimal.\n        \"\"\"\n        # TODO: This was originally a workaround for a bug in\n        # HTMLParser. (http://bugs.python.org/issue13633) The bug has\n        # been fixed, but removing this code still makes some\n        # Beautiful Soup tests fail. This needs investigation.\n        if name.startswith('x'):\n            real_name = int(name.lstrip('x'), 16)\n        elif name.startswith('X'):\n            real_name = int(name.lstrip('X'), 16)\n        else:\n            real_name = int(name)\n\n        data = None\n        if real_name < 256:\n            # HTML numeric entities are supposed to reference Unicode\n            # code points, but sometimes they reference code points in\n            # some other encoding (ahem, Windows-1252). E.g. &#147;\n            # instead of &#201; for LEFT DOUBLE QUOTATION MARK. This\n            # code tries to detect this situation and compensate.\n            for encoding in (self.soup.original_encoding, 'windows-1252'):\n                if not encoding:\n                    continue\n                try:\n                    data = bytearray([real_name]).decode(encoding)\n                except UnicodeDecodeError as e:\n                    pass\n        if not data:\n            try:\n                data = chr(real_name)\n            except (ValueError, OverflowError) as e:\n                pass\n        data = data or \"\\N{REPLACEMENT CHARACTER}\"\n        self.handle_data(data)\n\n    def handle_entityref(self, name):\n        \"\"\"Handle a named entity reference by converting it to the\n        corresponding Unicode character(s) and treating it as textual\n        data.\n\n        :param name: Name of the entity reference.\n        \"\"\"\n        character = EntitySubstitution.HTML_ENTITY_TO_CHARACTER.get(name)\n        if character is not None:\n            data = character\n        else:\n            # If this were XML, it would be ambiguous whether \"&foo\"\n            # was an character entity reference with a missing\n            # semicolon or the literal string \"&foo\". Since this is\n            # HTML, we have a complete list of all character entity references,\n            # and this one wasn't found, so assume it's the literal string \"&foo\".\n            data = \"&%s\" % name\n        self.handle_data(data)\n\n    def handle_comment(self, data):\n        \"\"\"Handle an HTML comment.\n\n        :param data: The text of the comment.\n        \"\"\"\n        self.soup.endData()\n        self.soup.handle_data(data)\n        self.soup.endData(Comment)\n\n    def handle_decl(self, data):\n        \"\"\"Handle a DOCTYPE declaration.\n\n        :param data: The text of the declaration.\n        \"\"\"\n        self.soup.endData()\n        data = data[len(\"DOCTYPE \"):]\n        self.soup.handle_data(data)\n        self.soup.endData(Doctype)\n\n    def unknown_decl(self, data):\n        \"\"\"Handle a declaration of unknown type -- probably a CDATA block.\n\n        :param data: The text of the declaration.\n        \"\"\"\n        if data.upper().startswith('CDATA['):\n            cls = CData\n            data = data[len('CDATA['):]\n        else:\n            cls = Declaration\n        self.soup.endData()\n        self.soup.handle_data(data)\n        self.soup.endData(cls)\n\n    def handle_pi(self, data):\n        \"\"\"Handle a processing instruction.\n\n        :param data: The text of the instruction.\n        \"\"\"\n        self.soup.endData()\n        self.soup.handle_data(data)\n        self._document_might_be_xml(data)\n        self.soup.endData(ProcessingInstruction)\n\n\nclass HTMLParserTreeBuilder(HTMLTreeBuilder):\n    \"\"\"A Beautiful soup `TreeBuilder` that uses the `HTMLParser` parser,\n    found in the Python standard library.\n    \"\"\"\n    is_xml = False\n    picklable = True\n    NAME = HTMLPARSER\n    features = [NAME, HTML, STRICT]\n\n    # The html.parser knows which line number and position in the\n    # original file is the source of an element.\n    TRACKS_LINE_NUMBERS = True\n\n    def __init__(self, parser_args=None, parser_kwargs=None, **kwargs):\n        \"\"\"Constructor.\n\n        :param parser_args: Positional arguments to pass into \n            the BeautifulSoupHTMLParser constructor, once it's\n            invoked.\n        :param parser_kwargs: Keyword arguments to pass into \n            the BeautifulSoupHTMLParser constructor, once it's\n            invoked.\n        :param kwargs: Keyword arguments for the superclass constructor.\n        \"\"\"\n        # Some keyword arguments will be pulled out of kwargs and placed\n        # into parser_kwargs.\n        extra_parser_kwargs = dict()\n        for arg in ('on_duplicate_attribute',):\n            if arg in kwargs:\n                value = kwargs.pop(arg)\n                extra_parser_kwargs[arg] = value\n        super(HTMLParserTreeBuilder, self).__init__(**kwargs)\n        parser_args = parser_args or []\n        parser_kwargs = parser_kwargs or {}\n        parser_kwargs.update(extra_parser_kwargs)\n        parser_kwargs['convert_charrefs'] = False\n        self.parser_args = (parser_args, parser_kwargs)\n        \n    def prepare_markup(self, markup, user_specified_encoding=None,\n                       document_declared_encoding=None, exclude_encodings=None):\n\n        \"\"\"Run any preliminary steps necessary to make incoming markup\n        acceptable to the parser.\n\n        :param markup: Some markup -- probably a bytestring.\n        :param user_specified_encoding: The user asked to try this encoding.\n        :param document_declared_encoding: The markup itself claims to be\n            in this encoding.\n        :param exclude_encodings: The user asked _not_ to try any of\n            these encodings.\n\n        :yield: A series of 4-tuples:\n         (markup, encoding, declared encoding,\n          has undergone character replacement)\n\n         Each 4-tuple represents a strategy for converting the\n         document to Unicode and parsing it. Each strategy will be tried \n         in turn.\n        \"\"\"\n        if isinstance(markup, str):\n            # Parse Unicode as-is.\n            yield (markup, None, None, False)\n            return\n\n        # Ask UnicodeDammit to sniff the most likely encoding.\n\n        # This was provided by the end-user; treat it as a known\n        # definite encoding per the algorithm laid out in the HTML5\n        # spec.  (See the EncodingDetector class for details.)\n        known_definite_encodings = [user_specified_encoding]\n\n        # This was found in the document; treat it as a slightly lower-priority\n        # user encoding.\n        user_encodings = [document_declared_encoding]\n\n        try_encodings = [user_specified_encoding, document_declared_encoding]\n        dammit = UnicodeDammit(\n            markup,\n            known_definite_encodings=known_definite_encodings,\n            user_encodings=user_encodings,\n            is_html=True,\n            exclude_encodings=exclude_encodings\n        )\n        yield (dammit.markup, dammit.original_encoding,\n               dammit.declared_html_encoding,\n               dammit.contains_replacement_characters)\n\n    def feed(self, markup):\n        \"\"\"Run some incoming markup through some parsing process,\n        populating the `BeautifulSoup` object in self.soup.\n        \"\"\"\n        args, kwargs = self.parser_args\n        parser = BeautifulSoupHTMLParser(*args, **kwargs)\n        parser.soup = self.soup\n        try:\n            parser.feed(markup)\n            parser.close()\n        except AssertionError as e:\n            # html.parser raises AssertionError in rare cases to\n            # indicate a fatal problem with the markup, especially\n            # when there's an error in the doctype declaration.\n            raise ParserRejectedMarkup(e)\n        parser.already_closed_empty_element = []\n"},"hash":"7WI3r31jX1"}