{"parsed":{"_id":"content:dev:nahj:lib:python3.12:site-packages:bs4:diagnose.py","body":"\"\"\"Diagnostic functions, mainly for use when doing tech support.\"\"\"\n\n# Use of this source code is governed by the MIT license.\n__license__ = \"MIT\"\n\nimport cProfile\nfrom io import BytesIO\nfrom html.parser import HTMLParser\nimport bs4\nfrom bs4 import BeautifulSoup, __version__\nfrom bs4.builder import builder_registry\n\nimport os\nimport pstats\nimport random\nimport tempfile\nimport time\nimport traceback\nimport sys\nimport cProfile\n\ndef diagnose(data):\n    \"\"\"Diagnostic suite for isolating common problems.\n\n    :param data: A string containing markup that needs to be explained.\n    :return: None; diagnostics are printed to standard output.\n    \"\"\"\n    print((\"Diagnostic running on Beautiful Soup %s\" % __version__))\n    print((\"Python version %s\" % sys.version))\n\n    basic_parsers = [\"html.parser\", \"html5lib\", \"lxml\"]\n    for name in basic_parsers:\n        for builder in builder_registry.builders:\n            if name in builder.features:\n                break\n        else:\n            basic_parsers.remove(name)\n            print((\n                \"I noticed that %s is not installed. Installing it may help.\" %\n                name))\n\n    if 'lxml' in basic_parsers:\n        basic_parsers.append(\"lxml-xml\")\n        try:\n            from lxml import etree\n            print((\"Found lxml version %s\" % \".\".join(map(str,etree.LXML_VERSION))))\n        except ImportError as e:\n            print(\n                \"lxml is not installed or couldn't be imported.\")\n\n\n    if 'html5lib' in basic_parsers:\n        try:\n            import html5lib\n            print((\"Found html5lib version %s\" % html5lib.__version__))\n        except ImportError as e:\n            print(\n                \"html5lib is not installed or couldn't be imported.\")\n\n    if hasattr(data, 'read'):\n        data = data.read()\n\n    for parser in basic_parsers:\n        print((\"Trying to parse your markup with %s\" % parser))\n        success = False\n        try:\n            soup = BeautifulSoup(data, features=parser)\n            success = True\n        except Exception as e:\n            print((\"%s could not parse the markup.\" % parser))\n            traceback.print_exc()\n        if success:\n            print((\"Here's what %s did with the markup:\" % parser))\n            print((soup.prettify()))\n\n        print((\"-\" * 80))\n\ndef lxml_trace(data, html=True, **kwargs):\n    \"\"\"Print out the lxml events that occur during parsing.\n\n    This lets you see how lxml parses a document when no Beautiful\n    Soup code is running. You can use this to determine whether\n    an lxml-specific problem is in Beautiful Soup's lxml tree builders\n    or in lxml itself.\n\n    :param data: Some markup.\n    :param html: If True, markup will be parsed with lxml's HTML parser.\n       if False, lxml's XML parser will be used.\n    \"\"\"\n    from lxml import etree\n    recover = kwargs.pop('recover', True)\n    if isinstance(data, str):\n        data = data.encode(\"utf8\")\n    reader = BytesIO(data)\n    for event, element in etree.iterparse(\n        reader, html=html, recover=recover, **kwargs\n    ):\n        print((\"%s, %4s, %s\" % (event, element.tag, element.text)))\n\nclass AnnouncingParser(HTMLParser):\n    \"\"\"Subclass of HTMLParser that announces parse events, without doing\n    anything else.\n\n    You can use this to get a picture of how html.parser sees a given\n    document. The easiest way to do this is to call `htmlparser_trace`.\n    \"\"\"\n\n    def _p(self, s):\n        print(s)\n\n    def handle_starttag(self, name, attrs):\n        self._p(\"%s START\" % name)\n\n    def handle_endtag(self, name):\n        self._p(\"%s END\" % name)\n\n    def handle_data(self, data):\n        self._p(\"%s DATA\" % data)\n\n    def handle_charref(self, name):\n        self._p(\"%s CHARREF\" % name)\n\n    def handle_entityref(self, name):\n        self._p(\"%s ENTITYREF\" % name)\n\n    def handle_comment(self, data):\n        self._p(\"%s COMMENT\" % data)\n\n    def handle_decl(self, data):\n        self._p(\"%s DECL\" % data)\n\n    def unknown_decl(self, data):\n        self._p(\"%s UNKNOWN-DECL\" % data)\n\n    def handle_pi(self, data):\n        self._p(\"%s PI\" % data)\n\ndef htmlparser_trace(data):\n    \"\"\"Print out the HTMLParser events that occur during parsing.\n\n    This lets you see how HTMLParser parses a document when no\n    Beautiful Soup code is running.\n\n    :param data: Some markup.\n    \"\"\"\n    parser = AnnouncingParser()\n    parser.feed(data)\n\n_vowels = \"aeiou\"\n_consonants = \"bcdfghjklmnpqrstvwxyz\"\n\ndef rword(length=5):\n    \"Generate a random word-like string.\"\n    s = ''\n    for i in range(length):\n        if i % 2 == 0:\n            t = _consonants\n        else:\n            t = _vowels\n        s += random.choice(t)\n    return s\n\ndef rsentence(length=4):\n    \"Generate a random sentence-like string.\"\n    return \" \".join(rword(random.randint(4,9)) for i in range(length))\n        \ndef rdoc(num_elements=1000):\n    \"\"\"Randomly generate an invalid HTML document.\"\"\"\n    tag_names = ['p', 'div', 'span', 'i', 'b', 'script', 'table']\n    elements = []\n    for i in range(num_elements):\n        choice = random.randint(0,3)\n        if choice == 0:\n            # New tag.\n            tag_name = random.choice(tag_names)\n            elements.append(\"<%s>\" % tag_name)\n        elif choice == 1:\n            elements.append(rsentence(random.randint(1,4)))\n        elif choice == 2:\n            # Close a tag.\n            tag_name = random.choice(tag_names)\n            elements.append(\"</%s>\" % tag_name)\n    return \"<html>\" + \"\\n\".join(elements) + \"</html>\"\n\ndef benchmark_parsers(num_elements=100000):\n    \"\"\"Very basic head-to-head performance benchmark.\"\"\"\n    print((\"Comparative parser benchmark on Beautiful Soup %s\" % __version__))\n    data = rdoc(num_elements)\n    print((\"Generated a large invalid HTML document (%d bytes).\" % len(data)))\n    \n    for parser in [\"lxml\", [\"lxml\", \"html\"], \"html5lib\", \"html.parser\"]:\n        success = False\n        try:\n            a = time.time()\n            soup = BeautifulSoup(data, parser)\n            b = time.time()\n            success = True\n        except Exception as e:\n            print((\"%s could not parse the markup.\" % parser))\n            traceback.print_exc()\n        if success:\n            print((\"BS4+%s parsed the markup in %.2fs.\" % (parser, b-a)))\n\n    from lxml import etree\n    a = time.time()\n    etree.HTML(data)\n    b = time.time()\n    print((\"Raw lxml parsed the markup in %.2fs.\" % (b-a)))\n\n    import html5lib\n    parser = html5lib.HTMLParser()\n    a = time.time()\n    parser.parse(data)\n    b = time.time()\n    print((\"Raw html5lib parsed the markup in %.2fs.\" % (b-a)))\n\ndef profile(num_elements=100000, parser=\"lxml\"):\n    \"\"\"Use Python's profiler on a randomly generated document.\"\"\"\n    filehandle = tempfile.NamedTemporaryFile()\n    filename = filehandle.name\n\n    data = rdoc(num_elements)\n    vars = dict(bs4=bs4, data=data, parser=parser)\n    cProfile.runctx('bs4.BeautifulSoup(data, parser)' , vars, vars, filename)\n\n    stats = pstats.Stats(filename)\n    # stats.strip_dirs()\n    stats.sort_stats(\"cumulative\")\n    stats.print_stats('_html5lib|bs4', 50)\n\n# If this file is run as a script, standard input is diagnosed.\nif __name__ == '__main__':\n    diagnose(sys.stdin.read())\n"},"hash":"e4ztwWWz2D"}